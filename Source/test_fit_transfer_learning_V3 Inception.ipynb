{
  "nbformat": 4,
  "nbformat_minor": 5,
  "metadata": {
    "colab": {
      "name": "test_fit_transfer_learning_V3.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.10"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Y8_z42HbEI36",
        "outputId": "9a9b5928-6498-4162-861d-584dc834a1e6"
      },
      "source": [
        "!pip install exif"
      ],
      "id": "Y8_z42HbEI36",
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting exif\n",
            "  Downloading exif-1.3.1-py3-none-any.whl (29 kB)\n",
            "Collecting plum-py>=0.5.0\n",
            "  Downloading plum_py-0.7.0-py3-none-any.whl (64 kB)\n",
            "\u001b[K     |████████████████████████████████| 64 kB 3.6 MB/s \n",
            "\u001b[?25hInstalling collected packages: plum-py, exif\n",
            "Successfully installed exif-1.3.1 plum-py-0.7.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "29e31f27-98b1-4cef-acc9-d06426f77e7f"
      },
      "source": [
        "import glob\n",
        "from PIL import Image, UnidentifiedImageError\n",
        "from PIL.ExifTags import TAGS #Dicionario chave/descricao dos metadatas padroes das imagens de formato jpg \n",
        "import exif\n",
        "\n",
        "from keras.preprocessing import image\n",
        "\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input as preprocess_input_vgg\n",
        "from keras.applications.vgg16 import decode_predictions as decode_predictions_vgg\n",
        "\n",
        "from keras.applications.inception_v3 import InceptionV3\n",
        "from keras.applications.inception_v3 import preprocess_input as preprocess_input_inception\n",
        "from keras.applications.inception_v3 import decode_predictions as decode_predictions_inception\n",
        "\n",
        "from keras.applications.resnet50 import ResNet50\n",
        "from keras.applications.resnet50 import preprocess_input as preprocess_input_resnet \n",
        "from keras.applications.resnet50 import decode_predictions as decode_predictions_resnet\n",
        "\n",
        "from keras.applications.mobilenet_v2 import MobileNetV2\n",
        "from keras.applications.mobilenet_v2 import preprocess_input as preprocess_input_mobilenet\n",
        "from keras.applications.mobilenet_v2 import decode_predictions as decode_predictions_mobilenet\n",
        "\n",
        "from keras.preprocessing.image import load_img, img_to_array, ImageDataGenerator\n",
        "\n",
        "from keras.models import load_model\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import fbeta_score\n",
        "\n",
        "import copy\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sys\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "from keras import backend\n",
        "\n",
        "from keras.models import Model\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Conv2D\n",
        "from keras.layers import MaxPooling2D\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Flatten\n",
        "from keras.layers import Dropout\n",
        "from keras.optimizers import SGD, RMSprop\n",
        "\n",
        "from google.colab import drive\n",
        "\n",
        "from keras.callbacks import ReduceLROnPlateau, ModelCheckpoint, EarlyStopping"
      ],
      "id": "29e31f27-98b1-4cef-acc9-d06426f77e7f",
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Kj_Ohc9JGMDd",
        "outputId": "cb3937cd-5043-40e9-a567-f4fc15d0e860"
      },
      "source": [
        "drive.mount(\"/content/drive\")"
      ],
      "id": "Kj_Ohc9JGMDd",
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "090c8914-1f1f-4075-bde7-aa52a91e937f"
      },
      "source": [
        "#Definicao do repertorio home do projet\n",
        "#os.chdir(\"C:\\\\Users\\\\Utilisateur\\\\Downloads\\\\tmp\\\\MBA\\\\\")\n",
        "os.chdir('/content/drive/MyDrive/Colab Notebooks/MBA')\n",
        "#Parametros\n",
        "sizeImg = 128"
      ],
      "id": "090c8914-1f1f-4075-bde7-aa52a91e937f",
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "388f2bd7-b5c7-4814-b014-86691e9832e7",
        "outputId": "5afb5749-5da6-4946-95c2-091926329a49"
      },
      "source": [
        "#Lista de tags das 15 classes trabalhadas \n",
        "lstTagClas = ['arvore', 'ave', 'cachorro', 'caminhao', 'carro', 'casa', 'cavalo', \\\n",
        "              'gato', 'mar', 'montanha', 'ponte', 'praia', 'predio', 'rio', 'sol']\n",
        "#Caso nao seja ainda feito, se ordena a lista por ordem alfabetico\n",
        "lstTagClas.sort()\n",
        "print(type(lstTagClas))\n",
        "#Criacao do dicionario tag-id label das classes\n",
        "dicTagId = {lstTagClas[idx]:idx for idx in range(len(lstTagClas))}\n",
        "#Criacao do dicionario id-tag label das classes\n",
        "dicIdTag = {idx:lstTagClas[idx] for idx in range(len(lstTagClas))}\n",
        "\n",
        "countClasses = len(lstTagClas)\n",
        "print(countClasses)\n"
      ],
      "id": "388f2bd7-b5c7-4814-b014-86691e9832e7",
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'list'>\n",
            "15\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "76252114-72a7-47c2-b093-39a32b0f0947"
      },
      "source": [
        "#Funcoes gerais para montar a lista de label de uma imagem (problema multi-label), codificar esta lista de label (gera o target da imagem),\n",
        "# decodificar a target (gera a lista de label da imagem)\n",
        "\n",
        "# Funcao para ter os tags de uma imagem a parte do nome do seu arquivo e da lista das classes trabalhadas\n",
        "def getTagImg(nameFile, lstTagClas):\n",
        "    #Recuperacao dos tags das classes trabalhadas do nome do arquivo\n",
        "    lstTagImg = [tag for tag in nameFile.split('-') if tag in lstTagClas]\n",
        "    #print(lstTagImg)\n",
        "    return lstTagImg\n",
        "\n",
        "# Funcao de codificaca do jogo de saida\n",
        "def oneHotEncode(lstTagImg, dicTagId):\n",
        "    '''Retorna um array de binary com 1 (classe presente) ou 0 (classe nao presente) para cada classe trabalhada, \n",
        "    na posicao definida pelo ID da classe'''\n",
        "    #Criacao do array de tamanho do dicionario de mapping tag-id, inicializado a 0\n",
        "    npIdImg = np.zeros(len(dicTagId), dtype=int)\n",
        "    #Loop sobre a lista dos diferentes tags da imagem\n",
        "    for tag in lstTagImg:\n",
        "        #Se posiciona 1 na posicao do arry que corresponde ao ID do tag\n",
        "        npIdImg[dicTagId[tag]] = 1\n",
        "    #Se retorna o array de codificacao do jogo de saida da imagem\n",
        "    return npIdImg\n",
        "\n",
        "# Funcao de decodificaca do jogo de saida (target) en lista dos tags da foto\n",
        "def oneHotDecode(tgt, dicIdTag):\n",
        "    '''Retorna uma lista dos tags de ID correspondendo as posicoes do jogo de saida com 1'''\n",
        "    #Recupera as posicoes preenchidas\n",
        "    posId = np.nonzero(tgt)\n",
        "    #Monta a lista dos tags da imagem\n",
        "    lstTag = [dicIdTag[id] for id in posId[0]]\n",
        "    #OBS: Precisa recuperar o indice 0 de posId prque np.nonzero retorna tuple de array de posicao nao 0, um elemento por dimensao do array\n",
        "    return lstTag\n",
        "    "
      ],
      "id": "76252114-72a7-47c2-b093-39a32b0f0947",
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "e2745eae-efb5-4da1-b01d-d116510043ee"
      },
      "source": [
        "#Funcao de carregamento e serializacao do jogo de entrada X (pixels das imagens) e de saida (one-hot encoding dos labels das imagens)\n",
        "def loadImg(maskNameFile=\"*\", sizeImg=128):\n",
        "    # Criacao das listas com as imagens e com os labels\n",
        "    lstImgs = []\n",
        "    lstTgts = []\n",
        "    lstNameFiles = []\n",
        "    gntImages = glob.iglob(f\"{maskNameFile}\", recursive=False)\n",
        "    #OBS: Pensar a regegar o generator que ficou vazio depois do loop que gerou o dico dos tags por imagem\n",
        "    for pth in gntImages:\n",
        "        try:\n",
        "            #Se tratar-se bem de um arquivo\n",
        "            if os.path.isfile(pth):\n",
        "                nameFile = os.path.basename(pth)\n",
        "                #print(nameFile)\n",
        "                # Visualizacao da imagem sem transformacao\n",
        "                #img = load_img(fr'{pth}')\n",
        "                #plt.imshow(img)\n",
        "                #plt.show()\n",
        "                #plt.pause(1) \n",
        "                # Dados dos pixels desta imagem de tamanho limitado para economizar memoria\n",
        "                img = image.load_img(fr'{pth}', target_size=(sizeImg,sizeImg))\n",
        "                # convert to numpy array\n",
        "                img = image.img_to_array(img)\n",
        "                #OBS: No exemplo deep_learning_for_computer_vision.pdf, pagina 334, esta indicado de usar dtype uint8, mas como \n",
        "                #     o predict sobre os modelos pretreinados sem ajuste, nao foi bem succedido, se deixou os valores originais.\n",
        "                # Target desta imagem\n",
        "                lstTagImg = getTagImg(nameFile, lstTagClas)\n",
        "                tgt = oneHotEncode(lstTagImg, dicTagId)\n",
        "                #print(tgt)\n",
        "                #Se uma das classes do projeto foi reconhecida a traves o nome do arquivo\n",
        "                if (np.nonzero(tgt)[0].size > 0):\n",
        "                    # Adicao da imagem, da target e do nome arquivo as listas\n",
        "                    lstImgs.append(img)\n",
        "                    lstTgts.append(tgt)\n",
        "                    lstNameFiles.append(nameFile)\n",
        "        except UnidentifiedImageError:\n",
        "            print(f'Warning: O arquivo {nameFile} nao pode estar carregado porque nao esta reconhecido como imagem.')\n",
        "        except:\n",
        "            print(nameFile)\n",
        "            print(\"Unexpected error:\", sys.exc_info()[0])\n",
        "            raise\n",
        "            \n",
        "    #Se passa as imagens, as targets e nomes arquivo em array numpy\n",
        "    X = np.asarray(lstImgs)\n",
        "    Y = np.asarray(lstTgts, dtype=np.int8)\n",
        "    npNameFiles = np.asarray(lstNameFiles)\n",
        "\n",
        "    #Se salva estes arrays em um arquivo compressado de padrao numpy\n",
        "    np.savez_compressed('XY_TestTransferLearning2.npz', X, Y, npNameFiles)  \n",
        "    "
      ],
      "id": "e2745eae-efb5-4da1-b01d-d116510043ee",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "deb99dce-4c36-4612-b122-f86b02fe1f7c",
        "outputId": "c66ea99b-6efc-42e7-84b7-04dd0589af7e"
      },
      "source": [
        "#Se cria o arquivo de compressao com a mascara de imagem e o tamanho de imagens desejados\n",
        "#OBS: A descomentar so na primeira execucao, ja que depois se pode ler diretamente do arquivo criado na primeira execucao\n",
        "#loadImg(\"*\", sizeImg)\n",
        "#Se recarrega o jogo de entrada e saida a parte do arquivo de compressao numpy\n",
        "data = np.load('XY_TestTransferLearning2.npz')\n",
        "X, Y, npNameFiles = data['arr_0'], data['arr_1'], data['arr_2']\n",
        "print(f'Loaded: X: {X.shape}, Y: {Y.shape}, npNameFiles: {npNameFiles.shape}\\n')\n",
        "\n",
        "#Se conta as imagens por classe estudada\n",
        "print(\"Total imagens por classe estudada:\")\n",
        "print(pd.Series(data=Y.sum(axis=0), index=lstTagClas))\n",
        "#Se aproveita do jogo de saida formada de uma serie de 15 booleans com 0 se nao a classe e 1 se tem a classe, para chegar\n",
        "# ao total por classe, somando no axe dos rows (somando no axe de coluna, indicaria o total de tag por imagem).\n",
        "\n",
        "#Stats do numero de classe por imagem\n",
        "print(\"\\nStats do total de classe estudada por imagem:\")\n",
        "print(pd.DataFrame(data=Y.sum(axis=1), columns=['Num. Classes']).describe())\n",
        "\n",
        "#Se separa entre o jogo de treinamento e jogo de test\n",
        "XTrain, XTest, YTrain, YTest = train_test_split(X, Y, test_size=0.3, random_state=1)\n",
        "print(XTrain.shape, YTrain.shape, XTest.shape, YTest.shape)\n"
      ],
      "id": "deb99dce-4c36-4612-b122-f86b02fe1f7c",
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Loaded: X: (750, 128, 128, 3), Y: (750, 15), npNameFiles: (750,)\n",
            "\n",
            "Total imagens por classe estudada:\n",
            "arvore      301\n",
            "ave          83\n",
            "cachorro    104\n",
            "caminhao     80\n",
            "carro       179\n",
            "casa        112\n",
            "cavalo       91\n",
            "gato         62\n",
            "mar         173\n",
            "montanha    111\n",
            "ponte        94\n",
            "praia       100\n",
            "predio       87\n",
            "rio         112\n",
            "sol         114\n",
            "dtype: int64\n",
            "\n",
            "Stats do total de classe estudada por imagem:\n",
            "       Num. Classes\n",
            "count    750.000000\n",
            "mean       2.404000\n",
            "std        0.723982\n",
            "min        1.000000\n",
            "25%        2.000000\n",
            "50%        2.000000\n",
            "75%        3.000000\n",
            "max        5.000000\n",
            "(525, 128, 128, 3) (525, 15) (225, 128, 128, 3) (225, 15)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7d01b37f-5820-4093-a73f-6cfad4fe4d4b"
      },
      "source": [
        "# Funcao de calculo da metrica Fbeta para uma classificacao multi-classe/label\n",
        "#Se cria a metrica fbeta para avaliar o treinamento do modelo (se vai usar a principio com o beta 1 para ter usar a metrica F1)\n",
        "#OBS: A funcao nativa foi retirada do keras devido a gerar confusao em funcao do calculo estar realizado ao nivel batch ou por metrica\n",
        "#     A avaliar se a funcao copiada de deep_learning_for_computer_vision.pdf (pagina 335) esta adequada ou se precisa de uma funcao\n",
        "#     mais sofisticada como explicada no pdf F-beta Score in Keras Part III. Creating custom F-beta score for… _ by Jolomi Tosanwumi _ Towards Data Science\n",
        "def fBetaKeyras(YTrue, YPred, beta=1):\n",
        "    # clip as predicoes entre 0 e 1 (inferior a 0 passa 0 e superior a 1 passa 1)\n",
        "    YPred = backend.clip(YPred, 0, 1)\n",
        "    # calcula os elementos que fazem parte do calculo do indicador FBeta\n",
        "    tp = backend.sum(backend.round(backend.clip(YTrue * YPred, 0, 1)), axis=1)  #Verdadeiros Positivos\n",
        "    fp = backend.sum(backend.round(backend.clip(YPred - YTrue, 0, 1)), axis=1)  #Falsos Positivos\n",
        "    fn = backend.sum(backend.round(backend.clip(YTrue - YPred, 0, 1)), axis=1)  #Falsos Negativos\n",
        "    # Calculo da acuracidade (precisao)\n",
        "    p = tp / (tp + fp + backend.epsilon())\n",
        "    # Calculo do recall\n",
        "    r = tp / (tp + fn + backend.epsilon())\n",
        "    # Calculo do FBeta, com a media de cada classe\n",
        "    bb = beta ** 2\n",
        "    fBetaScore = backend.mean((1 + bb) * (p * r) / (bb * p + r + backend.epsilon()))\n",
        "    #OBS: Uso de uma constante infinitessima epsilon baixa para nao cair no erro de divisao por zero\n",
        "        \n",
        "    return fBetaScore\n"
      ],
      "id": "7d01b37f-5820-4093-a73f-6cfad4fe4d4b",
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a49df431-5da9-4729-a0c8-0d00a5822cab",
        "outputId": "b1a682a7-28e1-4d63-85a2-fd1d02ce7a04"
      },
      "source": [
        "#Verificacao que esta implementacao especefica para Keyras da metrica fBeta da o mesmo resultado que a funcao equivalente de sklearn\n",
        "beta=1 #Calculo da metria F1\n",
        "# Se considera que todas as predicoes do jogo de treinamento e de teste acharam todas as classes em todas as imagens\n",
        "YPredTrain = np.asarray([np.ones(YTrain.shape[1]) for _ in range(YTrain.shape[0])])\n",
        "YPredTest = np.asarray([np.ones(YTest.shape[1]) for _ in range(YTest.shape[0])])\n",
        "# Evaluacao do score F1 destas predicoes de 1 com sklearn\n",
        "scoreTrain = fbeta_score(YTrain, YPredTrain, beta=beta, average='samples')\n",
        "scoreTest = fbeta_score(YTest, YPredTest, beta=beta, average='samples')\n",
        "print('All Ones (sklearn): train=%.4f, test=%.4f' % (scoreTrain, scoreTest))\n",
        "# Evaluacao do score F1 destas predicoes de 1 com a funcao especefica implementada para uso com Keyras\n",
        "scoreTrain = fBetaKeyras(backend.variable(YTrain), backend.variable(YPredTrain), beta=beta)\n",
        "scoreTest = fBetaKeyras(backend.variable(YTest), backend.variable(YPredTest), beta=beta)\n",
        "print('All Ones (keras): train=%.4f, test=%.4f' % (scoreTrain, scoreTest))\n",
        "\n",
        "# Se considera que todas as predicoes do jogo de treinamento e de teste acharam nenhuma classe em todas as imagens\n",
        "YPredTrain = np.asarray([np.zeros(YTrain.shape[1]) for _ in range(YTrain.shape[0])])\n",
        "YPredTest = np.asarray([np.zeros(YTest.shape[1]) for _ in range(YTest.shape[0])])\n",
        "# Evaluacao do score F1 destas predicoes de 1 com sklearn\n",
        "scoreTrain = fbeta_score(YTrain, YPredTrain, beta=beta, average='samples')\n",
        "scoreTest = fbeta_score(YTest, YPredTest, beta=beta, average='samples')\n",
        "print('All Zeros (sklearn): train=%.4f, test=%.4f' % (scoreTrain, scoreTest))\n",
        "# Evaluacao do score F1 destas predicoes de 1 com a funcao especefica implementada para uso com Keyras\n",
        "scoreTrain = fBetaKeyras(backend.variable(YTrain), backend.variable(YPredTrain), beta=beta)\n",
        "scoreTest = fBetaKeyras(backend.variable(YTest), backend.variable(YPredTest), beta=beta)\n",
        "print('All Zeros (keras): train=%.4f, test=%.4f' % (scoreTrain, scoreTest))\n"
      ],
      "id": "a49df431-5da9-4729-a0c8-0d00a5822cab",
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "All Ones (sklearn): train=0.2741, test=0.2714\n",
            "All Ones (keras): train=0.2741, test=0.2714\n",
            "All Zeros (sklearn): train=0.0000, test=0.0000\n",
            "All Zeros (keras): train=0.0000, test=0.0000\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "c321df96-c114-46bc-b055-8924f810b7d4"
      },
      "source": [
        "#Funcao para apresentar a evoluca da funcao custo de perda e da metrica F1 por epoca de treinamento\n",
        "def figureTrain(histTrain, nameFileFig):\n",
        "    plt.figure(figsize=(8,7))\n",
        "    # plot da funcao de custo de perda\n",
        "    plt.subplot(211)\n",
        "    plt.title('Cross Entropy Loss')\n",
        "    plt.plot(histTrain.history['loss'], color='blue', label='train')\n",
        "    plt.plot(histTrain.history['val_loss'], color='orange', label='test')\n",
        "    plt.legend()\n",
        "    # plot accuracy\n",
        "    plt.subplot(212)\n",
        "    plt.title('F1')\n",
        "    plt.plot(histTrain.history['fBetaKeyras'], color='blue', label='train')\n",
        "    plt.plot(histTrain.history['val_fBetaKeyras'], color='orange', label='test')\n",
        "    plt.legend()\n",
        "    \n",
        "    plt.show()\n",
        "    # Se salva a figura em arquivo\n",
        "    plt.savefig(f'{nameFileFig}.png')\n",
        "    plt.close()\n"
      ],
      "id": "c321df96-c114-46bc-b055-8924f810b7d4",
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "b6edwPj43LcI"
      },
      "source": [
        "Tecnica early-stopping, quando o custo (loss) do jogo de teste comeca a subir e o do jogo train a seguir a baixar\n",
        "(nao adianta seguir as epocas porque entrou na zona de over fitting) "
      ],
      "id": "b6edwPj43LcI",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LkC3C0Orp6_c"
      },
      "source": [
        "# II) MODELO INCEPTION PARA TRANSFER LEARNING\n",
        "OBS: - Tentanto com o modelo Resnet50, tive um erro tentando colocar a camada flatten:\n",
        "Attempt to convert a value (None) with an unsupported type (<class 'NoneType'>) to a Tensor. resnet\n",
        "\n",
        "      - Com MobileNet, os resultados se aproximam de os obtidos com Vgg16, usando o mesmo otimizador SGD com lr de 0,01, mas fica inferior."
      ],
      "id": "LkC3C0Orp6_c"
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4cfa2749-0ab6-494f-878f-5f46f067bc00"
      },
      "source": [
        "# Modelo derivado do InceptionV3 para aplicar o transfer learning de toda a parte de selecao das features (parte convolucional do modelo)\n",
        "# Drop out da camada convolucional passado de 0.2 a 0.1 para testar o data augmentation (um drop out demais forte junto com o data augmentation pode \n",
        "# impedir a aprendizagem)\n",
        "def defineModelInceptionV3(inputShape, outputShape):\n",
        "    # Se carrega o modelo da API Keyras\n",
        "    #model = ResNet50(include_top=False, input_shape=inputShape, weights='imagenet')\n",
        "    #model = MobileNetV2(include_top=False, input_shape=inputShape, weights='imagenet')\n",
        "    model = InceptionV3(include_top=False, input_shape=inputShape, weights='imagenet')\n",
        "    # Se indica que as camadas (ficou so as da parte convolucional de selecao das features) nao podem estar treinadas \n",
        "    # (para congelar os pesos recuperados do modelo Resnet)\n",
        "    for camada in model.layers:\n",
        "        camada.trainable = False\n",
        "    # Se cria a parte de classificacao do modelo adicionando novas camadas densamente conectadas\n",
        "    flat1 = Flatten()(model.layers[-1].output)\n",
        "    class1 = Dense(128, activation='relu', kernel_initializer='he_uniform')(flat1)\n",
        "    drop1 = Dropout(0.1)(class1)\n",
        "    output = Dense(outputShape, activation='sigmoid')(drop1)\n",
        "    # Definicao do novo modelo\n",
        "    model = Model(inputs=model.inputs, outputs=output)\n",
        "    # Compilacao do modelo\n",
        "    #opt = SGD(learning_rate=0.01, momentum=0.9)\n",
        "    opt = RMSprop(learning_rate=0.0001)\n",
        "    model.compile(optimizer=opt, loss='binary_crossentropy', metrics=[fBetaKeyras])\n",
        "    # Apresentacao do modelo\n",
        "    model.summary()\n",
        "    return model"
      ],
      "id": "4cfa2749-0ab6-494f-878f-5f46f067bc00",
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 231
        },
        "id": "DSmYftnDMxJ7",
        "outputId": "a3779333-5d0c-4024-b865-e123ce45f9b4"
      },
      "source": [
        "    # Se carrega o modelo da API Keyras\n",
        "    input_shape=(sizeImg, sizeImg, 3)\n",
        "    model = ResNet50(include_top=False, input_shape=inputShape, weights='imagenet')\n",
        "    #model = InceptionV3(include_top=False, input_shape=inputShape, weights='imagenet')\n",
        "    # Se indica que as camadas (ficou so as da parte convolucional de selecao das features) nao podem estar treinadas \n",
        "    # (para congelar os pesos recuperados do modelo Resnet)\n",
        "    for camada in model.layers:\n",
        "        camada.trainable = False\n",
        "    # Se cria a parte de classificacao do modelo adicionando novas camadas densamente conectadas\n",
        "    flat1 = Flatten()(model.layers[-1].output)"
      ],
      "id": "DSmYftnDMxJ7",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-14-4a3f46d455db>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Se carrega o modelo da API Keyras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msizeImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msizeImg\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mResNet50\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minclude_top\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_shape\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputShape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mweights\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'imagenet'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#model = InceptionV3(include_top=False, input_shape=inputShape, weights='imagenet')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Se indica que as camadas (ficou so as da parte convolucional de selecao das features) nao podem estar treinadas\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'inputShape' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "2c7428e3-e4ab-49c5-af36-db09111fa15d",
        "outputId": "3a58215a-42c9-40ab-d0f4-24e808e9cd17"
      },
      "source": [
        "#Inicializacao do modelo InceptionV3, treinamento e avaliacao do resultado (com um dropout da camada convolucional a 0.2)\n",
        "verbose=1\n",
        "\n",
        "# Objeto Generator de Keyras com preprocessamento usando os valores centralizacao do jogo de dados de IMAGENET\n",
        "dataGen = ImageDataGenerator(featurewise_center=True)\n",
        "# Definicao da media do jogo de dados Imagenet para centralizacao das fotos como esperado pelo \n",
        "# modelo InceptionV3 treinado sobre este jogo\n",
        "dataGen.mean = [123.68, 116.779, 103.939]\n",
        "\n",
        "# Criacao dos objetos de iteracao do jogo de treinamento e de teste para gerar batch das imagens a cada epoca do treinamento\n",
        "iterTrain = dataGen.flow(XTrain, YTrain, batch_size=128)\n",
        "iterTest = dataGen.flow(XTest, YTest, batch_size=128)\n",
        "# Definicao do modelo RENET50\n",
        "# Aplicacao da tecnica de machine learning ja que o treinamento vai se limitar a parte de classificacao (camadas densamente\n",
        "# conectadas), aproveitando na parte de selecao das features (camadas convolucionais e de pooling) dos pesos ja treinados \n",
        "# com o jogo de dados Imagenet.\n",
        "model = defineModelInceptionV3((sizeImg, sizeImg, 3), countClasses)\n",
        "# Treinamento (fit) do modelo\n",
        "histTrain = model.fit_generator(iterTrain, steps_per_epoch=len(iterTrain), \\\n",
        "                                validation_data=iterTest, validation_steps=len(iterTest), epochs=200, verbose=verbose)\n",
        "# Evaluacao do modelo\n",
        "loss, fBeta = model.evaluate_generator(iterTest, steps=len(iterTest), verbose=verbose)\n",
        "print('> loss=%.3f, fbeta=%.3f' % (loss, fBeta))\n",
        "# Figura com as curvas de treinamento\n",
        "figureTrain(histTrain, 'INCEPTIONV3')\n"
      ],
      "id": "2c7428e3-e4ab-49c5-af36-db09111fa15d",
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/inception_v3/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "87916544/87910968 [==============================] - 1s 0us/step\n",
            "87924736/87910968 [==============================] - 1s 0us/step\n",
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_1 (InputLayer)            [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d (Conv2D)                 (None, 63, 63, 32)   864         input_1[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization (BatchNorma (None, 63, 63, 32)   96          conv2d[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "activation (Activation)         (None, 63, 63, 32)   0           batch_normalization[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_1 (Conv2D)               (None, 61, 61, 32)   9216        activation[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_1 (BatchNor (None, 61, 61, 32)   96          conv2d_1[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_1 (Activation)       (None, 61, 61, 32)   0           batch_normalization_1[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_2 (Conv2D)               (None, 61, 61, 64)   18432       activation_1[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_2 (BatchNor (None, 61, 61, 64)   192         conv2d_2[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_2 (Activation)       (None, 61, 61, 64)   0           batch_normalization_2[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D)    (None, 30, 30, 64)   0           activation_2[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_3 (Conv2D)               (None, 30, 30, 80)   5120        max_pooling2d[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_3 (BatchNor (None, 30, 30, 80)   240         conv2d_3[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_3 (Activation)       (None, 30, 30, 80)   0           batch_normalization_3[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_4 (Conv2D)               (None, 28, 28, 192)  138240      activation_3[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_4 (BatchNor (None, 28, 28, 192)  576         conv2d_4[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_4 (Activation)       (None, 28, 28, 192)  0           batch_normalization_4[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2D)  (None, 13, 13, 192)  0           activation_4[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_8 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_8 (BatchNor (None, 13, 13, 64)   192         conv2d_8[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_8 (Activation)       (None, 13, 13, 64)   0           batch_normalization_8[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_6 (Conv2D)               (None, 13, 13, 48)   9216        max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_9 (Conv2D)               (None, 13, 13, 96)   55296       activation_8[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_6 (BatchNor (None, 13, 13, 48)   144         conv2d_6[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_9 (BatchNor (None, 13, 13, 96)   288         conv2d_9[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "activation_6 (Activation)       (None, 13, 13, 48)   0           batch_normalization_6[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_9 (Activation)       (None, 13, 13, 96)   0           batch_normalization_9[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d (AveragePooli (None, 13, 13, 192)  0           max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_5 (Conv2D)               (None, 13, 13, 64)   12288       max_pooling2d_1[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_7 (Conv2D)               (None, 13, 13, 64)   76800       activation_6[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_10 (Conv2D)              (None, 13, 13, 96)   82944       activation_9[0][0]               \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_11 (Conv2D)              (None, 13, 13, 32)   6144        average_pooling2d[0][0]          \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_5 (BatchNor (None, 13, 13, 64)   192         conv2d_5[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_7 (BatchNor (None, 13, 13, 64)   192         conv2d_7[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_10 (BatchNo (None, 13, 13, 96)   288         conv2d_10[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_11 (BatchNo (None, 13, 13, 32)   96          conv2d_11[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_5 (Activation)       (None, 13, 13, 64)   0           batch_normalization_5[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_7 (Activation)       (None, 13, 13, 64)   0           batch_normalization_7[0][0]      \n",
            "__________________________________________________________________________________________________\n",
            "activation_10 (Activation)      (None, 13, 13, 96)   0           batch_normalization_10[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_11 (Activation)      (None, 13, 13, 32)   0           batch_normalization_11[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 13, 13, 256)  0           activation_5[0][0]               \n",
            "                                                                 activation_7[0][0]               \n",
            "                                                                 activation_10[0][0]              \n",
            "                                                                 activation_11[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_15 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_15 (BatchNo (None, 13, 13, 64)   192         conv2d_15[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_15 (Activation)      (None, 13, 13, 64)   0           batch_normalization_15[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_13 (Conv2D)              (None, 13, 13, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_16 (Conv2D)              (None, 13, 13, 96)   55296       activation_15[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_13 (BatchNo (None, 13, 13, 48)   144         conv2d_13[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_16 (BatchNo (None, 13, 13, 96)   288         conv2d_16[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_13 (Activation)      (None, 13, 13, 48)   0           batch_normalization_13[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_16 (Activation)      (None, 13, 13, 96)   0           batch_normalization_16[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_1 (AveragePoo (None, 13, 13, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_12 (Conv2D)              (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_14 (Conv2D)              (None, 13, 13, 64)   76800       activation_13[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_17 (Conv2D)              (None, 13, 13, 96)   82944       activation_16[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_18 (Conv2D)              (None, 13, 13, 64)   16384       average_pooling2d_1[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_12 (BatchNo (None, 13, 13, 64)   192         conv2d_12[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_14 (BatchNo (None, 13, 13, 64)   192         conv2d_14[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_17 (BatchNo (None, 13, 13, 96)   288         conv2d_17[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_18 (BatchNo (None, 13, 13, 64)   192         conv2d_18[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_12 (Activation)      (None, 13, 13, 64)   0           batch_normalization_12[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_14 (Activation)      (None, 13, 13, 64)   0           batch_normalization_14[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_17 (Activation)      (None, 13, 13, 96)   0           batch_normalization_17[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_18 (Activation)      (None, 13, 13, 64)   0           batch_normalization_18[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 13, 13, 288)  0           activation_12[0][0]              \n",
            "                                                                 activation_14[0][0]              \n",
            "                                                                 activation_17[0][0]              \n",
            "                                                                 activation_18[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_22 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_22 (BatchNo (None, 13, 13, 64)   192         conv2d_22[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_22 (Activation)      (None, 13, 13, 64)   0           batch_normalization_22[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_20 (Conv2D)              (None, 13, 13, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_23 (Conv2D)              (None, 13, 13, 96)   55296       activation_22[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_20 (BatchNo (None, 13, 13, 48)   144         conv2d_20[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_23 (BatchNo (None, 13, 13, 96)   288         conv2d_23[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_20 (Activation)      (None, 13, 13, 48)   0           batch_normalization_20[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_23 (Activation)      (None, 13, 13, 96)   0           batch_normalization_23[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_2 (AveragePoo (None, 13, 13, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_19 (Conv2D)              (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_21 (Conv2D)              (None, 13, 13, 64)   76800       activation_20[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_24 (Conv2D)              (None, 13, 13, 96)   82944       activation_23[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_25 (Conv2D)              (None, 13, 13, 64)   18432       average_pooling2d_2[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_19 (BatchNo (None, 13, 13, 64)   192         conv2d_19[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_21 (BatchNo (None, 13, 13, 64)   192         conv2d_21[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_24 (BatchNo (None, 13, 13, 96)   288         conv2d_24[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_25 (BatchNo (None, 13, 13, 64)   192         conv2d_25[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_19 (Activation)      (None, 13, 13, 64)   0           batch_normalization_19[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_21 (Activation)      (None, 13, 13, 64)   0           batch_normalization_21[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_24 (Activation)      (None, 13, 13, 96)   0           batch_normalization_24[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_25 (Activation)      (None, 13, 13, 64)   0           batch_normalization_25[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 13, 13, 288)  0           activation_19[0][0]              \n",
            "                                                                 activation_21[0][0]              \n",
            "                                                                 activation_24[0][0]              \n",
            "                                                                 activation_25[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_27 (Conv2D)              (None, 13, 13, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_27 (BatchNo (None, 13, 13, 64)   192         conv2d_27[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_27 (Activation)      (None, 13, 13, 64)   0           batch_normalization_27[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_28 (Conv2D)              (None, 13, 13, 96)   55296       activation_27[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_28 (BatchNo (None, 13, 13, 96)   288         conv2d_28[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_28 (Activation)      (None, 13, 13, 96)   0           batch_normalization_28[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_26 (Conv2D)              (None, 6, 6, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_29 (Conv2D)              (None, 6, 6, 96)     82944       activation_28[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_26 (BatchNo (None, 6, 6, 384)    1152        conv2d_26[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_29 (BatchNo (None, 6, 6, 96)     288         conv2d_29[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_26 (Activation)      (None, 6, 6, 384)    0           batch_normalization_26[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_29 (Activation)      (None, 6, 6, 96)     0           batch_normalization_29[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_2 (MaxPooling2D)  (None, 6, 6, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 6, 6, 768)    0           activation_26[0][0]              \n",
            "                                                                 activation_29[0][0]              \n",
            "                                                                 max_pooling2d_2[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_34 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_34 (BatchNo (None, 6, 6, 128)    384         conv2d_34[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_34 (Activation)      (None, 6, 6, 128)    0           batch_normalization_34[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_35 (Conv2D)              (None, 6, 6, 128)    114688      activation_34[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_35 (BatchNo (None, 6, 6, 128)    384         conv2d_35[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_35 (Activation)      (None, 6, 6, 128)    0           batch_normalization_35[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_31 (Conv2D)              (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_36 (Conv2D)              (None, 6, 6, 128)    114688      activation_35[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_31 (BatchNo (None, 6, 6, 128)    384         conv2d_31[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_36 (BatchNo (None, 6, 6, 128)    384         conv2d_36[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_31 (Activation)      (None, 6, 6, 128)    0           batch_normalization_31[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_36 (Activation)      (None, 6, 6, 128)    0           batch_normalization_36[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_32 (Conv2D)              (None, 6, 6, 128)    114688      activation_31[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_37 (Conv2D)              (None, 6, 6, 128)    114688      activation_36[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_32 (BatchNo (None, 6, 6, 128)    384         conv2d_32[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_37 (BatchNo (None, 6, 6, 128)    384         conv2d_37[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_32 (Activation)      (None, 6, 6, 128)    0           batch_normalization_32[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_37 (Activation)      (None, 6, 6, 128)    0           batch_normalization_37[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_3 (AveragePoo (None, 6, 6, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_30 (Conv2D)              (None, 6, 6, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_33 (Conv2D)              (None, 6, 6, 192)    172032      activation_32[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_38 (Conv2D)              (None, 6, 6, 192)    172032      activation_37[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_39 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_3[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_30 (BatchNo (None, 6, 6, 192)    576         conv2d_30[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_33 (BatchNo (None, 6, 6, 192)    576         conv2d_33[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_38 (BatchNo (None, 6, 6, 192)    576         conv2d_38[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_39 (BatchNo (None, 6, 6, 192)    576         conv2d_39[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_30 (Activation)      (None, 6, 6, 192)    0           batch_normalization_30[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_33 (Activation)      (None, 6, 6, 192)    0           batch_normalization_33[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_38 (Activation)      (None, 6, 6, 192)    0           batch_normalization_38[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_39 (Activation)      (None, 6, 6, 192)    0           batch_normalization_39[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 6, 6, 768)    0           activation_30[0][0]              \n",
            "                                                                 activation_33[0][0]              \n",
            "                                                                 activation_38[0][0]              \n",
            "                                                                 activation_39[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_44 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_44 (BatchNo (None, 6, 6, 160)    480         conv2d_44[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_44 (Activation)      (None, 6, 6, 160)    0           batch_normalization_44[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_45 (Conv2D)              (None, 6, 6, 160)    179200      activation_44[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_45 (BatchNo (None, 6, 6, 160)    480         conv2d_45[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_45 (Activation)      (None, 6, 6, 160)    0           batch_normalization_45[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_41 (Conv2D)              (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_46 (Conv2D)              (None, 6, 6, 160)    179200      activation_45[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_41 (BatchNo (None, 6, 6, 160)    480         conv2d_41[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_46 (BatchNo (None, 6, 6, 160)    480         conv2d_46[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_41 (Activation)      (None, 6, 6, 160)    0           batch_normalization_41[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_46 (Activation)      (None, 6, 6, 160)    0           batch_normalization_46[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_42 (Conv2D)              (None, 6, 6, 160)    179200      activation_41[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_47 (Conv2D)              (None, 6, 6, 160)    179200      activation_46[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_42 (BatchNo (None, 6, 6, 160)    480         conv2d_42[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_47 (BatchNo (None, 6, 6, 160)    480         conv2d_47[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_42 (Activation)      (None, 6, 6, 160)    0           batch_normalization_42[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_47 (Activation)      (None, 6, 6, 160)    0           batch_normalization_47[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_4 (AveragePoo (None, 6, 6, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_40 (Conv2D)              (None, 6, 6, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_43 (Conv2D)              (None, 6, 6, 192)    215040      activation_42[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_48 (Conv2D)              (None, 6, 6, 192)    215040      activation_47[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_49 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_4[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_40 (BatchNo (None, 6, 6, 192)    576         conv2d_40[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_43 (BatchNo (None, 6, 6, 192)    576         conv2d_43[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_48 (BatchNo (None, 6, 6, 192)    576         conv2d_48[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_49 (BatchNo (None, 6, 6, 192)    576         conv2d_49[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_40 (Activation)      (None, 6, 6, 192)    0           batch_normalization_40[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_43 (Activation)      (None, 6, 6, 192)    0           batch_normalization_43[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_48 (Activation)      (None, 6, 6, 192)    0           batch_normalization_48[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_49 (Activation)      (None, 6, 6, 192)    0           batch_normalization_49[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 6, 6, 768)    0           activation_40[0][0]              \n",
            "                                                                 activation_43[0][0]              \n",
            "                                                                 activation_48[0][0]              \n",
            "                                                                 activation_49[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_54 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_54 (BatchNo (None, 6, 6, 160)    480         conv2d_54[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_54 (Activation)      (None, 6, 6, 160)    0           batch_normalization_54[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_55 (Conv2D)              (None, 6, 6, 160)    179200      activation_54[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_55 (BatchNo (None, 6, 6, 160)    480         conv2d_55[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_55 (Activation)      (None, 6, 6, 160)    0           batch_normalization_55[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_51 (Conv2D)              (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_56 (Conv2D)              (None, 6, 6, 160)    179200      activation_55[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_51 (BatchNo (None, 6, 6, 160)    480         conv2d_51[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_56 (BatchNo (None, 6, 6, 160)    480         conv2d_56[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_51 (Activation)      (None, 6, 6, 160)    0           batch_normalization_51[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_56 (Activation)      (None, 6, 6, 160)    0           batch_normalization_56[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_52 (Conv2D)              (None, 6, 6, 160)    179200      activation_51[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_57 (Conv2D)              (None, 6, 6, 160)    179200      activation_56[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_52 (BatchNo (None, 6, 6, 160)    480         conv2d_52[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_57 (BatchNo (None, 6, 6, 160)    480         conv2d_57[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_52 (Activation)      (None, 6, 6, 160)    0           batch_normalization_52[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_57 (Activation)      (None, 6, 6, 160)    0           batch_normalization_57[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_5 (AveragePoo (None, 6, 6, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_50 (Conv2D)              (None, 6, 6, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_53 (Conv2D)              (None, 6, 6, 192)    215040      activation_52[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_58 (Conv2D)              (None, 6, 6, 192)    215040      activation_57[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_59 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_5[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_50 (BatchNo (None, 6, 6, 192)    576         conv2d_50[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_53 (BatchNo (None, 6, 6, 192)    576         conv2d_53[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_58 (BatchNo (None, 6, 6, 192)    576         conv2d_58[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_59 (BatchNo (None, 6, 6, 192)    576         conv2d_59[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_50 (Activation)      (None, 6, 6, 192)    0           batch_normalization_50[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_53 (Activation)      (None, 6, 6, 192)    0           batch_normalization_53[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_58 (Activation)      (None, 6, 6, 192)    0           batch_normalization_58[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_59 (Activation)      (None, 6, 6, 192)    0           batch_normalization_59[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 6, 6, 768)    0           activation_50[0][0]              \n",
            "                                                                 activation_53[0][0]              \n",
            "                                                                 activation_58[0][0]              \n",
            "                                                                 activation_59[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_64 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_64 (BatchNo (None, 6, 6, 192)    576         conv2d_64[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_64 (Activation)      (None, 6, 6, 192)    0           batch_normalization_64[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_65 (Conv2D)              (None, 6, 6, 192)    258048      activation_64[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_65 (BatchNo (None, 6, 6, 192)    576         conv2d_65[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_65 (Activation)      (None, 6, 6, 192)    0           batch_normalization_65[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_61 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_66 (Conv2D)              (None, 6, 6, 192)    258048      activation_65[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_61 (BatchNo (None, 6, 6, 192)    576         conv2d_61[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_66 (BatchNo (None, 6, 6, 192)    576         conv2d_66[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_61 (Activation)      (None, 6, 6, 192)    0           batch_normalization_61[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_66 (Activation)      (None, 6, 6, 192)    0           batch_normalization_66[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_62 (Conv2D)              (None, 6, 6, 192)    258048      activation_61[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_67 (Conv2D)              (None, 6, 6, 192)    258048      activation_66[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_62 (BatchNo (None, 6, 6, 192)    576         conv2d_62[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_67 (BatchNo (None, 6, 6, 192)    576         conv2d_67[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_62 (Activation)      (None, 6, 6, 192)    0           batch_normalization_62[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_67 (Activation)      (None, 6, 6, 192)    0           batch_normalization_67[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_6 (AveragePoo (None, 6, 6, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_60 (Conv2D)              (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_63 (Conv2D)              (None, 6, 6, 192)    258048      activation_62[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_68 (Conv2D)              (None, 6, 6, 192)    258048      activation_67[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_69 (Conv2D)              (None, 6, 6, 192)    147456      average_pooling2d_6[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_60 (BatchNo (None, 6, 6, 192)    576         conv2d_60[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_63 (BatchNo (None, 6, 6, 192)    576         conv2d_63[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_68 (BatchNo (None, 6, 6, 192)    576         conv2d_68[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_69 (BatchNo (None, 6, 6, 192)    576         conv2d_69[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_60 (Activation)      (None, 6, 6, 192)    0           batch_normalization_60[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_63 (Activation)      (None, 6, 6, 192)    0           batch_normalization_63[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_68 (Activation)      (None, 6, 6, 192)    0           batch_normalization_68[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_69 (Activation)      (None, 6, 6, 192)    0           batch_normalization_69[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 6, 6, 768)    0           activation_60[0][0]              \n",
            "                                                                 activation_63[0][0]              \n",
            "                                                                 activation_68[0][0]              \n",
            "                                                                 activation_69[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_72 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_72 (BatchNo (None, 6, 6, 192)    576         conv2d_72[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_72 (Activation)      (None, 6, 6, 192)    0           batch_normalization_72[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_73 (Conv2D)              (None, 6, 6, 192)    258048      activation_72[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_73 (BatchNo (None, 6, 6, 192)    576         conv2d_73[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_73 (Activation)      (None, 6, 6, 192)    0           batch_normalization_73[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_70 (Conv2D)              (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_74 (Conv2D)              (None, 6, 6, 192)    258048      activation_73[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_70 (BatchNo (None, 6, 6, 192)    576         conv2d_70[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_74 (BatchNo (None, 6, 6, 192)    576         conv2d_74[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_70 (Activation)      (None, 6, 6, 192)    0           batch_normalization_70[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_74 (Activation)      (None, 6, 6, 192)    0           batch_normalization_74[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_71 (Conv2D)              (None, 2, 2, 320)    552960      activation_70[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_75 (Conv2D)              (None, 2, 2, 192)    331776      activation_74[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_71 (BatchNo (None, 2, 2, 320)    960         conv2d_71[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_75 (BatchNo (None, 2, 2, 192)    576         conv2d_75[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_71 (Activation)      (None, 2, 2, 320)    0           batch_normalization_71[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_75 (Activation)      (None, 2, 2, 192)    0           batch_normalization_75[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_3 (MaxPooling2D)  (None, 2, 2, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 2, 2, 1280)   0           activation_71[0][0]              \n",
            "                                                                 activation_75[0][0]              \n",
            "                                                                 max_pooling2d_3[0][0]            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_80 (Conv2D)              (None, 2, 2, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_80 (BatchNo (None, 2, 2, 448)    1344        conv2d_80[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_80 (Activation)      (None, 2, 2, 448)    0           batch_normalization_80[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_77 (Conv2D)              (None, 2, 2, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_81 (Conv2D)              (None, 2, 2, 384)    1548288     activation_80[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_77 (BatchNo (None, 2, 2, 384)    1152        conv2d_77[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_81 (BatchNo (None, 2, 2, 384)    1152        conv2d_81[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_77 (Activation)      (None, 2, 2, 384)    0           batch_normalization_77[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_81 (Activation)      (None, 2, 2, 384)    0           batch_normalization_81[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_78 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_79 (Conv2D)              (None, 2, 2, 384)    442368      activation_77[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_82 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_83 (Conv2D)              (None, 2, 2, 384)    442368      activation_81[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_7 (AveragePoo (None, 2, 2, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_76 (Conv2D)              (None, 2, 2, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_78 (BatchNo (None, 2, 2, 384)    1152        conv2d_78[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_79 (BatchNo (None, 2, 2, 384)    1152        conv2d_79[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_82 (BatchNo (None, 2, 2, 384)    1152        conv2d_82[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_83 (BatchNo (None, 2, 2, 384)    1152        conv2d_83[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_84 (Conv2D)              (None, 2, 2, 192)    245760      average_pooling2d_7[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_76 (BatchNo (None, 2, 2, 320)    960         conv2d_76[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_78 (Activation)      (None, 2, 2, 384)    0           batch_normalization_78[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_79 (Activation)      (None, 2, 2, 384)    0           batch_normalization_79[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_82 (Activation)      (None, 2, 2, 384)    0           batch_normalization_82[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_83 (Activation)      (None, 2, 2, 384)    0           batch_normalization_83[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_84 (BatchNo (None, 2, 2, 192)    576         conv2d_84[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_76 (Activation)      (None, 2, 2, 320)    0           batch_normalization_76[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 2, 2, 768)    0           activation_78[0][0]              \n",
            "                                                                 activation_79[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate (Concatenate)       (None, 2, 2, 768)    0           activation_82[0][0]              \n",
            "                                                                 activation_83[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_84 (Activation)      (None, 2, 2, 192)    0           batch_normalization_84[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 2, 2, 2048)   0           activation_76[0][0]              \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate[0][0]                \n",
            "                                                                 activation_84[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_89 (Conv2D)              (None, 2, 2, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_89 (BatchNo (None, 2, 2, 448)    1344        conv2d_89[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_89 (Activation)      (None, 2, 2, 448)    0           batch_normalization_89[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_86 (Conv2D)              (None, 2, 2, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_90 (Conv2D)              (None, 2, 2, 384)    1548288     activation_89[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_86 (BatchNo (None, 2, 2, 384)    1152        conv2d_86[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_90 (BatchNo (None, 2, 2, 384)    1152        conv2d_90[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_86 (Activation)      (None, 2, 2, 384)    0           batch_normalization_86[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_90 (Activation)      (None, 2, 2, 384)    0           batch_normalization_90[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_87 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_88 (Conv2D)              (None, 2, 2, 384)    442368      activation_86[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_91 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_92 (Conv2D)              (None, 2, 2, 384)    442368      activation_90[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_8 (AveragePoo (None, 2, 2, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_85 (Conv2D)              (None, 2, 2, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_87 (BatchNo (None, 2, 2, 384)    1152        conv2d_87[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_88 (BatchNo (None, 2, 2, 384)    1152        conv2d_88[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_91 (BatchNo (None, 2, 2, 384)    1152        conv2d_91[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_92 (BatchNo (None, 2, 2, 384)    1152        conv2d_92[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_93 (Conv2D)              (None, 2, 2, 192)    393216      average_pooling2d_8[0][0]        \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_85 (BatchNo (None, 2, 2, 320)    960         conv2d_85[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_87 (Activation)      (None, 2, 2, 384)    0           batch_normalization_87[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_88 (Activation)      (None, 2, 2, 384)    0           batch_normalization_88[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_91 (Activation)      (None, 2, 2, 384)    0           batch_normalization_91[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "activation_92 (Activation)      (None, 2, 2, 384)    0           batch_normalization_92[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_93 (BatchNo (None, 2, 2, 192)    576         conv2d_93[0][0]                  \n",
            "__________________________________________________________________________________________________\n",
            "activation_85 (Activation)      (None, 2, 2, 320)    0           batch_normalization_85[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 2, 2, 768)    0           activation_87[0][0]              \n",
            "                                                                 activation_88[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_1 (Concatenate)     (None, 2, 2, 768)    0           activation_91[0][0]              \n",
            "                                                                 activation_92[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "activation_93 (Activation)      (None, 2, 2, 192)    0           batch_normalization_93[0][0]     \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 2, 2, 2048)   0           activation_85[0][0]              \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_1[0][0]              \n",
            "                                                                 activation_93[0][0]              \n",
            "__________________________________________________________________________________________________\n",
            "flatten (Flatten)               (None, 8192)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense (Dense)                   (None, 128)          1048704     flatten[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dropout (Dropout)               (None, 128)          0           dense[0][0]                      \n",
            "__________________________________________________________________________________________________\n",
            "dense_1 (Dense)                 (None, 15)           1935        dropout[0][0]                    \n",
            "==================================================================================================\n",
            "Total params: 22,853,423\n",
            "Trainable params: 1,050,639\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1915: UserWarning: `Model.fit_generator` is deprecated and will be removed in a future version. Please use `Model.fit`, which supports generators.\n",
            "  warnings.warn('`Model.fit_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "5/5 [==============================] - 70s 3s/step - loss: 5.4970 - fBetaKeyras: 0.1603 - val_loss: 2.5983 - val_fBetaKeyras: 0.2300\n",
            "Epoch 2/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 2.6428 - fBetaKeyras: 0.2267 - val_loss: 1.9500 - val_fBetaKeyras: 0.2337\n",
            "Epoch 3/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 2.0020 - fBetaKeyras: 0.2461 - val_loss: 1.6560 - val_fBetaKeyras: 0.2214\n",
            "Epoch 4/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 1.4782 - fBetaKeyras: 0.2602 - val_loss: 1.2967 - val_fBetaKeyras: 0.2091\n",
            "Epoch 5/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 1.2055 - fBetaKeyras: 0.2367 - val_loss: 1.1018 - val_fBetaKeyras: 0.2641\n",
            "Epoch 6/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.9254 - fBetaKeyras: 0.2942 - val_loss: 1.1651 - val_fBetaKeyras: 0.2596\n",
            "Epoch 7/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.8792 - fBetaKeyras: 0.3038 - val_loss: 0.9153 - val_fBetaKeyras: 0.1943\n",
            "Epoch 8/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.7869 - fBetaKeyras: 0.2694 - val_loss: 0.7803 - val_fBetaKeyras: 0.2097\n",
            "Epoch 9/200\n",
            "5/5 [==============================] - 1s 165ms/step - loss: 0.6365 - fBetaKeyras: 0.3224 - val_loss: 0.7505 - val_fBetaKeyras: 0.2269\n",
            "Epoch 10/200\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 0.5912 - fBetaKeyras: 0.3062 - val_loss: 0.8075 - val_fBetaKeyras: 0.2314\n",
            "Epoch 11/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.6540 - fBetaKeyras: 0.2991 - val_loss: 0.7349 - val_fBetaKeyras: 0.2186\n",
            "Epoch 12/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.5436 - fBetaKeyras: 0.3414 - val_loss: 0.7161 - val_fBetaKeyras: 0.1997\n",
            "Epoch 13/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.5296 - fBetaKeyras: 0.3296 - val_loss: 0.7049 - val_fBetaKeyras: 0.1973\n",
            "Epoch 14/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.5286 - fBetaKeyras: 0.3077 - val_loss: 0.7135 - val_fBetaKeyras: 0.2170\n",
            "Epoch 15/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.5127 - fBetaKeyras: 0.3595 - val_loss: 0.7813 - val_fBetaKeyras: 0.1784\n",
            "Epoch 16/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.5469 - fBetaKeyras: 0.2827 - val_loss: 0.7280 - val_fBetaKeyras: 0.1801\n",
            "Epoch 17/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.4972 - fBetaKeyras: 0.3263 - val_loss: 0.6822 - val_fBetaKeyras: 0.2084\n",
            "Epoch 18/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.4871 - fBetaKeyras: 0.3108 - val_loss: 0.7098 - val_fBetaKeyras: 0.2095\n",
            "Epoch 19/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.4830 - fBetaKeyras: 0.3450 - val_loss: 0.6890 - val_fBetaKeyras: 0.2132\n",
            "Epoch 20/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.4830 - fBetaKeyras: 0.4255 - val_loss: 0.7058 - val_fBetaKeyras: 0.2418\n",
            "Epoch 21/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.4646 - fBetaKeyras: 0.3896 - val_loss: 0.6848 - val_fBetaKeyras: 0.2024\n",
            "Epoch 22/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.4499 - fBetaKeyras: 0.4099 - val_loss: 0.7234 - val_fBetaKeyras: 0.2210\n",
            "Epoch 23/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.4759 - fBetaKeyras: 0.3832 - val_loss: 0.6770 - val_fBetaKeyras: 0.2197\n",
            "Epoch 24/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.4552 - fBetaKeyras: 0.3770 - val_loss: 0.6927 - val_fBetaKeyras: 0.2268\n",
            "Epoch 25/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.4528 - fBetaKeyras: 0.4165 - val_loss: 0.7202 - val_fBetaKeyras: 0.2453\n",
            "Epoch 26/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.4222 - fBetaKeyras: 0.4521 - val_loss: 0.7369 - val_fBetaKeyras: 0.2116\n",
            "Epoch 27/200\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.4570 - fBetaKeyras: 0.3278 - val_loss: 0.7136 - val_fBetaKeyras: 0.2217\n",
            "Epoch 28/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.4145 - fBetaKeyras: 0.4106 - val_loss: 0.7087 - val_fBetaKeyras: 0.2404\n",
            "Epoch 29/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.4121 - fBetaKeyras: 0.4435 - val_loss: 0.6999 - val_fBetaKeyras: 0.2187\n",
            "Epoch 30/200\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 0.3861 - fBetaKeyras: 0.4220 - val_loss: 0.7434 - val_fBetaKeyras: 0.2239\n",
            "Epoch 31/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.4228 - fBetaKeyras: 0.4513 - val_loss: 0.6935 - val_fBetaKeyras: 0.2298\n",
            "Epoch 32/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.3894 - fBetaKeyras: 0.4620 - val_loss: 0.7170 - val_fBetaKeyras: 0.2172\n",
            "Epoch 33/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.4086 - fBetaKeyras: 0.4329 - val_loss: 0.6990 - val_fBetaKeyras: 0.2342\n",
            "Epoch 34/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.3803 - fBetaKeyras: 0.4863 - val_loss: 0.7020 - val_fBetaKeyras: 0.1853\n",
            "Epoch 35/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.3998 - fBetaKeyras: 0.4374 - val_loss: 0.7431 - val_fBetaKeyras: 0.2114\n",
            "Epoch 36/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.3655 - fBetaKeyras: 0.4858 - val_loss: 0.7233 - val_fBetaKeyras: 0.2052\n",
            "Epoch 37/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.3708 - fBetaKeyras: 0.4429 - val_loss: 0.6855 - val_fBetaKeyras: 0.2423\n",
            "Epoch 38/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.3738 - fBetaKeyras: 0.4763 - val_loss: 0.7022 - val_fBetaKeyras: 0.2536\n",
            "Epoch 39/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.3655 - fBetaKeyras: 0.4834 - val_loss: 0.6988 - val_fBetaKeyras: 0.2537\n",
            "Epoch 40/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.3542 - fBetaKeyras: 0.4960 - val_loss: 0.7034 - val_fBetaKeyras: 0.2175\n",
            "Epoch 41/200\n",
            "5/5 [==============================] - 1s 123ms/step - loss: 0.3289 - fBetaKeyras: 0.5142 - val_loss: 0.8444 - val_fBetaKeyras: 0.2039\n",
            "Epoch 42/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.3852 - fBetaKeyras: 0.4387 - val_loss: 0.7063 - val_fBetaKeyras: 0.2601\n",
            "Epoch 43/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.3450 - fBetaKeyras: 0.5001 - val_loss: 0.7309 - val_fBetaKeyras: 0.2299\n",
            "Epoch 44/200\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 0.3218 - fBetaKeyras: 0.5402 - val_loss: 0.7397 - val_fBetaKeyras: 0.2445\n",
            "Epoch 45/200\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.3340 - fBetaKeyras: 0.5283 - val_loss: 0.7568 - val_fBetaKeyras: 0.2180\n",
            "Epoch 46/200\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.3480 - fBetaKeyras: 0.4960 - val_loss: 0.7315 - val_fBetaKeyras: 0.2488\n",
            "Epoch 47/200\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.3379 - fBetaKeyras: 0.5054 - val_loss: 0.7552 - val_fBetaKeyras: 0.2177\n",
            "Epoch 48/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.3413 - fBetaKeyras: 0.5358 - val_loss: 0.7143 - val_fBetaKeyras: 0.2357\n",
            "Epoch 49/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.3105 - fBetaKeyras: 0.5767 - val_loss: 0.7296 - val_fBetaKeyras: 0.2273\n",
            "Epoch 50/200\n",
            "5/5 [==============================] - 1s 122ms/step - loss: 0.3082 - fBetaKeyras: 0.5541 - val_loss: 0.7464 - val_fBetaKeyras: 0.2462\n",
            "Epoch 51/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.3571 - fBetaKeyras: 0.5196 - val_loss: 0.7224 - val_fBetaKeyras: 0.2371\n",
            "Epoch 52/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.3060 - fBetaKeyras: 0.5326 - val_loss: 0.7154 - val_fBetaKeyras: 0.2390\n",
            "Epoch 53/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.2840 - fBetaKeyras: 0.5699 - val_loss: 0.7602 - val_fBetaKeyras: 0.2202\n",
            "Epoch 54/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.3232 - fBetaKeyras: 0.5481 - val_loss: 0.7421 - val_fBetaKeyras: 0.2309\n",
            "Epoch 55/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.3144 - fBetaKeyras: 0.5483 - val_loss: 0.7231 - val_fBetaKeyras: 0.2387\n",
            "Epoch 56/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.3044 - fBetaKeyras: 0.5633 - val_loss: 0.7014 - val_fBetaKeyras: 0.2756\n",
            "Epoch 57/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.3025 - fBetaKeyras: 0.5406 - val_loss: 0.7042 - val_fBetaKeyras: 0.2559\n",
            "Epoch 58/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.2860 - fBetaKeyras: 0.5776 - val_loss: 0.7748 - val_fBetaKeyras: 0.2094\n",
            "Epoch 59/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.3111 - fBetaKeyras: 0.5521 - val_loss: 0.7718 - val_fBetaKeyras: 0.2126\n",
            "Epoch 60/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.2841 - fBetaKeyras: 0.6215 - val_loss: 0.6994 - val_fBetaKeyras: 0.2628\n",
            "Epoch 61/200\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.2730 - fBetaKeyras: 0.6314 - val_loss: 0.7216 - val_fBetaKeyras: 0.2485\n",
            "Epoch 62/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.2933 - fBetaKeyras: 0.5705 - val_loss: 0.7270 - val_fBetaKeyras: 0.2603\n",
            "Epoch 63/200\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 0.2798 - fBetaKeyras: 0.6015 - val_loss: 0.7252 - val_fBetaKeyras: 0.2500\n",
            "Epoch 64/200\n",
            "5/5 [==============================] - 1s 124ms/step - loss: 0.2576 - fBetaKeyras: 0.6217 - val_loss: 0.7912 - val_fBetaKeyras: 0.2279\n",
            "Epoch 65/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.3057 - fBetaKeyras: 0.5723 - val_loss: 0.7554 - val_fBetaKeyras: 0.2480\n",
            "Epoch 66/200\n",
            "5/5 [==============================] - 1s 147ms/step - loss: 0.2638 - fBetaKeyras: 0.6342 - val_loss: 0.7455 - val_fBetaKeyras: 0.2588\n",
            "Epoch 67/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.2638 - fBetaKeyras: 0.6028 - val_loss: 0.7127 - val_fBetaKeyras: 0.2450\n",
            "Epoch 68/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.2575 - fBetaKeyras: 0.6008 - val_loss: 0.7166 - val_fBetaKeyras: 0.2921\n",
            "Epoch 69/200\n",
            "5/5 [==============================] - 1s 146ms/step - loss: 0.2531 - fBetaKeyras: 0.6816 - val_loss: 0.7316 - val_fBetaKeyras: 0.2729\n",
            "Epoch 70/200\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.2891 - fBetaKeyras: 0.5571 - val_loss: 0.7530 - val_fBetaKeyras: 0.2460\n",
            "Epoch 71/200\n",
            "5/5 [==============================] - 1s 123ms/step - loss: 0.2461 - fBetaKeyras: 0.6141 - val_loss: 0.7717 - val_fBetaKeyras: 0.2964\n",
            "Epoch 72/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.3058 - fBetaKeyras: 0.6235 - val_loss: 0.7317 - val_fBetaKeyras: 0.2387\n",
            "Epoch 73/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.2534 - fBetaKeyras: 0.6138 - val_loss: 0.7353 - val_fBetaKeyras: 0.2472\n",
            "Epoch 74/200\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.2559 - fBetaKeyras: 0.6635 - val_loss: 0.7236 - val_fBetaKeyras: 0.2730\n",
            "Epoch 75/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.2445 - fBetaKeyras: 0.6095 - val_loss: 0.7513 - val_fBetaKeyras: 0.2425\n",
            "Epoch 76/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.2629 - fBetaKeyras: 0.5943 - val_loss: 0.7333 - val_fBetaKeyras: 0.2614\n",
            "Epoch 77/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.2266 - fBetaKeyras: 0.6771 - val_loss: 0.7303 - val_fBetaKeyras: 0.2518\n",
            "Epoch 78/200\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 0.2390 - fBetaKeyras: 0.6550 - val_loss: 0.7950 - val_fBetaKeyras: 0.2208\n",
            "Epoch 79/200\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.3216 - fBetaKeyras: 0.5493 - val_loss: 0.7262 - val_fBetaKeyras: 0.2989\n",
            "Epoch 80/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.2217 - fBetaKeyras: 0.6893 - val_loss: 0.7342 - val_fBetaKeyras: 0.2523\n",
            "Epoch 81/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.2506 - fBetaKeyras: 0.6304 - val_loss: 0.7757 - val_fBetaKeyras: 0.2599\n",
            "Epoch 82/200\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.2880 - fBetaKeyras: 0.6348 - val_loss: 0.7157 - val_fBetaKeyras: 0.2420\n",
            "Epoch 83/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.2293 - fBetaKeyras: 0.6549 - val_loss: 0.7202 - val_fBetaKeyras: 0.2283\n",
            "Epoch 84/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.2363 - fBetaKeyras: 0.6132 - val_loss: 0.7167 - val_fBetaKeyras: 0.2890\n",
            "Epoch 85/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.2487 - fBetaKeyras: 0.6354 - val_loss: 0.7397 - val_fBetaKeyras: 0.2610\n",
            "Epoch 86/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.2244 - fBetaKeyras: 0.6920 - val_loss: 0.7176 - val_fBetaKeyras: 0.2631\n",
            "Epoch 87/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.2308 - fBetaKeyras: 0.6682 - val_loss: 0.8713 - val_fBetaKeyras: 0.2301\n",
            "Epoch 88/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.2868 - fBetaKeyras: 0.6095 - val_loss: 0.8250 - val_fBetaKeyras: 0.3033\n",
            "Epoch 89/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.2947 - fBetaKeyras: 0.6270 - val_loss: 0.7513 - val_fBetaKeyras: 0.2630\n",
            "Epoch 90/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.2239 - fBetaKeyras: 0.6885 - val_loss: 0.7354 - val_fBetaKeyras: 0.2878\n",
            "Epoch 91/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.2135 - fBetaKeyras: 0.6941 - val_loss: 0.7512 - val_fBetaKeyras: 0.2425\n",
            "Epoch 92/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.2039 - fBetaKeyras: 0.6925 - val_loss: 0.7730 - val_fBetaKeyras: 0.2629\n",
            "Epoch 93/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.2511 - fBetaKeyras: 0.6401 - val_loss: 0.7821 - val_fBetaKeyras: 0.2455\n",
            "Epoch 94/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.2397 - fBetaKeyras: 0.6368 - val_loss: 0.7584 - val_fBetaKeyras: 0.2729\n",
            "Epoch 95/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.2264 - fBetaKeyras: 0.6580 - val_loss: 0.7531 - val_fBetaKeyras: 0.2741\n",
            "Epoch 96/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 0.2215 - fBetaKeyras: 0.6682 - val_loss: 0.7481 - val_fBetaKeyras: 0.2720\n",
            "Epoch 97/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 0.2086 - fBetaKeyras: 0.6843 - val_loss: 0.8140 - val_fBetaKeyras: 0.2381\n",
            "Epoch 98/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.2365 - fBetaKeyras: 0.6491 - val_loss: 0.7268 - val_fBetaKeyras: 0.2755\n",
            "Epoch 99/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.2045 - fBetaKeyras: 0.7058 - val_loss: 0.7608 - val_fBetaKeyras: 0.2873\n",
            "Epoch 100/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.2126 - fBetaKeyras: 0.6971 - val_loss: 0.7750 - val_fBetaKeyras: 0.2839\n",
            "Epoch 101/200\n",
            "5/5 [==============================] - 1s 154ms/step - loss: 0.2355 - fBetaKeyras: 0.6934 - val_loss: 0.7481 - val_fBetaKeyras: 0.2637\n",
            "Epoch 102/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.1938 - fBetaKeyras: 0.7299 - val_loss: 0.7719 - val_fBetaKeyras: 0.2966\n",
            "Epoch 103/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.2048 - fBetaKeyras: 0.7173 - val_loss: 0.7655 - val_fBetaKeyras: 0.2784\n",
            "Epoch 104/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.1995 - fBetaKeyras: 0.7043 - val_loss: 0.7603 - val_fBetaKeyras: 0.2609\n",
            "Epoch 105/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.2009 - fBetaKeyras: 0.7106 - val_loss: 0.7757 - val_fBetaKeyras: 0.2919\n",
            "Epoch 106/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.2104 - fBetaKeyras: 0.6988 - val_loss: 0.7878 - val_fBetaKeyras: 0.2829\n",
            "Epoch 107/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.2384 - fBetaKeyras: 0.6805 - val_loss: 0.7589 - val_fBetaKeyras: 0.2710\n",
            "Epoch 108/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.1783 - fBetaKeyras: 0.7585 - val_loss: 0.9472 - val_fBetaKeyras: 0.2993\n",
            "Epoch 109/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.2555 - fBetaKeyras: 0.6522 - val_loss: 0.8035 - val_fBetaKeyras: 0.3142\n",
            "Epoch 110/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.1900 - fBetaKeyras: 0.7291 - val_loss: 0.8904 - val_fBetaKeyras: 0.3015\n",
            "Epoch 111/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 0.2202 - fBetaKeyras: 0.6553 - val_loss: 0.7806 - val_fBetaKeyras: 0.2778\n",
            "Epoch 112/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.1779 - fBetaKeyras: 0.7650 - val_loss: 0.8474 - val_fBetaKeyras: 0.2339\n",
            "Epoch 113/200\n",
            "5/5 [==============================] - 1s 142ms/step - loss: 0.2115 - fBetaKeyras: 0.6840 - val_loss: 0.8017 - val_fBetaKeyras: 0.2351\n",
            "Epoch 114/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.2289 - fBetaKeyras: 0.7246 - val_loss: 0.7623 - val_fBetaKeyras: 0.3101\n",
            "Epoch 115/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.1732 - fBetaKeyras: 0.7586 - val_loss: 0.8846 - val_fBetaKeyras: 0.2297\n",
            "Epoch 116/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.2308 - fBetaKeyras: 0.6908 - val_loss: 0.8323 - val_fBetaKeyras: 0.2978\n",
            "Epoch 117/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.2060 - fBetaKeyras: 0.7128 - val_loss: 0.8217 - val_fBetaKeyras: 0.2782\n",
            "Epoch 118/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.1866 - fBetaKeyras: 0.7341 - val_loss: 0.7882 - val_fBetaKeyras: 0.2833\n",
            "Epoch 119/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1940 - fBetaKeyras: 0.7425 - val_loss: 0.8255 - val_fBetaKeyras: 0.2799\n",
            "Epoch 120/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.1886 - fBetaKeyras: 0.7292 - val_loss: 0.7950 - val_fBetaKeyras: 0.3155\n",
            "Epoch 121/200\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.2106 - fBetaKeyras: 0.7229 - val_loss: 0.8126 - val_fBetaKeyras: 0.3074\n",
            "Epoch 122/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1781 - fBetaKeyras: 0.7496 - val_loss: 0.8320 - val_fBetaKeyras: 0.2602\n",
            "Epoch 123/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.1820 - fBetaKeyras: 0.7406 - val_loss: 0.7899 - val_fBetaKeyras: 0.3288\n",
            "Epoch 124/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1943 - fBetaKeyras: 0.7435 - val_loss: 0.8166 - val_fBetaKeyras: 0.3038\n",
            "Epoch 125/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.1718 - fBetaKeyras: 0.7593 - val_loss: 0.7996 - val_fBetaKeyras: 0.2923\n",
            "Epoch 126/200\n",
            "5/5 [==============================] - 1s 145ms/step - loss: 0.2037 - fBetaKeyras: 0.6862 - val_loss: 0.7588 - val_fBetaKeyras: 0.3203\n",
            "Epoch 127/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.1803 - fBetaKeyras: 0.7577 - val_loss: 0.7832 - val_fBetaKeyras: 0.2896\n",
            "Epoch 128/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.1616 - fBetaKeyras: 0.7863 - val_loss: 0.8712 - val_fBetaKeyras: 0.2906\n",
            "Epoch 129/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.1831 - fBetaKeyras: 0.7460 - val_loss: 0.8760 - val_fBetaKeyras: 0.2445\n",
            "Epoch 130/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1972 - fBetaKeyras: 0.7506 - val_loss: 0.7990 - val_fBetaKeyras: 0.3043\n",
            "Epoch 131/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.1857 - fBetaKeyras: 0.7867 - val_loss: 0.8483 - val_fBetaKeyras: 0.2600\n",
            "Epoch 132/200\n",
            "5/5 [==============================] - 1s 143ms/step - loss: 0.1820 - fBetaKeyras: 0.7565 - val_loss: 0.8170 - val_fBetaKeyras: 0.3277\n",
            "Epoch 133/200\n",
            "5/5 [==============================] - 1s 158ms/step - loss: 0.1871 - fBetaKeyras: 0.7599 - val_loss: 0.8269 - val_fBetaKeyras: 0.2930\n",
            "Epoch 134/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.1730 - fBetaKeyras: 0.7687 - val_loss: 0.8233 - val_fBetaKeyras: 0.3012\n",
            "Epoch 135/200\n",
            "5/5 [==============================] - 1s 141ms/step - loss: 0.1671 - fBetaKeyras: 0.8054 - val_loss: 0.9158 - val_fBetaKeyras: 0.2609\n",
            "Epoch 136/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.1797 - fBetaKeyras: 0.7443 - val_loss: 0.8047 - val_fBetaKeyras: 0.2888\n",
            "Epoch 137/200\n",
            "5/5 [==============================] - 1s 152ms/step - loss: 0.1443 - fBetaKeyras: 0.7899 - val_loss: 0.8516 - val_fBetaKeyras: 0.2869\n",
            "Epoch 138/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.1595 - fBetaKeyras: 0.7854 - val_loss: 0.8795 - val_fBetaKeyras: 0.2900\n",
            "Epoch 139/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.1819 - fBetaKeyras: 0.7799 - val_loss: 0.8684 - val_fBetaKeyras: 0.3244\n",
            "Epoch 140/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.1666 - fBetaKeyras: 0.7865 - val_loss: 0.8604 - val_fBetaKeyras: 0.2791\n",
            "Epoch 141/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.1673 - fBetaKeyras: 0.7849 - val_loss: 0.8931 - val_fBetaKeyras: 0.3006\n",
            "Epoch 142/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 0.1806 - fBetaKeyras: 0.7533 - val_loss: 0.8280 - val_fBetaKeyras: 0.2912\n",
            "Epoch 143/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.1524 - fBetaKeyras: 0.8083 - val_loss: 0.8222 - val_fBetaKeyras: 0.2986\n",
            "Epoch 144/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.1638 - fBetaKeyras: 0.7836 - val_loss: 0.8501 - val_fBetaKeyras: 0.3048\n",
            "Epoch 145/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.1475 - fBetaKeyras: 0.8116 - val_loss: 0.9043 - val_fBetaKeyras: 0.2427\n",
            "Epoch 146/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.2238 - fBetaKeyras: 0.7161 - val_loss: 0.8282 - val_fBetaKeyras: 0.2929\n",
            "Epoch 147/200\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.1414 - fBetaKeyras: 0.8111 - val_loss: 0.8833 - val_fBetaKeyras: 0.3057\n",
            "Epoch 148/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.1566 - fBetaKeyras: 0.7781 - val_loss: 0.9284 - val_fBetaKeyras: 0.3285\n",
            "Epoch 149/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.2163 - fBetaKeyras: 0.7360 - val_loss: 0.8429 - val_fBetaKeyras: 0.2851\n",
            "Epoch 150/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.1356 - fBetaKeyras: 0.8152 - val_loss: 0.8373 - val_fBetaKeyras: 0.3012\n",
            "Epoch 151/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.1630 - fBetaKeyras: 0.7991 - val_loss: 0.9475 - val_fBetaKeyras: 0.3033\n",
            "Epoch 152/200\n",
            "5/5 [==============================] - 1s 139ms/step - loss: 0.1838 - fBetaKeyras: 0.7684 - val_loss: 0.8522 - val_fBetaKeyras: 0.2914\n",
            "Epoch 153/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1239 - fBetaKeyras: 0.8446 - val_loss: 0.8645 - val_fBetaKeyras: 0.2812\n",
            "Epoch 154/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.1479 - fBetaKeyras: 0.7958 - val_loss: 0.8817 - val_fBetaKeyras: 0.3001\n",
            "Epoch 155/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.1366 - fBetaKeyras: 0.8041 - val_loss: 0.9858 - val_fBetaKeyras: 0.2848\n",
            "Epoch 156/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 0.1886 - fBetaKeyras: 0.7638 - val_loss: 0.9589 - val_fBetaKeyras: 0.3182\n",
            "Epoch 157/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.1855 - fBetaKeyras: 0.7723 - val_loss: 0.9909 - val_fBetaKeyras: 0.3349\n",
            "Epoch 158/200\n",
            "5/5 [==============================] - 1s 155ms/step - loss: 0.1481 - fBetaKeyras: 0.8267 - val_loss: 0.8865 - val_fBetaKeyras: 0.2937\n",
            "Epoch 159/200\n",
            "5/5 [==============================] - 1s 157ms/step - loss: 0.1370 - fBetaKeyras: 0.8364 - val_loss: 0.9033 - val_fBetaKeyras: 0.3031\n",
            "Epoch 160/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.1534 - fBetaKeyras: 0.8091 - val_loss: 0.8615 - val_fBetaKeyras: 0.2838\n",
            "Epoch 161/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1406 - fBetaKeyras: 0.8204 - val_loss: 0.9044 - val_fBetaKeyras: 0.3434\n",
            "Epoch 162/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.1792 - fBetaKeyras: 0.7939 - val_loss: 0.8491 - val_fBetaKeyras: 0.2851\n",
            "Epoch 163/200\n",
            "5/5 [==============================] - 1s 138ms/step - loss: 0.1232 - fBetaKeyras: 0.8488 - val_loss: 0.8919 - val_fBetaKeyras: 0.2984\n",
            "Epoch 164/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.1218 - fBetaKeyras: 0.8381 - val_loss: 0.8752 - val_fBetaKeyras: 0.3058\n",
            "Epoch 165/200\n",
            "5/5 [==============================] - 1s 125ms/step - loss: 0.1283 - fBetaKeyras: 0.8271 - val_loss: 0.9108 - val_fBetaKeyras: 0.2688\n",
            "Epoch 166/200\n",
            "5/5 [==============================] - 1s 136ms/step - loss: 0.2059 - fBetaKeyras: 0.7599 - val_loss: 0.8754 - val_fBetaKeyras: 0.3068\n",
            "Epoch 167/200\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.1328 - fBetaKeyras: 0.8322 - val_loss: 0.9243 - val_fBetaKeyras: 0.2927\n",
            "Epoch 168/200\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.1401 - fBetaKeyras: 0.8268 - val_loss: 0.8926 - val_fBetaKeyras: 0.3060\n",
            "Epoch 169/200\n",
            "5/5 [==============================] - 1s 151ms/step - loss: 0.1552 - fBetaKeyras: 0.8405 - val_loss: 0.8297 - val_fBetaKeyras: 0.3365\n",
            "Epoch 170/200\n",
            "5/5 [==============================] - 1s 137ms/step - loss: 0.1440 - fBetaKeyras: 0.8218 - val_loss: 0.8603 - val_fBetaKeyras: 0.3101\n",
            "Epoch 171/200\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 0.1268 - fBetaKeyras: 0.8443 - val_loss: 0.9333 - val_fBetaKeyras: 0.3106\n",
            "Epoch 172/200\n",
            "5/5 [==============================] - 1s 150ms/step - loss: 0.1548 - fBetaKeyras: 0.8381 - val_loss: 0.9396 - val_fBetaKeyras: 0.2950\n",
            "Epoch 173/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1385 - fBetaKeyras: 0.8450 - val_loss: 0.8974 - val_fBetaKeyras: 0.3104\n",
            "Epoch 174/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.1274 - fBetaKeyras: 0.8419 - val_loss: 0.8990 - val_fBetaKeyras: 0.2876\n",
            "Epoch 175/200\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.1311 - fBetaKeyras: 0.8301 - val_loss: 0.9549 - val_fBetaKeyras: 0.2805\n",
            "Epoch 176/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.1609 - fBetaKeyras: 0.8034 - val_loss: 0.8609 - val_fBetaKeyras: 0.3535\n",
            "Epoch 177/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.1289 - fBetaKeyras: 0.8518 - val_loss: 0.9386 - val_fBetaKeyras: 0.2757\n",
            "Epoch 178/200\n",
            "5/5 [==============================] - 1s 156ms/step - loss: 0.1408 - fBetaKeyras: 0.8537 - val_loss: 0.8667 - val_fBetaKeyras: 0.2920\n",
            "Epoch 179/200\n",
            "5/5 [==============================] - 1s 140ms/step - loss: 0.1203 - fBetaKeyras: 0.8486 - val_loss: 0.9137 - val_fBetaKeyras: 0.2954\n",
            "Epoch 180/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.1743 - fBetaKeyras: 0.7470 - val_loss: 0.8510 - val_fBetaKeyras: 0.3077\n",
            "Epoch 181/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.1261 - fBetaKeyras: 0.8631 - val_loss: 0.8991 - val_fBetaKeyras: 0.3024\n",
            "Epoch 182/200\n",
            "5/5 [==============================] - 1s 129ms/step - loss: 0.1128 - fBetaKeyras: 0.8570 - val_loss: 0.9133 - val_fBetaKeyras: 0.2959\n",
            "Epoch 183/200\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.1046 - fBetaKeyras: 0.8758 - val_loss: 0.9240 - val_fBetaKeyras: 0.3042\n",
            "Epoch 184/200\n",
            "5/5 [==============================] - 1s 128ms/step - loss: 0.1287 - fBetaKeyras: 0.8307 - val_loss: 0.9463 - val_fBetaKeyras: 0.3076\n",
            "Epoch 185/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1638 - fBetaKeyras: 0.8194 - val_loss: 0.9097 - val_fBetaKeyras: 0.2892\n",
            "Epoch 186/200\n",
            "5/5 [==============================] - 1s 148ms/step - loss: 0.1204 - fBetaKeyras: 0.8321 - val_loss: 0.9328 - val_fBetaKeyras: 0.3001\n",
            "Epoch 187/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.1081 - fBetaKeyras: 0.8718 - val_loss: 0.9338 - val_fBetaKeyras: 0.2732\n",
            "Epoch 188/200\n",
            "5/5 [==============================] - 1s 126ms/step - loss: 0.1135 - fBetaKeyras: 0.8564 - val_loss: 0.9826 - val_fBetaKeyras: 0.2400\n",
            "Epoch 189/200\n",
            "5/5 [==============================] - 1s 133ms/step - loss: 0.1701 - fBetaKeyras: 0.8147 - val_loss: 0.8967 - val_fBetaKeyras: 0.2862\n",
            "Epoch 190/200\n",
            "5/5 [==============================] - 1s 153ms/step - loss: 0.1603 - fBetaKeyras: 0.8336 - val_loss: 0.9170 - val_fBetaKeyras: 0.3063\n",
            "Epoch 191/200\n",
            "5/5 [==============================] - 1s 132ms/step - loss: 0.1066 - fBetaKeyras: 0.8731 - val_loss: 0.9140 - val_fBetaKeyras: 0.2851\n",
            "Epoch 192/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1080 - fBetaKeyras: 0.8639 - val_loss: 0.9341 - val_fBetaKeyras: 0.2988\n",
            "Epoch 193/200\n",
            "5/5 [==============================] - 1s 130ms/step - loss: 0.1477 - fBetaKeyras: 0.8250 - val_loss: 1.0178 - val_fBetaKeyras: 0.2396\n",
            "Epoch 194/200\n",
            "5/5 [==============================] - 1s 149ms/step - loss: 0.1519 - fBetaKeyras: 0.7595 - val_loss: 0.9388 - val_fBetaKeyras: 0.2945\n",
            "Epoch 195/200\n",
            "5/5 [==============================] - 1s 131ms/step - loss: 0.1059 - fBetaKeyras: 0.8616 - val_loss: 0.9251 - val_fBetaKeyras: 0.3002\n",
            "Epoch 196/200\n",
            "5/5 [==============================] - 1s 134ms/step - loss: 0.0991 - fBetaKeyras: 0.8879 - val_loss: 0.9524 - val_fBetaKeyras: 0.2771\n",
            "Epoch 197/200\n",
            "5/5 [==============================] - 1s 127ms/step - loss: 0.1050 - fBetaKeyras: 0.8643 - val_loss: 1.0619 - val_fBetaKeyras: 0.3001\n",
            "Epoch 198/200\n",
            "5/5 [==============================] - 1s 124ms/step - loss: 0.1601 - fBetaKeyras: 0.7922 - val_loss: 0.8950 - val_fBetaKeyras: 0.3022\n",
            "Epoch 199/200\n",
            "5/5 [==============================] - 1s 135ms/step - loss: 0.1334 - fBetaKeyras: 0.8387 - val_loss: 0.8807 - val_fBetaKeyras: 0.3074\n",
            "Epoch 200/200\n",
            "5/5 [==============================] - 1s 124ms/step - loss: 0.1106 - fBetaKeyras: 0.8817 - val_loss: 0.9274 - val_fBetaKeyras: 0.3137\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1948: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 68ms/step - loss: 0.9274 - fBetaKeyras: 0.3136\n",
            "> loss=0.927, fbeta=0.314\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 576x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "J6clzGQ_Xlgm",
        "outputId": "88d76ecf-7ee9-4515-97d0-e52923ff6954"
      },
      "source": [
        "#Inicializacao do modelo INCEPTIONV3, treinamento COM DATA AUGMENTATION e avaliacao do resultado (com um dropout da camada convolucional baixado a 0.1)\n",
        "verbose=1\n",
        "\n",
        "#Multiplica o numero de etapa para finalizar uma epoca (se espera que todas as imagens foram lidas a cada epoca para aproveitar ao maximo\n",
        "# do jogo de treinamento).\n",
        "# Ao final de cada etapa se executa o calculo da funcao de perda sobre o batch de imagem, aplicando a backpropagacao do erro para ajustar os pesos, \n",
        "# antes de iniciar a proxima etapa.\n",
        "# Como a tecnica de data augmentation, permite ao generator do batch size de treinamento de estar em teoria infinito, se multiplica o tamanho do\n",
        "# iterator de treinamento (igual ao trunc por encima do total imagem do jogo dividido pelo batch size) pelo parametro abaixo, para tentar aproveitar\n",
        "# do dataaumentation sobre todo o jogo de imagem original.\n",
        "# Por padrao, se informa este parametro com o numero de tecnicas de data augmentation, indicado no objeto generator do jogo de treinamento.\n",
        "# Nao precisa augmentar o numero de etapa sobre o jogo de validacao, porque nao se aplica a tecnica de date augmentation sobre este jogo.\n",
        "numMultStepEpoc=3\n",
        "#OBS: Nao funciona conforme esperado e precisa deixar o parametro a 1 senao tem o erro \"WARNING:tensorflow:Your input ran out of data; interrupting training.\"\n",
        "# Pesquisa no Internet indicando que se aproveita do data augmenetion de uma epoca para outra (entretanto aumentar param epoca em vez param step), \n",
        "# mas fica a duvida se realmente a cada epoca, o generator gera a mesma quantidade de imagem com transformacao diferente\n",
        "# https://stackoverflow.com/questions/61918148/input-ran-out-of-data-interrupting-training \n",
        "# https://stackoverflow.com/questions/63713904/data-augmentation-with-keras-running-out-of-data\n",
        "#Under the hood it returns a tf.data.Dataset which does not run indefinitely. The transformations are applied randomly. It's not new images that are created indefinitely. \n",
        "#But that's just how keras is made. In previous versions you didn't have to specify these arguments\n",
        "# https://keras.io/api/preprocessing/image/#imagedatagenerator-class\n",
        "#-> Param a usar para multiplicar o numero de epoca em vez do numero de step\n",
        "\n",
        "# Objeto Generator de Keyras com preprocessamento usando os valores centralizacao do jogo de dados de IMAGENET\n",
        "# No caso do generator usado coom o jogo de treinamento, se aplica distorcoes da foto para aplicar a tecnica de data augmentatin\n",
        "#Parametros usados no livro Deep Learning with Python\n",
        "dictArgDataAugm = {'rotation_range':40, 'width_shift_range':0.2, 'height_shift_range':0.2, 'shear_range':0.2, \\\n",
        "                   'zoom_range':0.2, 'horizontal_flip':True, 'fill_mode':'nearest'}\n",
        "dataGenTrain = ImageDataGenerator(featurewise_center=True, **dictArgDataAugm)\n",
        "\n",
        "\n",
        "dataGenTest = ImageDataGenerator(featurewise_center=True)\n",
        "# Definicao da media do jogo de dados Imagenet para centralizacao das fotos como esperado pelo modelo VGG16 treinado sobre este jogo\n",
        "dataGenTrain.mean = [123.68, 116.779, 103.939]\n",
        "dataGenTest.mean = [123.68, 116.779, 103.939]\n",
        "# Criacao dos objetos de iteracao do jogo de treinamento e de teste para gerar batch das imagens a cada epoca do treinamento\n",
        "iterTrain = dataGenTrain.flow(XTrain, YTrain, batch_size=128)\n",
        "iterTest = dataGenTest.flow(XTest, YTest, batch_size=128)\n",
        "\n",
        "# O resto do codigo esta parecido ao de treinamento do modelo VGG base e poderia estar passado em uma funcao \n",
        "# (menos o numero de epoca que pode estar menor que para o treinamento base, visto que se treina so a parte de classificacao)\n",
        "\n",
        "# Definicao do modelo INCEPTIONV3\n",
        "# Aplicacao da tecnica de machine learning ja que o treinamento vai se limitar a parte de classificacao (camadas densamente\n",
        "# conectadas), aproveitando na parte de selecao das features (camadas convolucionais e de pooling) dos pesos ja treinados \n",
        "# com o jogo de dados Imagenet.\n",
        "model = defineModelInceptionV3((sizeImg, sizeImg, 3), countClasses)\n",
        "# Treinamento (fit) do modelo\n",
        "histTrain = model.fit(iterTrain, steps_per_epoch=len(iterTrain), \\\n",
        "                                validation_data=iterTest, validation_steps=len(iterTest), epochs=100*numMultStepEpoc, verbose=verbose)\n",
        "#OBS: fit_generator esta depreciado. Se usa agora fit que foi adequado para funcionar com generator para os parametros de jogo de treinamento/test.\n",
        "# Evaluacao do modelo\n",
        "loss, fBeta = model.evaluate_generator(iterTest, steps=len(iterTest), verbose=verbose)\n",
        "print('> loss=%.3f, fbeta=%.3f' % (loss, fBeta))\n",
        "# Figura com as curvas de treinamento\n",
        "figureTrain(histTrain, 'InceptionV3DataAugm')\n"
      ],
      "id": "J6clzGQ_Xlgm",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"model_11\"\n",
            "__________________________________________________________________________________________________\n",
            "Layer (type)                    Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            "input_13 (InputLayer)           [(None, 128, 128, 3) 0                                            \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_752 (Conv2D)             (None, 63, 63, 32)   864         input_13[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_752 (BatchN (None, 63, 63, 32)   96          conv2d_752[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_752 (Activation)     (None, 63, 63, 32)   0           batch_normalization_752[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_753 (Conv2D)             (None, 61, 61, 32)   9216        activation_752[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_753 (BatchN (None, 61, 61, 32)   96          conv2d_753[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_753 (Activation)     (None, 61, 61, 32)   0           batch_normalization_753[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_754 (Conv2D)             (None, 61, 61, 64)   18432       activation_753[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_754 (BatchN (None, 61, 61, 64)   192         conv2d_754[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_754 (Activation)     (None, 61, 61, 64)   0           batch_normalization_754[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_32 (MaxPooling2D) (None, 30, 30, 64)   0           activation_754[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_755 (Conv2D)             (None, 30, 30, 80)   5120        max_pooling2d_32[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_755 (BatchN (None, 30, 30, 80)   240         conv2d_755[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_755 (Activation)     (None, 30, 30, 80)   0           batch_normalization_755[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_756 (Conv2D)             (None, 28, 28, 192)  138240      activation_755[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_756 (BatchN (None, 28, 28, 192)  576         conv2d_756[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_756 (Activation)     (None, 28, 28, 192)  0           batch_normalization_756[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_33 (MaxPooling2D) (None, 13, 13, 192)  0           activation_756[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_760 (Conv2D)             (None, 13, 13, 64)   12288       max_pooling2d_33[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_760 (BatchN (None, 13, 13, 64)   192         conv2d_760[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_760 (Activation)     (None, 13, 13, 64)   0           batch_normalization_760[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_758 (Conv2D)             (None, 13, 13, 48)   9216        max_pooling2d_33[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_761 (Conv2D)             (None, 13, 13, 96)   55296       activation_760[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_758 (BatchN (None, 13, 13, 48)   144         conv2d_758[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_761 (BatchN (None, 13, 13, 96)   288         conv2d_761[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_758 (Activation)     (None, 13, 13, 48)   0           batch_normalization_758[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_761 (Activation)     (None, 13, 13, 96)   0           batch_normalization_761[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_72 (AveragePo (None, 13, 13, 192)  0           max_pooling2d_33[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_757 (Conv2D)             (None, 13, 13, 64)   12288       max_pooling2d_33[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_759 (Conv2D)             (None, 13, 13, 64)   76800       activation_758[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_762 (Conv2D)             (None, 13, 13, 96)   82944       activation_761[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_763 (Conv2D)             (None, 13, 13, 32)   6144        average_pooling2d_72[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_757 (BatchN (None, 13, 13, 64)   192         conv2d_757[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_759 (BatchN (None, 13, 13, 64)   192         conv2d_759[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_762 (BatchN (None, 13, 13, 96)   288         conv2d_762[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_763 (BatchN (None, 13, 13, 32)   96          conv2d_763[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_757 (Activation)     (None, 13, 13, 64)   0           batch_normalization_757[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_759 (Activation)     (None, 13, 13, 64)   0           batch_normalization_759[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_762 (Activation)     (None, 13, 13, 96)   0           batch_normalization_762[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_763 (Activation)     (None, 13, 13, 32)   0           batch_normalization_763[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed0 (Concatenate)            (None, 13, 13, 256)  0           activation_757[0][0]             \n",
            "                                                                 activation_759[0][0]             \n",
            "                                                                 activation_762[0][0]             \n",
            "                                                                 activation_763[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_767 (Conv2D)             (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_767 (BatchN (None, 13, 13, 64)   192         conv2d_767[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_767 (Activation)     (None, 13, 13, 64)   0           batch_normalization_767[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_765 (Conv2D)             (None, 13, 13, 48)   12288       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_768 (Conv2D)             (None, 13, 13, 96)   55296       activation_767[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_765 (BatchN (None, 13, 13, 48)   144         conv2d_765[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_768 (BatchN (None, 13, 13, 96)   288         conv2d_768[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_765 (Activation)     (None, 13, 13, 48)   0           batch_normalization_765[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_768 (Activation)     (None, 13, 13, 96)   0           batch_normalization_768[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_73 (AveragePo (None, 13, 13, 256)  0           mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_764 (Conv2D)             (None, 13, 13, 64)   16384       mixed0[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_766 (Conv2D)             (None, 13, 13, 64)   76800       activation_765[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_769 (Conv2D)             (None, 13, 13, 96)   82944       activation_768[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_770 (Conv2D)             (None, 13, 13, 64)   16384       average_pooling2d_73[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_764 (BatchN (None, 13, 13, 64)   192         conv2d_764[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_766 (BatchN (None, 13, 13, 64)   192         conv2d_766[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_769 (BatchN (None, 13, 13, 96)   288         conv2d_769[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_770 (BatchN (None, 13, 13, 64)   192         conv2d_770[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_764 (Activation)     (None, 13, 13, 64)   0           batch_normalization_764[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_766 (Activation)     (None, 13, 13, 64)   0           batch_normalization_766[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_769 (Activation)     (None, 13, 13, 96)   0           batch_normalization_769[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_770 (Activation)     (None, 13, 13, 64)   0           batch_normalization_770[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed1 (Concatenate)            (None, 13, 13, 288)  0           activation_764[0][0]             \n",
            "                                                                 activation_766[0][0]             \n",
            "                                                                 activation_769[0][0]             \n",
            "                                                                 activation_770[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_774 (Conv2D)             (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_774 (BatchN (None, 13, 13, 64)   192         conv2d_774[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_774 (Activation)     (None, 13, 13, 64)   0           batch_normalization_774[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_772 (Conv2D)             (None, 13, 13, 48)   13824       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_775 (Conv2D)             (None, 13, 13, 96)   55296       activation_774[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_772 (BatchN (None, 13, 13, 48)   144         conv2d_772[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_775 (BatchN (None, 13, 13, 96)   288         conv2d_775[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_772 (Activation)     (None, 13, 13, 48)   0           batch_normalization_772[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_775 (Activation)     (None, 13, 13, 96)   0           batch_normalization_775[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_74 (AveragePo (None, 13, 13, 288)  0           mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_771 (Conv2D)             (None, 13, 13, 64)   18432       mixed1[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_773 (Conv2D)             (None, 13, 13, 64)   76800       activation_772[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_776 (Conv2D)             (None, 13, 13, 96)   82944       activation_775[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_777 (Conv2D)             (None, 13, 13, 64)   18432       average_pooling2d_74[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_771 (BatchN (None, 13, 13, 64)   192         conv2d_771[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_773 (BatchN (None, 13, 13, 64)   192         conv2d_773[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_776 (BatchN (None, 13, 13, 96)   288         conv2d_776[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_777 (BatchN (None, 13, 13, 64)   192         conv2d_777[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_771 (Activation)     (None, 13, 13, 64)   0           batch_normalization_771[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_773 (Activation)     (None, 13, 13, 64)   0           batch_normalization_773[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_776 (Activation)     (None, 13, 13, 96)   0           batch_normalization_776[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_777 (Activation)     (None, 13, 13, 64)   0           batch_normalization_777[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed2 (Concatenate)            (None, 13, 13, 288)  0           activation_771[0][0]             \n",
            "                                                                 activation_773[0][0]             \n",
            "                                                                 activation_776[0][0]             \n",
            "                                                                 activation_777[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_779 (Conv2D)             (None, 13, 13, 64)   18432       mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_779 (BatchN (None, 13, 13, 64)   192         conv2d_779[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_779 (Activation)     (None, 13, 13, 64)   0           batch_normalization_779[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_780 (Conv2D)             (None, 13, 13, 96)   55296       activation_779[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_780 (BatchN (None, 13, 13, 96)   288         conv2d_780[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_780 (Activation)     (None, 13, 13, 96)   0           batch_normalization_780[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_778 (Conv2D)             (None, 6, 6, 384)    995328      mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_781 (Conv2D)             (None, 6, 6, 96)     82944       activation_780[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_778 (BatchN (None, 6, 6, 384)    1152        conv2d_778[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_781 (BatchN (None, 6, 6, 96)     288         conv2d_781[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_778 (Activation)     (None, 6, 6, 384)    0           batch_normalization_778[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_781 (Activation)     (None, 6, 6, 96)     0           batch_normalization_781[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_34 (MaxPooling2D) (None, 6, 6, 288)    0           mixed2[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed3 (Concatenate)            (None, 6, 6, 768)    0           activation_778[0][0]             \n",
            "                                                                 activation_781[0][0]             \n",
            "                                                                 max_pooling2d_34[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_786 (Conv2D)             (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_786 (BatchN (None, 6, 6, 128)    384         conv2d_786[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_786 (Activation)     (None, 6, 6, 128)    0           batch_normalization_786[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_787 (Conv2D)             (None, 6, 6, 128)    114688      activation_786[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_787 (BatchN (None, 6, 6, 128)    384         conv2d_787[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_787 (Activation)     (None, 6, 6, 128)    0           batch_normalization_787[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_783 (Conv2D)             (None, 6, 6, 128)    98304       mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_788 (Conv2D)             (None, 6, 6, 128)    114688      activation_787[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_783 (BatchN (None, 6, 6, 128)    384         conv2d_783[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_788 (BatchN (None, 6, 6, 128)    384         conv2d_788[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_783 (Activation)     (None, 6, 6, 128)    0           batch_normalization_783[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_788 (Activation)     (None, 6, 6, 128)    0           batch_normalization_788[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_784 (Conv2D)             (None, 6, 6, 128)    114688      activation_783[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_789 (Conv2D)             (None, 6, 6, 128)    114688      activation_788[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_784 (BatchN (None, 6, 6, 128)    384         conv2d_784[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_789 (BatchN (None, 6, 6, 128)    384         conv2d_789[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_784 (Activation)     (None, 6, 6, 128)    0           batch_normalization_784[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_789 (Activation)     (None, 6, 6, 128)    0           batch_normalization_789[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_75 (AveragePo (None, 6, 6, 768)    0           mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_782 (Conv2D)             (None, 6, 6, 192)    147456      mixed3[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_785 (Conv2D)             (None, 6, 6, 192)    172032      activation_784[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_790 (Conv2D)             (None, 6, 6, 192)    172032      activation_789[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_791 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_75[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_782 (BatchN (None, 6, 6, 192)    576         conv2d_782[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_785 (BatchN (None, 6, 6, 192)    576         conv2d_785[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_790 (BatchN (None, 6, 6, 192)    576         conv2d_790[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_791 (BatchN (None, 6, 6, 192)    576         conv2d_791[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_782 (Activation)     (None, 6, 6, 192)    0           batch_normalization_782[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_785 (Activation)     (None, 6, 6, 192)    0           batch_normalization_785[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_790 (Activation)     (None, 6, 6, 192)    0           batch_normalization_790[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_791 (Activation)     (None, 6, 6, 192)    0           batch_normalization_791[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed4 (Concatenate)            (None, 6, 6, 768)    0           activation_782[0][0]             \n",
            "                                                                 activation_785[0][0]             \n",
            "                                                                 activation_790[0][0]             \n",
            "                                                                 activation_791[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_796 (Conv2D)             (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_796 (BatchN (None, 6, 6, 160)    480         conv2d_796[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_796 (Activation)     (None, 6, 6, 160)    0           batch_normalization_796[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_797 (Conv2D)             (None, 6, 6, 160)    179200      activation_796[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_797 (BatchN (None, 6, 6, 160)    480         conv2d_797[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_797 (Activation)     (None, 6, 6, 160)    0           batch_normalization_797[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_793 (Conv2D)             (None, 6, 6, 160)    122880      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_798 (Conv2D)             (None, 6, 6, 160)    179200      activation_797[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_793 (BatchN (None, 6, 6, 160)    480         conv2d_793[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_798 (BatchN (None, 6, 6, 160)    480         conv2d_798[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_793 (Activation)     (None, 6, 6, 160)    0           batch_normalization_793[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_798 (Activation)     (None, 6, 6, 160)    0           batch_normalization_798[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_794 (Conv2D)             (None, 6, 6, 160)    179200      activation_793[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_799 (Conv2D)             (None, 6, 6, 160)    179200      activation_798[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_794 (BatchN (None, 6, 6, 160)    480         conv2d_794[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_799 (BatchN (None, 6, 6, 160)    480         conv2d_799[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_794 (Activation)     (None, 6, 6, 160)    0           batch_normalization_794[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_799 (Activation)     (None, 6, 6, 160)    0           batch_normalization_799[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_76 (AveragePo (None, 6, 6, 768)    0           mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_792 (Conv2D)             (None, 6, 6, 192)    147456      mixed4[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_795 (Conv2D)             (None, 6, 6, 192)    215040      activation_794[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_800 (Conv2D)             (None, 6, 6, 192)    215040      activation_799[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_801 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_76[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_792 (BatchN (None, 6, 6, 192)    576         conv2d_792[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_795 (BatchN (None, 6, 6, 192)    576         conv2d_795[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_800 (BatchN (None, 6, 6, 192)    576         conv2d_800[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_801 (BatchN (None, 6, 6, 192)    576         conv2d_801[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_792 (Activation)     (None, 6, 6, 192)    0           batch_normalization_792[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_795 (Activation)     (None, 6, 6, 192)    0           batch_normalization_795[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_800 (Activation)     (None, 6, 6, 192)    0           batch_normalization_800[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_801 (Activation)     (None, 6, 6, 192)    0           batch_normalization_801[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed5 (Concatenate)            (None, 6, 6, 768)    0           activation_792[0][0]             \n",
            "                                                                 activation_795[0][0]             \n",
            "                                                                 activation_800[0][0]             \n",
            "                                                                 activation_801[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_806 (Conv2D)             (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_806 (BatchN (None, 6, 6, 160)    480         conv2d_806[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_806 (Activation)     (None, 6, 6, 160)    0           batch_normalization_806[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_807 (Conv2D)             (None, 6, 6, 160)    179200      activation_806[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_807 (BatchN (None, 6, 6, 160)    480         conv2d_807[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_807 (Activation)     (None, 6, 6, 160)    0           batch_normalization_807[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_803 (Conv2D)             (None, 6, 6, 160)    122880      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_808 (Conv2D)             (None, 6, 6, 160)    179200      activation_807[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_803 (BatchN (None, 6, 6, 160)    480         conv2d_803[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_808 (BatchN (None, 6, 6, 160)    480         conv2d_808[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_803 (Activation)     (None, 6, 6, 160)    0           batch_normalization_803[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_808 (Activation)     (None, 6, 6, 160)    0           batch_normalization_808[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_804 (Conv2D)             (None, 6, 6, 160)    179200      activation_803[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_809 (Conv2D)             (None, 6, 6, 160)    179200      activation_808[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_804 (BatchN (None, 6, 6, 160)    480         conv2d_804[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_809 (BatchN (None, 6, 6, 160)    480         conv2d_809[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_804 (Activation)     (None, 6, 6, 160)    0           batch_normalization_804[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_809 (Activation)     (None, 6, 6, 160)    0           batch_normalization_809[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_77 (AveragePo (None, 6, 6, 768)    0           mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_802 (Conv2D)             (None, 6, 6, 192)    147456      mixed5[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_805 (Conv2D)             (None, 6, 6, 192)    215040      activation_804[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_810 (Conv2D)             (None, 6, 6, 192)    215040      activation_809[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_811 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_77[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_802 (BatchN (None, 6, 6, 192)    576         conv2d_802[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_805 (BatchN (None, 6, 6, 192)    576         conv2d_805[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_810 (BatchN (None, 6, 6, 192)    576         conv2d_810[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_811 (BatchN (None, 6, 6, 192)    576         conv2d_811[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_802 (Activation)     (None, 6, 6, 192)    0           batch_normalization_802[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_805 (Activation)     (None, 6, 6, 192)    0           batch_normalization_805[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_810 (Activation)     (None, 6, 6, 192)    0           batch_normalization_810[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_811 (Activation)     (None, 6, 6, 192)    0           batch_normalization_811[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed6 (Concatenate)            (None, 6, 6, 768)    0           activation_802[0][0]             \n",
            "                                                                 activation_805[0][0]             \n",
            "                                                                 activation_810[0][0]             \n",
            "                                                                 activation_811[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_816 (Conv2D)             (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_816 (BatchN (None, 6, 6, 192)    576         conv2d_816[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_816 (Activation)     (None, 6, 6, 192)    0           batch_normalization_816[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_817 (Conv2D)             (None, 6, 6, 192)    258048      activation_816[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_817 (BatchN (None, 6, 6, 192)    576         conv2d_817[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_817 (Activation)     (None, 6, 6, 192)    0           batch_normalization_817[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_813 (Conv2D)             (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_818 (Conv2D)             (None, 6, 6, 192)    258048      activation_817[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_813 (BatchN (None, 6, 6, 192)    576         conv2d_813[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_818 (BatchN (None, 6, 6, 192)    576         conv2d_818[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_813 (Activation)     (None, 6, 6, 192)    0           batch_normalization_813[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_818 (Activation)     (None, 6, 6, 192)    0           batch_normalization_818[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_814 (Conv2D)             (None, 6, 6, 192)    258048      activation_813[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_819 (Conv2D)             (None, 6, 6, 192)    258048      activation_818[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_814 (BatchN (None, 6, 6, 192)    576         conv2d_814[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_819 (BatchN (None, 6, 6, 192)    576         conv2d_819[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_814 (Activation)     (None, 6, 6, 192)    0           batch_normalization_814[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_819 (Activation)     (None, 6, 6, 192)    0           batch_normalization_819[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_78 (AveragePo (None, 6, 6, 768)    0           mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_812 (Conv2D)             (None, 6, 6, 192)    147456      mixed6[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_815 (Conv2D)             (None, 6, 6, 192)    258048      activation_814[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_820 (Conv2D)             (None, 6, 6, 192)    258048      activation_819[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_821 (Conv2D)             (None, 6, 6, 192)    147456      average_pooling2d_78[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_812 (BatchN (None, 6, 6, 192)    576         conv2d_812[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_815 (BatchN (None, 6, 6, 192)    576         conv2d_815[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_820 (BatchN (None, 6, 6, 192)    576         conv2d_820[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_821 (BatchN (None, 6, 6, 192)    576         conv2d_821[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_812 (Activation)     (None, 6, 6, 192)    0           batch_normalization_812[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_815 (Activation)     (None, 6, 6, 192)    0           batch_normalization_815[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_820 (Activation)     (None, 6, 6, 192)    0           batch_normalization_820[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_821 (Activation)     (None, 6, 6, 192)    0           batch_normalization_821[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed7 (Concatenate)            (None, 6, 6, 768)    0           activation_812[0][0]             \n",
            "                                                                 activation_815[0][0]             \n",
            "                                                                 activation_820[0][0]             \n",
            "                                                                 activation_821[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_824 (Conv2D)             (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_824 (BatchN (None, 6, 6, 192)    576         conv2d_824[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_824 (Activation)     (None, 6, 6, 192)    0           batch_normalization_824[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_825 (Conv2D)             (None, 6, 6, 192)    258048      activation_824[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_825 (BatchN (None, 6, 6, 192)    576         conv2d_825[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_825 (Activation)     (None, 6, 6, 192)    0           batch_normalization_825[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_822 (Conv2D)             (None, 6, 6, 192)    147456      mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_826 (Conv2D)             (None, 6, 6, 192)    258048      activation_825[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_822 (BatchN (None, 6, 6, 192)    576         conv2d_822[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_826 (BatchN (None, 6, 6, 192)    576         conv2d_826[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_822 (Activation)     (None, 6, 6, 192)    0           batch_normalization_822[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_826 (Activation)     (None, 6, 6, 192)    0           batch_normalization_826[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_823 (Conv2D)             (None, 2, 2, 320)    552960      activation_822[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_827 (Conv2D)             (None, 2, 2, 192)    331776      activation_826[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_823 (BatchN (None, 2, 2, 320)    960         conv2d_823[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_827 (BatchN (None, 2, 2, 192)    576         conv2d_827[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_823 (Activation)     (None, 2, 2, 320)    0           batch_normalization_823[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_827 (Activation)     (None, 2, 2, 192)    0           batch_normalization_827[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "max_pooling2d_35 (MaxPooling2D) (None, 2, 2, 768)    0           mixed7[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "mixed8 (Concatenate)            (None, 2, 2, 1280)   0           activation_823[0][0]             \n",
            "                                                                 activation_827[0][0]             \n",
            "                                                                 max_pooling2d_35[0][0]           \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_832 (Conv2D)             (None, 2, 2, 448)    573440      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_832 (BatchN (None, 2, 2, 448)    1344        conv2d_832[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_832 (Activation)     (None, 2, 2, 448)    0           batch_normalization_832[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_829 (Conv2D)             (None, 2, 2, 384)    491520      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_833 (Conv2D)             (None, 2, 2, 384)    1548288     activation_832[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_829 (BatchN (None, 2, 2, 384)    1152        conv2d_829[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_833 (BatchN (None, 2, 2, 384)    1152        conv2d_833[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_829 (Activation)     (None, 2, 2, 384)    0           batch_normalization_829[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_833 (Activation)     (None, 2, 2, 384)    0           batch_normalization_833[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_830 (Conv2D)             (None, 2, 2, 384)    442368      activation_829[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_831 (Conv2D)             (None, 2, 2, 384)    442368      activation_829[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_834 (Conv2D)             (None, 2, 2, 384)    442368      activation_833[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_835 (Conv2D)             (None, 2, 2, 384)    442368      activation_833[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_79 (AveragePo (None, 2, 2, 1280)   0           mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_828 (Conv2D)             (None, 2, 2, 320)    409600      mixed8[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_830 (BatchN (None, 2, 2, 384)    1152        conv2d_830[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_831 (BatchN (None, 2, 2, 384)    1152        conv2d_831[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_834 (BatchN (None, 2, 2, 384)    1152        conv2d_834[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_835 (BatchN (None, 2, 2, 384)    1152        conv2d_835[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_836 (Conv2D)             (None, 2, 2, 192)    245760      average_pooling2d_79[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_828 (BatchN (None, 2, 2, 320)    960         conv2d_828[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_830 (Activation)     (None, 2, 2, 384)    0           batch_normalization_830[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_831 (Activation)     (None, 2, 2, 384)    0           batch_normalization_831[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_834 (Activation)     (None, 2, 2, 384)    0           batch_normalization_834[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_835 (Activation)     (None, 2, 2, 384)    0           batch_normalization_835[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_836 (BatchN (None, 2, 2, 192)    576         conv2d_836[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_828 (Activation)     (None, 2, 2, 320)    0           batch_normalization_828[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_0 (Concatenate)          (None, 2, 2, 768)    0           activation_830[0][0]             \n",
            "                                                                 activation_831[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_16 (Concatenate)    (None, 2, 2, 768)    0           activation_834[0][0]             \n",
            "                                                                 activation_835[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_836 (Activation)     (None, 2, 2, 192)    0           batch_normalization_836[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9 (Concatenate)            (None, 2, 2, 2048)   0           activation_828[0][0]             \n",
            "                                                                 mixed9_0[0][0]                   \n",
            "                                                                 concatenate_16[0][0]             \n",
            "                                                                 activation_836[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_841 (Conv2D)             (None, 2, 2, 448)    917504      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_841 (BatchN (None, 2, 2, 448)    1344        conv2d_841[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_841 (Activation)     (None, 2, 2, 448)    0           batch_normalization_841[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_838 (Conv2D)             (None, 2, 2, 384)    786432      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_842 (Conv2D)             (None, 2, 2, 384)    1548288     activation_841[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_838 (BatchN (None, 2, 2, 384)    1152        conv2d_838[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_842 (BatchN (None, 2, 2, 384)    1152        conv2d_842[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_838 (Activation)     (None, 2, 2, 384)    0           batch_normalization_838[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_842 (Activation)     (None, 2, 2, 384)    0           batch_normalization_842[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_839 (Conv2D)             (None, 2, 2, 384)    442368      activation_838[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_840 (Conv2D)             (None, 2, 2, 384)    442368      activation_838[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_843 (Conv2D)             (None, 2, 2, 384)    442368      activation_842[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_844 (Conv2D)             (None, 2, 2, 384)    442368      activation_842[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "average_pooling2d_80 (AveragePo (None, 2, 2, 2048)   0           mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_837 (Conv2D)             (None, 2, 2, 320)    655360      mixed9[0][0]                     \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_839 (BatchN (None, 2, 2, 384)    1152        conv2d_839[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_840 (BatchN (None, 2, 2, 384)    1152        conv2d_840[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_843 (BatchN (None, 2, 2, 384)    1152        conv2d_843[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_844 (BatchN (None, 2, 2, 384)    1152        conv2d_844[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "conv2d_845 (Conv2D)             (None, 2, 2, 192)    393216      average_pooling2d_80[0][0]       \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_837 (BatchN (None, 2, 2, 320)    960         conv2d_837[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_839 (Activation)     (None, 2, 2, 384)    0           batch_normalization_839[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_840 (Activation)     (None, 2, 2, 384)    0           batch_normalization_840[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_843 (Activation)     (None, 2, 2, 384)    0           batch_normalization_843[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "activation_844 (Activation)     (None, 2, 2, 384)    0           batch_normalization_844[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "batch_normalization_845 (BatchN (None, 2, 2, 192)    576         conv2d_845[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "activation_837 (Activation)     (None, 2, 2, 320)    0           batch_normalization_837[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed9_1 (Concatenate)          (None, 2, 2, 768)    0           activation_839[0][0]             \n",
            "                                                                 activation_840[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "concatenate_17 (Concatenate)    (None, 2, 2, 768)    0           activation_843[0][0]             \n",
            "                                                                 activation_844[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "activation_845 (Activation)     (None, 2, 2, 192)    0           batch_normalization_845[0][0]    \n",
            "__________________________________________________________________________________________________\n",
            "mixed10 (Concatenate)           (None, 2, 2, 2048)   0           activation_837[0][0]             \n",
            "                                                                 mixed9_1[0][0]                   \n",
            "                                                                 concatenate_17[0][0]             \n",
            "                                                                 activation_845[0][0]             \n",
            "__________________________________________________________________________________________________\n",
            "flatten_15 (Flatten)            (None, 8192)         0           mixed10[0][0]                    \n",
            "__________________________________________________________________________________________________\n",
            "dense_23 (Dense)                (None, 128)          1048704     flatten_15[0][0]                 \n",
            "__________________________________________________________________________________________________\n",
            "dropout_12 (Dropout)            (None, 128)          0           dense_23[0][0]                   \n",
            "__________________________________________________________________________________________________\n",
            "dense_24 (Dense)                (None, 15)           1935        dropout_12[0][0]                 \n",
            "==================================================================================================\n",
            "Total params: 22,853,423\n",
            "Trainable params: 1,050,639\n",
            "Non-trainable params: 21,802,784\n",
            "__________________________________________________________________________________________________\n",
            "Epoch 1/300\n",
            "5/5 [==============================] - 22s 2s/step - loss: 7.2382 - fBetaKeyras: 0.2073 - val_loss: 2.8964 - val_fBetaKeyras: 0.2358\n",
            "Epoch 2/300\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 3.2351 - fBetaKeyras: 0.1977 - val_loss: 1.9544 - val_fBetaKeyras: 0.2036\n",
            "Epoch 3/300\n",
            "5/5 [==============================] - 2s 427ms/step - loss: 2.1204 - fBetaKeyras: 0.2240 - val_loss: 1.8915 - val_fBetaKeyras: 0.2522\n",
            "Epoch 4/300\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 1.9318 - fBetaKeyras: 0.2077 - val_loss: 1.2344 - val_fBetaKeyras: 0.2249\n",
            "Epoch 5/300\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 1.4226 - fBetaKeyras: 0.2430 - val_loss: 1.0705 - val_fBetaKeyras: 0.2571\n",
            "Epoch 6/300\n",
            "5/5 [==============================] - 2s 428ms/step - loss: 1.0967 - fBetaKeyras: 0.2344 - val_loss: 0.8520 - val_fBetaKeyras: 0.2286\n",
            "Epoch 7/300\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.8372 - fBetaKeyras: 0.2304 - val_loss: 0.7808 - val_fBetaKeyras: 0.1879\n",
            "Epoch 8/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.7784 - fBetaKeyras: 0.1718 - val_loss: 0.7459 - val_fBetaKeyras: 0.2093\n",
            "Epoch 9/300\n",
            "5/5 [==============================] - 2s 545ms/step - loss: 0.7332 - fBetaKeyras: 0.1469 - val_loss: 0.7124 - val_fBetaKeyras: 0.1516\n",
            "Epoch 10/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.7075 - fBetaKeyras: 0.0936 - val_loss: 0.7095 - val_fBetaKeyras: 0.1170\n",
            "Epoch 11/300\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.7015 - fBetaKeyras: 0.0902 - val_loss: 0.7065 - val_fBetaKeyras: 0.0954\n",
            "Epoch 12/300\n",
            "5/5 [==============================] - 2s 421ms/step - loss: 0.6956 - fBetaKeyras: 0.0665 - val_loss: 0.7065 - val_fBetaKeyras: 0.0724\n",
            "Epoch 13/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.6949 - fBetaKeyras: 0.0432 - val_loss: 0.7033 - val_fBetaKeyras: 0.0770\n",
            "Epoch 14/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6988 - fBetaKeyras: 0.0542 - val_loss: 0.6939 - val_fBetaKeyras: 0.0773\n",
            "Epoch 15/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.6958 - fBetaKeyras: 0.0655 - val_loss: 0.6864 - val_fBetaKeyras: 0.0743\n",
            "Epoch 16/300\n",
            "5/5 [==============================] - 2s 418ms/step - loss: 0.6926 - fBetaKeyras: 0.0602 - val_loss: 0.6908 - val_fBetaKeyras: 0.0729\n",
            "Epoch 17/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6829 - fBetaKeyras: 0.0750 - val_loss: 0.6895 - val_fBetaKeyras: 0.0449\n",
            "Epoch 18/300\n",
            "5/5 [==============================] - 2s 418ms/step - loss: 0.6914 - fBetaKeyras: 0.0274 - val_loss: 0.6828 - val_fBetaKeyras: 0.0572\n",
            "Epoch 19/300\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.6864 - fBetaKeyras: 0.0417 - val_loss: 0.6797 - val_fBetaKeyras: 0.0754\n",
            "Epoch 20/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.6841 - fBetaKeyras: 0.0628 - val_loss: 0.6785 - val_fBetaKeyras: 0.1025\n",
            "Epoch 21/300\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.6957 - fBetaKeyras: 0.0855 - val_loss: 0.6817 - val_fBetaKeyras: 0.0585\n",
            "Epoch 22/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6885 - fBetaKeyras: 0.0422 - val_loss: 0.6820 - val_fBetaKeyras: 0.0650\n",
            "Epoch 23/300\n",
            "5/5 [==============================] - 2s 509ms/step - loss: 0.6867 - fBetaKeyras: 0.0237 - val_loss: 0.6861 - val_fBetaKeyras: 0.0683\n",
            "Epoch 24/300\n",
            "5/5 [==============================] - 2s 396ms/step - loss: 0.6857 - fBetaKeyras: 0.0604 - val_loss: 0.6864 - val_fBetaKeyras: 0.0443\n",
            "Epoch 25/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6834 - fBetaKeyras: 0.0496 - val_loss: 0.6749 - val_fBetaKeyras: 0.1101\n",
            "Epoch 26/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.6830 - fBetaKeyras: 0.0749 - val_loss: 0.6800 - val_fBetaKeyras: 0.1136\n",
            "Epoch 27/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6848 - fBetaKeyras: 0.0797 - val_loss: 0.6806 - val_fBetaKeyras: 0.0759\n",
            "Epoch 28/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6917 - fBetaKeyras: 0.0817 - val_loss: 0.6815 - val_fBetaKeyras: 0.0820\n",
            "Epoch 29/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6795 - fBetaKeyras: 0.0656 - val_loss: 0.6844 - val_fBetaKeyras: 0.1286\n",
            "Epoch 30/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.6797 - fBetaKeyras: 0.1309 - val_loss: 0.6779 - val_fBetaKeyras: 0.1087\n",
            "Epoch 31/300\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.6887 - fBetaKeyras: 0.0634 - val_loss: 0.6800 - val_fBetaKeyras: 0.0531\n",
            "Epoch 32/300\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.6832 - fBetaKeyras: 0.0513 - val_loss: 0.6728 - val_fBetaKeyras: 0.1036\n",
            "Epoch 33/300\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.6790 - fBetaKeyras: 0.0559 - val_loss: 0.6734 - val_fBetaKeyras: 0.0856\n",
            "Epoch 34/300\n",
            "5/5 [==============================] - 2s 551ms/step - loss: 0.6798 - fBetaKeyras: 0.0713 - val_loss: 0.6773 - val_fBetaKeyras: 0.1234\n",
            "Epoch 35/300\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.6816 - fBetaKeyras: 0.0931 - val_loss: 0.7109 - val_fBetaKeyras: 0.1945\n",
            "Epoch 36/300\n",
            "5/5 [==============================] - 2s 547ms/step - loss: 0.6904 - fBetaKeyras: 0.1079 - val_loss: 0.6870 - val_fBetaKeyras: 0.1386\n",
            "Epoch 37/300\n",
            "5/5 [==============================] - 2s 461ms/step - loss: 0.6835 - fBetaKeyras: 0.0919 - val_loss: 0.6626 - val_fBetaKeyras: 0.1797\n",
            "Epoch 38/300\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.6674 - fBetaKeyras: 0.1310 - val_loss: 0.6750 - val_fBetaKeyras: 0.0859\n",
            "Epoch 39/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.6773 - fBetaKeyras: 0.0622 - val_loss: 0.6664 - val_fBetaKeyras: 0.1089\n",
            "Epoch 40/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.6700 - fBetaKeyras: 0.1009 - val_loss: 0.6670 - val_fBetaKeyras: 0.1620\n",
            "Epoch 41/300\n",
            "5/5 [==============================] - 2s 549ms/step - loss: 0.6921 - fBetaKeyras: 0.1338 - val_loss: 0.6672 - val_fBetaKeyras: 0.1375\n",
            "Epoch 42/300\n",
            "5/5 [==============================] - 2s 415ms/step - loss: 0.6796 - fBetaKeyras: 0.0908 - val_loss: 0.6718 - val_fBetaKeyras: 0.1089\n",
            "Epoch 43/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.6805 - fBetaKeyras: 0.0938 - val_loss: 0.6636 - val_fBetaKeyras: 0.1828\n",
            "Epoch 44/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6827 - fBetaKeyras: 0.1325 - val_loss: 0.6976 - val_fBetaKeyras: 0.2099\n",
            "Epoch 45/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6822 - fBetaKeyras: 0.1480 - val_loss: 0.6711 - val_fBetaKeyras: 0.1026\n",
            "Epoch 46/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.6728 - fBetaKeyras: 0.1033 - val_loss: 0.6555 - val_fBetaKeyras: 0.1611\n",
            "Epoch 47/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6743 - fBetaKeyras: 0.1325 - val_loss: 0.6783 - val_fBetaKeyras: 0.2335\n",
            "Epoch 48/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.7130 - fBetaKeyras: 0.1333 - val_loss: 0.6597 - val_fBetaKeyras: 0.1609\n",
            "Epoch 49/300\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.6633 - fBetaKeyras: 0.1129 - val_loss: 0.6574 - val_fBetaKeyras: 0.1426\n",
            "Epoch 50/300\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.6724 - fBetaKeyras: 0.1344 - val_loss: 0.7301 - val_fBetaKeyras: 0.2299\n",
            "Epoch 51/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.7041 - fBetaKeyras: 0.1595 - val_loss: 0.6635 - val_fBetaKeyras: 0.1707\n",
            "Epoch 52/300\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.6716 - fBetaKeyras: 0.1438 - val_loss: 0.6642 - val_fBetaKeyras: 0.1767\n",
            "Epoch 53/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6733 - fBetaKeyras: 0.1549 - val_loss: 0.6510 - val_fBetaKeyras: 0.1556\n",
            "Epoch 54/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.6688 - fBetaKeyras: 0.1242 - val_loss: 0.6496 - val_fBetaKeyras: 0.1655\n",
            "Epoch 55/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6665 - fBetaKeyras: 0.1177 - val_loss: 0.6586 - val_fBetaKeyras: 0.1371\n",
            "Epoch 56/300\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.6648 - fBetaKeyras: 0.1393 - val_loss: 0.6497 - val_fBetaKeyras: 0.2078\n",
            "Epoch 57/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6725 - fBetaKeyras: 0.1634 - val_loss: 0.6476 - val_fBetaKeyras: 0.1582\n",
            "Epoch 58/300\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 0.6559 - fBetaKeyras: 0.1521 - val_loss: 0.6449 - val_fBetaKeyras: 0.1756\n",
            "Epoch 59/300\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.6499 - fBetaKeyras: 0.1511 - val_loss: 0.6442 - val_fBetaKeyras: 0.1456\n",
            "Epoch 60/300\n",
            "5/5 [==============================] - 2s 428ms/step - loss: 0.6676 - fBetaKeyras: 0.1146 - val_loss: 0.6456 - val_fBetaKeyras: 0.1663\n",
            "Epoch 61/300\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.6619 - fBetaKeyras: 0.1481 - val_loss: 0.6594 - val_fBetaKeyras: 0.1931\n",
            "Epoch 62/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.6507 - fBetaKeyras: 0.1642 - val_loss: 0.6422 - val_fBetaKeyras: 0.1869\n",
            "Epoch 63/300\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.6450 - fBetaKeyras: 0.1744 - val_loss: 0.6398 - val_fBetaKeyras: 0.2085\n",
            "Epoch 64/300\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.6750 - fBetaKeyras: 0.1232 - val_loss: 0.6425 - val_fBetaKeyras: 0.1590\n",
            "Epoch 65/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.6568 - fBetaKeyras: 0.1281 - val_loss: 0.6462 - val_fBetaKeyras: 0.1513\n",
            "Epoch 66/300\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.6581 - fBetaKeyras: 0.1226 - val_loss: 0.6548 - val_fBetaKeyras: 0.1372\n",
            "Epoch 67/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.6604 - fBetaKeyras: 0.1226 - val_loss: 0.6433 - val_fBetaKeyras: 0.1620\n",
            "Epoch 68/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.6527 - fBetaKeyras: 0.1618 - val_loss: 0.6422 - val_fBetaKeyras: 0.1427\n",
            "Epoch 69/300\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.6456 - fBetaKeyras: 0.1533 - val_loss: 0.6388 - val_fBetaKeyras: 0.1396\n",
            "Epoch 70/300\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.6521 - fBetaKeyras: 0.1303 - val_loss: 0.6389 - val_fBetaKeyras: 0.1968\n",
            "Epoch 71/300\n",
            "5/5 [==============================] - 2s 422ms/step - loss: 0.6569 - fBetaKeyras: 0.1540 - val_loss: 0.6543 - val_fBetaKeyras: 0.1781\n",
            "Epoch 72/300\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.6549 - fBetaKeyras: 0.2166 - val_loss: 0.6459 - val_fBetaKeyras: 0.1581\n",
            "Epoch 73/300\n",
            "5/5 [==============================] - 2s 399ms/step - loss: 0.6513 - fBetaKeyras: 0.1271 - val_loss: 0.6863 - val_fBetaKeyras: 0.2115\n",
            "Epoch 74/300\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.6778 - fBetaKeyras: 0.1486 - val_loss: 0.6432 - val_fBetaKeyras: 0.1532\n",
            "Epoch 75/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.6514 - fBetaKeyras: 0.1485 - val_loss: 0.6346 - val_fBetaKeyras: 0.1974\n",
            "Epoch 76/300\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.6393 - fBetaKeyras: 0.1698 - val_loss: 0.6537 - val_fBetaKeyras: 0.2396\n",
            "Epoch 77/300\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.6681 - fBetaKeyras: 0.1779 - val_loss: 0.6243 - val_fBetaKeyras: 0.1844\n",
            "Epoch 78/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6456 - fBetaKeyras: 0.1699 - val_loss: 0.6252 - val_fBetaKeyras: 0.1939\n",
            "Epoch 79/300\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.6404 - fBetaKeyras: 0.2374 - val_loss: 0.6268 - val_fBetaKeyras: 0.1709\n",
            "Epoch 80/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.6341 - fBetaKeyras: 0.1705 - val_loss: 0.6220 - val_fBetaKeyras: 0.1948\n",
            "Epoch 81/300\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.6396 - fBetaKeyras: 0.1744 - val_loss: 0.6203 - val_fBetaKeyras: 0.2098\n",
            "Epoch 82/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.6615 - fBetaKeyras: 0.1501 - val_loss: 0.6421 - val_fBetaKeyras: 0.1724\n",
            "Epoch 83/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6598 - fBetaKeyras: 0.1637 - val_loss: 0.6278 - val_fBetaKeyras: 0.1914\n",
            "Epoch 84/300\n",
            "5/5 [==============================] - 2s 397ms/step - loss: 0.6333 - fBetaKeyras: 0.1608 - val_loss: 0.6650 - val_fBetaKeyras: 0.2375\n",
            "Epoch 85/300\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.6854 - fBetaKeyras: 0.1925 - val_loss: 0.6332 - val_fBetaKeyras: 0.2013\n",
            "Epoch 86/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6371 - fBetaKeyras: 0.1421 - val_loss: 0.6216 - val_fBetaKeyras: 0.1991\n",
            "Epoch 87/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6349 - fBetaKeyras: 0.1722 - val_loss: 0.6302 - val_fBetaKeyras: 0.1798\n",
            "Epoch 88/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.6412 - fBetaKeyras: 0.1823 - val_loss: 0.6188 - val_fBetaKeyras: 0.1843\n",
            "Epoch 89/300\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.6336 - fBetaKeyras: 0.1829 - val_loss: 0.6250 - val_fBetaKeyras: 0.2634\n",
            "Epoch 90/300\n",
            "5/5 [==============================] - 2s 424ms/step - loss: 0.6379 - fBetaKeyras: 0.1612 - val_loss: 0.6229 - val_fBetaKeyras: 0.1502\n",
            "Epoch 91/300\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.6317 - fBetaKeyras: 0.1540 - val_loss: 0.6159 - val_fBetaKeyras: 0.2273\n",
            "Epoch 92/300\n",
            "5/5 [==============================] - 2s 423ms/step - loss: 0.6443 - fBetaKeyras: 0.1646 - val_loss: 0.6332 - val_fBetaKeyras: 0.2484\n",
            "Epoch 93/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.6374 - fBetaKeyras: 0.2104 - val_loss: 0.6329 - val_fBetaKeyras: 0.2553\n",
            "Epoch 94/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.6385 - fBetaKeyras: 0.1835 - val_loss: 0.6212 - val_fBetaKeyras: 0.1959\n",
            "Epoch 95/300\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.6377 - fBetaKeyras: 0.1681 - val_loss: 0.6174 - val_fBetaKeyras: 0.1920\n",
            "Epoch 96/300\n",
            "5/5 [==============================] - 2s 544ms/step - loss: 0.6536 - fBetaKeyras: 0.1256 - val_loss: 0.6146 - val_fBetaKeyras: 0.2031\n",
            "Epoch 97/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.6205 - fBetaKeyras: 0.1689 - val_loss: 0.6173 - val_fBetaKeyras: 0.1775\n",
            "Epoch 98/300\n",
            "5/5 [==============================] - 2s 422ms/step - loss: 0.6247 - fBetaKeyras: 0.1754 - val_loss: 0.6158 - val_fBetaKeyras: 0.2197\n",
            "Epoch 99/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.6299 - fBetaKeyras: 0.1492 - val_loss: 0.6124 - val_fBetaKeyras: 0.1984\n",
            "Epoch 100/300\n",
            "5/5 [==============================] - 2s 552ms/step - loss: 0.6292 - fBetaKeyras: 0.1504 - val_loss: 0.6061 - val_fBetaKeyras: 0.2049\n",
            "Epoch 101/300\n",
            "5/5 [==============================] - 2s 419ms/step - loss: 0.6183 - fBetaKeyras: 0.1944 - val_loss: 0.5991 - val_fBetaKeyras: 0.2531\n",
            "Epoch 102/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6484 - fBetaKeyras: 0.2146 - val_loss: 0.6080 - val_fBetaKeyras: 0.2466\n",
            "Epoch 103/300\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.6581 - fBetaKeyras: 0.1674 - val_loss: 0.5969 - val_fBetaKeyras: 0.2247\n",
            "Epoch 104/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6150 - fBetaKeyras: 0.1880 - val_loss: 0.5956 - val_fBetaKeyras: 0.2536\n",
            "Epoch 105/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6232 - fBetaKeyras: 0.1959 - val_loss: 0.5967 - val_fBetaKeyras: 0.2173\n",
            "Epoch 106/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6207 - fBetaKeyras: 0.1916 - val_loss: 0.6190 - val_fBetaKeyras: 0.1836\n",
            "Epoch 107/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.6420 - fBetaKeyras: 0.1372 - val_loss: 0.6045 - val_fBetaKeyras: 0.2067\n",
            "Epoch 108/300\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.6344 - fBetaKeyras: 0.1660 - val_loss: 0.6019 - val_fBetaKeyras: 0.1953\n",
            "Epoch 109/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.6193 - fBetaKeyras: 0.1769 - val_loss: 0.5910 - val_fBetaKeyras: 0.2239\n",
            "Epoch 110/300\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.6165 - fBetaKeyras: 0.1933 - val_loss: 0.6058 - val_fBetaKeyras: 0.2479\n",
            "Epoch 111/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.6206 - fBetaKeyras: 0.2082 - val_loss: 0.5951 - val_fBetaKeyras: 0.2327\n",
            "Epoch 112/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.6179 - fBetaKeyras: 0.1944 - val_loss: 0.5937 - val_fBetaKeyras: 0.2497\n",
            "Epoch 113/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6154 - fBetaKeyras: 0.2254 - val_loss: 0.5962 - val_fBetaKeyras: 0.2342\n",
            "Epoch 114/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.6205 - fBetaKeyras: 0.2299 - val_loss: 0.5946 - val_fBetaKeyras: 0.1951\n",
            "Epoch 115/300\n",
            "5/5 [==============================] - 2s 410ms/step - loss: 0.6102 - fBetaKeyras: 0.1688 - val_loss: 0.5982 - val_fBetaKeyras: 0.2035\n",
            "Epoch 116/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.6112 - fBetaKeyras: 0.1931 - val_loss: 0.6019 - val_fBetaKeyras: 0.2685\n",
            "Epoch 117/300\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.6074 - fBetaKeyras: 0.2115 - val_loss: 0.5882 - val_fBetaKeyras: 0.2614\n",
            "Epoch 118/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6143 - fBetaKeyras: 0.1999 - val_loss: 0.5832 - val_fBetaKeyras: 0.2478\n",
            "Epoch 119/300\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.6246 - fBetaKeyras: 0.2145 - val_loss: 0.5858 - val_fBetaKeyras: 0.2419\n",
            "Epoch 120/300\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.6087 - fBetaKeyras: 0.1955 - val_loss: 0.5832 - val_fBetaKeyras: 0.2607\n",
            "Epoch 121/300\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.6095 - fBetaKeyras: 0.2103 - val_loss: 0.6011 - val_fBetaKeyras: 0.2058\n",
            "Epoch 122/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.6116 - fBetaKeyras: 0.1910 - val_loss: 0.6030 - val_fBetaKeyras: 0.2468\n",
            "Epoch 123/300\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.6222 - fBetaKeyras: 0.2261 - val_loss: 0.6580 - val_fBetaKeyras: 0.2399\n",
            "Epoch 124/300\n",
            "5/5 [==============================] - 2s 568ms/step - loss: 0.6408 - fBetaKeyras: 0.2186 - val_loss: 0.5768 - val_fBetaKeyras: 0.2284\n",
            "Epoch 125/300\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.5998 - fBetaKeyras: 0.2199 - val_loss: 0.5790 - val_fBetaKeyras: 0.2168\n",
            "Epoch 126/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.6073 - fBetaKeyras: 0.2114 - val_loss: 0.5798 - val_fBetaKeyras: 0.2366\n",
            "Epoch 127/300\n",
            "5/5 [==============================] - 2s 422ms/step - loss: 0.6035 - fBetaKeyras: 0.1882 - val_loss: 0.5761 - val_fBetaKeyras: 0.2118\n",
            "Epoch 128/300\n",
            "5/5 [==============================] - 2s 424ms/step - loss: 0.5939 - fBetaKeyras: 0.2022 - val_loss: 0.6160 - val_fBetaKeyras: 0.2629\n",
            "Epoch 129/300\n",
            "5/5 [==============================] - 2s 550ms/step - loss: 0.6104 - fBetaKeyras: 0.1768 - val_loss: 0.5761 - val_fBetaKeyras: 0.2499\n",
            "Epoch 130/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.6102 - fBetaKeyras: 0.2348 - val_loss: 0.5736 - val_fBetaKeyras: 0.2198\n",
            "Epoch 131/300\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.6053 - fBetaKeyras: 0.1551 - val_loss: 0.5760 - val_fBetaKeyras: 0.2094\n",
            "Epoch 132/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.5939 - fBetaKeyras: 0.2019 - val_loss: 0.5646 - val_fBetaKeyras: 0.2261\n",
            "Epoch 133/300\n",
            "5/5 [==============================] - 2s 534ms/step - loss: 0.5803 - fBetaKeyras: 0.1932 - val_loss: 0.5631 - val_fBetaKeyras: 0.2644\n",
            "Epoch 134/300\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.5986 - fBetaKeyras: 0.2113 - val_loss: 0.5755 - val_fBetaKeyras: 0.2080\n",
            "Epoch 135/300\n",
            "5/5 [==============================] - 2s 435ms/step - loss: 0.5935 - fBetaKeyras: 0.1833 - val_loss: 0.5669 - val_fBetaKeyras: 0.2421\n",
            "Epoch 136/300\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.5842 - fBetaKeyras: 0.2351 - val_loss: 0.5779 - val_fBetaKeyras: 0.2384\n",
            "Epoch 137/300\n",
            "5/5 [==============================] - 2s 546ms/step - loss: 0.5700 - fBetaKeyras: 0.2409 - val_loss: 0.5727 - val_fBetaKeyras: 0.2355\n",
            "Epoch 138/300\n",
            "5/5 [==============================] - 2s 442ms/step - loss: 0.5838 - fBetaKeyras: 0.2415 - val_loss: 0.5728 - val_fBetaKeyras: 0.2159\n",
            "Epoch 139/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.5987 - fBetaKeyras: 0.1953 - val_loss: 0.5616 - val_fBetaKeyras: 0.2299\n",
            "Epoch 140/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.5868 - fBetaKeyras: 0.2261 - val_loss: 0.5615 - val_fBetaKeyras: 0.2273\n",
            "Epoch 141/300\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.5890 - fBetaKeyras: 0.2080 - val_loss: 0.5610 - val_fBetaKeyras: 0.2224\n",
            "Epoch 142/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.5725 - fBetaKeyras: 0.2036 - val_loss: 0.5630 - val_fBetaKeyras: 0.2560\n",
            "Epoch 143/300\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.5756 - fBetaKeyras: 0.2364 - val_loss: 0.5733 - val_fBetaKeyras: 0.2087\n",
            "Epoch 144/300\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.5828 - fBetaKeyras: 0.2022 - val_loss: 0.5830 - val_fBetaKeyras: 0.2680\n",
            "Epoch 145/300\n",
            "5/5 [==============================] - 2s 524ms/step - loss: 0.6186 - fBetaKeyras: 0.2690 - val_loss: 0.5574 - val_fBetaKeyras: 0.2685\n",
            "Epoch 146/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.5826 - fBetaKeyras: 0.1951 - val_loss: 0.5547 - val_fBetaKeyras: 0.2546\n",
            "Epoch 147/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.5766 - fBetaKeyras: 0.2145 - val_loss: 0.5793 - val_fBetaKeyras: 0.1740\n",
            "Epoch 148/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.5981 - fBetaKeyras: 0.1953 - val_loss: 0.5571 - val_fBetaKeyras: 0.2343\n",
            "Epoch 149/300\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.5757 - fBetaKeyras: 0.1943 - val_loss: 0.5503 - val_fBetaKeyras: 0.2396\n",
            "Epoch 150/300\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.5799 - fBetaKeyras: 0.1831 - val_loss: 0.5561 - val_fBetaKeyras: 0.2200\n",
            "Epoch 151/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.5843 - fBetaKeyras: 0.1924 - val_loss: 0.5476 - val_fBetaKeyras: 0.2314\n",
            "Epoch 152/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.5665 - fBetaKeyras: 0.2103 - val_loss: 0.5513 - val_fBetaKeyras: 0.2198\n",
            "Epoch 153/300\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 0.5771 - fBetaKeyras: 0.2305 - val_loss: 0.5527 - val_fBetaKeyras: 0.2423\n",
            "Epoch 154/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.5776 - fBetaKeyras: 0.2166 - val_loss: 0.5555 - val_fBetaKeyras: 0.2409\n",
            "Epoch 155/300\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.5567 - fBetaKeyras: 0.2417 - val_loss: 0.5514 - val_fBetaKeyras: 0.2449\n",
            "Epoch 156/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.5758 - fBetaKeyras: 0.1920 - val_loss: 0.5472 - val_fBetaKeyras: 0.2431\n",
            "Epoch 157/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.5811 - fBetaKeyras: 0.2309 - val_loss: 0.5535 - val_fBetaKeyras: 0.2173\n",
            "Epoch 158/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.5814 - fBetaKeyras: 0.1937 - val_loss: 0.5444 - val_fBetaKeyras: 0.2372\n",
            "Epoch 159/300\n",
            "5/5 [==============================] - 2s 514ms/step - loss: 0.5845 - fBetaKeyras: 0.2215 - val_loss: 0.5423 - val_fBetaKeyras: 0.2185\n",
            "Epoch 160/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.5501 - fBetaKeyras: 0.2062 - val_loss: 0.5525 - val_fBetaKeyras: 0.2708\n",
            "Epoch 161/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.5752 - fBetaKeyras: 0.2365 - val_loss: 0.5517 - val_fBetaKeyras: 0.2268\n",
            "Epoch 162/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.5768 - fBetaKeyras: 0.2192 - val_loss: 0.5488 - val_fBetaKeyras: 0.2013\n",
            "Epoch 163/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.5626 - fBetaKeyras: 0.1898 - val_loss: 0.5510 - val_fBetaKeyras: 0.2114\n",
            "Epoch 164/300\n",
            "5/5 [==============================] - 2s 429ms/step - loss: 0.5800 - fBetaKeyras: 0.2145 - val_loss: 0.5391 - val_fBetaKeyras: 0.2099\n",
            "Epoch 165/300\n",
            "5/5 [==============================] - 2s 428ms/step - loss: 0.5666 - fBetaKeyras: 0.2175 - val_loss: 0.5532 - val_fBetaKeyras: 0.1903\n",
            "Epoch 166/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.5875 - fBetaKeyras: 0.1977 - val_loss: 0.5410 - val_fBetaKeyras: 0.2271\n",
            "Epoch 167/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.5537 - fBetaKeyras: 0.2321 - val_loss: 0.5679 - val_fBetaKeyras: 0.2495\n",
            "Epoch 168/300\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.5799 - fBetaKeyras: 0.2191 - val_loss: 0.5463 - val_fBetaKeyras: 0.2125\n",
            "Epoch 169/300\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.5566 - fBetaKeyras: 0.2591 - val_loss: 0.5334 - val_fBetaKeyras: 0.2276\n",
            "Epoch 170/300\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.5701 - fBetaKeyras: 0.2063 - val_loss: 0.5315 - val_fBetaKeyras: 0.2626\n",
            "Epoch 171/300\n",
            "5/5 [==============================] - 2s 427ms/step - loss: 0.5594 - fBetaKeyras: 0.2105 - val_loss: 0.5843 - val_fBetaKeyras: 0.1204\n",
            "Epoch 172/300\n",
            "5/5 [==============================] - 2s 550ms/step - loss: 0.5873 - fBetaKeyras: 0.1456 - val_loss: 0.5356 - val_fBetaKeyras: 0.1948\n",
            "Epoch 173/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.5547 - fBetaKeyras: 0.1982 - val_loss: 0.5435 - val_fBetaKeyras: 0.1862\n",
            "Epoch 174/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.5577 - fBetaKeyras: 0.2149 - val_loss: 0.5253 - val_fBetaKeyras: 0.2284\n",
            "Epoch 175/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.5523 - fBetaKeyras: 0.2378 - val_loss: 0.5281 - val_fBetaKeyras: 0.2180\n",
            "Epoch 176/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.5652 - fBetaKeyras: 0.2099 - val_loss: 0.5292 - val_fBetaKeyras: 0.2458\n",
            "Epoch 177/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.5673 - fBetaKeyras: 0.2309 - val_loss: 0.5249 - val_fBetaKeyras: 0.2055\n",
            "Epoch 178/300\n",
            "5/5 [==============================] - 2s 410ms/step - loss: 0.5587 - fBetaKeyras: 0.2126 - val_loss: 0.5318 - val_fBetaKeyras: 0.2385\n",
            "Epoch 179/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.5508 - fBetaKeyras: 0.2027 - val_loss: 0.5390 - val_fBetaKeyras: 0.1896\n",
            "Epoch 180/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.5513 - fBetaKeyras: 0.2075 - val_loss: 0.5340 - val_fBetaKeyras: 0.2235\n",
            "Epoch 181/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.5716 - fBetaKeyras: 0.1994 - val_loss: 0.5255 - val_fBetaKeyras: 0.2309\n",
            "Epoch 182/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.5497 - fBetaKeyras: 0.2087 - val_loss: 0.5292 - val_fBetaKeyras: 0.2326\n",
            "Epoch 183/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.5440 - fBetaKeyras: 0.2167 - val_loss: 0.5599 - val_fBetaKeyras: 0.1674\n",
            "Epoch 184/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.5952 - fBetaKeyras: 0.1924 - val_loss: 0.5320 - val_fBetaKeyras: 0.1921\n",
            "Epoch 185/300\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.5611 - fBetaKeyras: 0.2108 - val_loss: 0.5302 - val_fBetaKeyras: 0.1869\n",
            "Epoch 186/300\n",
            "5/5 [==============================] - 2s 414ms/step - loss: 0.5528 - fBetaKeyras: 0.2098 - val_loss: 0.5166 - val_fBetaKeyras: 0.1922\n",
            "Epoch 187/300\n",
            "5/5 [==============================] - 2s 414ms/step - loss: 0.5471 - fBetaKeyras: 0.1958 - val_loss: 0.5438 - val_fBetaKeyras: 0.2333\n",
            "Epoch 188/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.5475 - fBetaKeyras: 0.1835 - val_loss: 0.5294 - val_fBetaKeyras: 0.2272\n",
            "Epoch 189/300\n",
            "5/5 [==============================] - 2s 512ms/step - loss: 0.6101 - fBetaKeyras: 0.1983 - val_loss: 0.5179 - val_fBetaKeyras: 0.2613\n",
            "Epoch 190/300\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.5390 - fBetaKeyras: 0.2223 - val_loss: 0.5219 - val_fBetaKeyras: 0.2194\n",
            "Epoch 191/300\n",
            "5/5 [==============================] - 2s 403ms/step - loss: 0.5282 - fBetaKeyras: 0.2167 - val_loss: 0.5114 - val_fBetaKeyras: 0.2329\n",
            "Epoch 192/300\n",
            "5/5 [==============================] - 2s 537ms/step - loss: 0.5473 - fBetaKeyras: 0.2126 - val_loss: 0.5142 - val_fBetaKeyras: 0.2348\n",
            "Epoch 193/300\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.5465 - fBetaKeyras: 0.2254 - val_loss: 0.5150 - val_fBetaKeyras: 0.1964\n",
            "Epoch 194/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.5356 - fBetaKeyras: 0.2063 - val_loss: 0.5237 - val_fBetaKeyras: 0.2151\n",
            "Epoch 195/300\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.5412 - fBetaKeyras: 0.1976 - val_loss: 0.5204 - val_fBetaKeyras: 0.2603\n",
            "Epoch 196/300\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.5458 - fBetaKeyras: 0.1963 - val_loss: 0.5248 - val_fBetaKeyras: 0.2150\n",
            "Epoch 197/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.5464 - fBetaKeyras: 0.1945 - val_loss: 0.5512 - val_fBetaKeyras: 0.2919\n",
            "Epoch 198/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.5573 - fBetaKeyras: 0.2107 - val_loss: 0.5270 - val_fBetaKeyras: 0.1708\n",
            "Epoch 199/300\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.5351 - fBetaKeyras: 0.1752 - val_loss: 0.5138 - val_fBetaKeyras: 0.1968\n",
            "Epoch 200/300\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.5613 - fBetaKeyras: 0.2001 - val_loss: 0.5055 - val_fBetaKeyras: 0.2101\n",
            "Epoch 201/300\n",
            "5/5 [==============================] - 2s 434ms/step - loss: 0.5352 - fBetaKeyras: 0.2225 - val_loss: 0.5082 - val_fBetaKeyras: 0.2176\n",
            "Epoch 202/300\n",
            "5/5 [==============================] - 2s 423ms/step - loss: 0.5274 - fBetaKeyras: 0.2167 - val_loss: 0.5259 - val_fBetaKeyras: 0.2649\n",
            "Epoch 203/300\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.5662 - fBetaKeyras: 0.2150 - val_loss: 0.5084 - val_fBetaKeyras: 0.2376\n",
            "Epoch 204/300\n",
            "5/5 [==============================] - 2s 522ms/step - loss: 0.5388 - fBetaKeyras: 0.2455 - val_loss: 0.5055 - val_fBetaKeyras: 0.2592\n",
            "Epoch 205/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.5393 - fBetaKeyras: 0.2109 - val_loss: 0.5099 - val_fBetaKeyras: 0.2086\n",
            "Epoch 206/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.5433 - fBetaKeyras: 0.2103 - val_loss: 0.5143 - val_fBetaKeyras: 0.1970\n",
            "Epoch 207/300\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.5308 - fBetaKeyras: 0.2029 - val_loss: 0.5355 - val_fBetaKeyras: 0.1484\n",
            "Epoch 208/300\n",
            "5/5 [==============================] - 2s 419ms/step - loss: 0.5470 - fBetaKeyras: 0.2127 - val_loss: 0.5093 - val_fBetaKeyras: 0.2228\n",
            "Epoch 209/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.5356 - fBetaKeyras: 0.1789 - val_loss: 0.5218 - val_fBetaKeyras: 0.1809\n",
            "Epoch 210/300\n",
            "5/5 [==============================] - 2s 398ms/step - loss: 0.5268 - fBetaKeyras: 0.1727 - val_loss: 0.5214 - val_fBetaKeyras: 0.1800\n",
            "Epoch 211/300\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 0.5594 - fBetaKeyras: 0.1940 - val_loss: 0.5070 - val_fBetaKeyras: 0.2353\n",
            "Epoch 212/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.5353 - fBetaKeyras: 0.2064 - val_loss: 0.4983 - val_fBetaKeyras: 0.2073\n",
            "Epoch 213/300\n",
            "5/5 [==============================] - 2s 410ms/step - loss: 0.5203 - fBetaKeyras: 0.1965 - val_loss: 0.5831 - val_fBetaKeyras: 0.0965\n",
            "Epoch 214/300\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.5805 - fBetaKeyras: 0.1358 - val_loss: 0.5103 - val_fBetaKeyras: 0.2106\n",
            "Epoch 215/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.5247 - fBetaKeyras: 0.2019 - val_loss: 0.5053 - val_fBetaKeyras: 0.2150\n",
            "Epoch 216/300\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.5268 - fBetaKeyras: 0.1992 - val_loss: 0.5530 - val_fBetaKeyras: 0.2057\n",
            "Epoch 217/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.5280 - fBetaKeyras: 0.2376 - val_loss: 0.5123 - val_fBetaKeyras: 0.1580\n",
            "Epoch 218/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.5319 - fBetaKeyras: 0.2058 - val_loss: 0.5094 - val_fBetaKeyras: 0.2064\n",
            "Epoch 219/300\n",
            "5/5 [==============================] - 2s 417ms/step - loss: 0.5262 - fBetaKeyras: 0.2001 - val_loss: 0.5071 - val_fBetaKeyras: 0.1673\n",
            "Epoch 220/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.5113 - fBetaKeyras: 0.1981 - val_loss: 0.4990 - val_fBetaKeyras: 0.2286\n",
            "Epoch 221/300\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.5199 - fBetaKeyras: 0.2058 - val_loss: 0.5115 - val_fBetaKeyras: 0.2320\n",
            "Epoch 222/300\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.5150 - fBetaKeyras: 0.1948 - val_loss: 0.4995 - val_fBetaKeyras: 0.1794\n",
            "Epoch 223/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.5183 - fBetaKeyras: 0.1698 - val_loss: 0.5193 - val_fBetaKeyras: 0.1985\n",
            "Epoch 224/300\n",
            "5/5 [==============================] - 2s 552ms/step - loss: 0.5362 - fBetaKeyras: 0.1574 - val_loss: 0.4902 - val_fBetaKeyras: 0.2125\n",
            "Epoch 225/300\n",
            "5/5 [==============================] - 2s 552ms/step - loss: 0.5418 - fBetaKeyras: 0.1673 - val_loss: 0.4980 - val_fBetaKeyras: 0.1755\n",
            "Epoch 226/300\n",
            "5/5 [==============================] - 2s 446ms/step - loss: 0.5183 - fBetaKeyras: 0.1765 - val_loss: 0.5006 - val_fBetaKeyras: 0.1846\n",
            "Epoch 227/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.5227 - fBetaKeyras: 0.1944 - val_loss: 0.4933 - val_fBetaKeyras: 0.1963\n",
            "Epoch 228/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.5232 - fBetaKeyras: 0.1892 - val_loss: 0.5203 - val_fBetaKeyras: 0.1968\n",
            "Epoch 229/300\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.5409 - fBetaKeyras: 0.2059 - val_loss: 0.5001 - val_fBetaKeyras: 0.2244\n",
            "Epoch 230/300\n",
            "5/5 [==============================] - 2s 552ms/step - loss: 0.5139 - fBetaKeyras: 0.2096 - val_loss: 0.4941 - val_fBetaKeyras: 0.1977\n",
            "Epoch 231/300\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.5117 - fBetaKeyras: 0.2191 - val_loss: 0.4929 - val_fBetaKeyras: 0.1799\n",
            "Epoch 232/300\n",
            "5/5 [==============================] - 2s 519ms/step - loss: 0.5177 - fBetaKeyras: 0.1450 - val_loss: 0.4888 - val_fBetaKeyras: 0.2256\n",
            "Epoch 233/300\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 0.5474 - fBetaKeyras: 0.1692 - val_loss: 0.5037 - val_fBetaKeyras: 0.1621\n",
            "Epoch 234/300\n",
            "5/5 [==============================] - 2s 402ms/step - loss: 0.5146 - fBetaKeyras: 0.1902 - val_loss: 0.5608 - val_fBetaKeyras: 0.2099\n",
            "Epoch 235/300\n",
            "5/5 [==============================] - 2s 410ms/step - loss: 0.5506 - fBetaKeyras: 0.1586 - val_loss: 0.4996 - val_fBetaKeyras: 0.2397\n",
            "Epoch 236/300\n",
            "5/5 [==============================] - 2s 417ms/step - loss: 0.5102 - fBetaKeyras: 0.1816 - val_loss: 0.4862 - val_fBetaKeyras: 0.2183\n",
            "Epoch 237/300\n",
            "5/5 [==============================] - 2s 420ms/step - loss: 0.5255 - fBetaKeyras: 0.1952 - val_loss: 0.4897 - val_fBetaKeyras: 0.2377\n",
            "Epoch 238/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.5052 - fBetaKeyras: 0.1863 - val_loss: 0.4889 - val_fBetaKeyras: 0.2027\n",
            "Epoch 239/300\n",
            "5/5 [==============================] - 2s 400ms/step - loss: 0.5048 - fBetaKeyras: 0.1815 - val_loss: 0.4874 - val_fBetaKeyras: 0.1969\n",
            "Epoch 240/300\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.5392 - fBetaKeyras: 0.1474 - val_loss: 0.4828 - val_fBetaKeyras: 0.2103\n",
            "Epoch 241/300\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.4998 - fBetaKeyras: 0.1954 - val_loss: 0.5007 - val_fBetaKeyras: 0.2162\n",
            "Epoch 242/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.5037 - fBetaKeyras: 0.1881 - val_loss: 0.5040 - val_fBetaKeyras: 0.1432\n",
            "Epoch 243/300\n",
            "5/5 [==============================] - 2s 511ms/step - loss: 0.5162 - fBetaKeyras: 0.2014 - val_loss: 0.4856 - val_fBetaKeyras: 0.2080\n",
            "Epoch 244/300\n",
            "5/5 [==============================] - 2s 405ms/step - loss: 0.4962 - fBetaKeyras: 0.1803 - val_loss: 0.5322 - val_fBetaKeyras: 0.1845\n",
            "Epoch 245/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.5396 - fBetaKeyras: 0.1868 - val_loss: 0.4867 - val_fBetaKeyras: 0.2288\n",
            "Epoch 246/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.5075 - fBetaKeyras: 0.1793 - val_loss: 0.4779 - val_fBetaKeyras: 0.1884\n",
            "Epoch 247/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.5071 - fBetaKeyras: 0.2070 - val_loss: 0.4904 - val_fBetaKeyras: 0.1597\n",
            "Epoch 248/300\n",
            "5/5 [==============================] - 2s 517ms/step - loss: 0.5248 - fBetaKeyras: 0.1842 - val_loss: 0.4820 - val_fBetaKeyras: 0.2154\n",
            "Epoch 249/300\n",
            "5/5 [==============================] - 2s 533ms/step - loss: 0.5180 - fBetaKeyras: 0.1560 - val_loss: 0.4882 - val_fBetaKeyras: 0.1949\n",
            "Epoch 250/300\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.4817 - fBetaKeyras: 0.1906 - val_loss: 0.4751 - val_fBetaKeyras: 0.1973\n",
            "Epoch 251/300\n",
            "5/5 [==============================] - 2s 550ms/step - loss: 0.5069 - fBetaKeyras: 0.2153 - val_loss: 0.4974 - val_fBetaKeyras: 0.2026\n",
            "Epoch 252/300\n",
            "5/5 [==============================] - 2s 554ms/step - loss: 0.5081 - fBetaKeyras: 0.1599 - val_loss: 0.4733 - val_fBetaKeyras: 0.1905\n",
            "Epoch 253/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.4916 - fBetaKeyras: 0.1978 - val_loss: 0.5062 - val_fBetaKeyras: 0.1322\n",
            "Epoch 254/300\n",
            "5/5 [==============================] - 2s 558ms/step - loss: 0.5131 - fBetaKeyras: 0.1565 - val_loss: 0.4837 - val_fBetaKeyras: 0.1532\n",
            "Epoch 255/300\n",
            "5/5 [==============================] - 2s 440ms/step - loss: 0.5066 - fBetaKeyras: 0.1566 - val_loss: 0.4820 - val_fBetaKeyras: 0.2426\n",
            "Epoch 256/300\n",
            "5/5 [==============================] - 2s 431ms/step - loss: 0.5067 - fBetaKeyras: 0.1896 - val_loss: 0.4838 - val_fBetaKeyras: 0.1932\n",
            "Epoch 257/300\n",
            "5/5 [==============================] - 2s 548ms/step - loss: 0.5043 - fBetaKeyras: 0.1633 - val_loss: 0.4717 - val_fBetaKeyras: 0.1919\n",
            "Epoch 258/300\n",
            "5/5 [==============================] - 2s 436ms/step - loss: 0.4927 - fBetaKeyras: 0.1994 - val_loss: 0.4856 - val_fBetaKeyras: 0.1876\n",
            "Epoch 259/300\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.4970 - fBetaKeyras: 0.2051 - val_loss: 0.4931 - val_fBetaKeyras: 0.1596\n",
            "Epoch 260/300\n",
            "5/5 [==============================] - 2s 520ms/step - loss: 0.4979 - fBetaKeyras: 0.1262 - val_loss: 0.4925 - val_fBetaKeyras: 0.1801\n",
            "Epoch 261/300\n",
            "5/5 [==============================] - 2s 515ms/step - loss: 0.5155 - fBetaKeyras: 0.1801 - val_loss: 0.4758 - val_fBetaKeyras: 0.2115\n",
            "Epoch 262/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.5089 - fBetaKeyras: 0.1665 - val_loss: 0.4707 - val_fBetaKeyras: 0.2372\n",
            "Epoch 263/300\n",
            "5/5 [==============================] - 2s 424ms/step - loss: 0.5004 - fBetaKeyras: 0.1962 - val_loss: 0.4805 - val_fBetaKeyras: 0.1637\n",
            "Epoch 264/300\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.4827 - fBetaKeyras: 0.1684 - val_loss: 0.4834 - val_fBetaKeyras: 0.2412\n",
            "Epoch 265/300\n",
            "5/5 [==============================] - 2s 548ms/step - loss: 0.5036 - fBetaKeyras: 0.2809 - val_loss: 0.4703 - val_fBetaKeyras: 0.1727\n",
            "Epoch 266/300\n",
            "5/5 [==============================] - 2s 438ms/step - loss: 0.4915 - fBetaKeyras: 0.2043 - val_loss: 0.4816 - val_fBetaKeyras: 0.2177\n",
            "Epoch 267/300\n",
            "5/5 [==============================] - 2s 546ms/step - loss: 0.4952 - fBetaKeyras: 0.1394 - val_loss: 0.4728 - val_fBetaKeyras: 0.1803\n",
            "Epoch 268/300\n",
            "5/5 [==============================] - 2s 553ms/step - loss: 0.4912 - fBetaKeyras: 0.2085 - val_loss: 0.4669 - val_fBetaKeyras: 0.1604\n",
            "Epoch 269/300\n",
            "5/5 [==============================] - 2s 443ms/step - loss: 0.5084 - fBetaKeyras: 0.1684 - val_loss: 0.4648 - val_fBetaKeyras: 0.1611\n",
            "Epoch 270/300\n",
            "5/5 [==============================] - 2s 437ms/step - loss: 0.4826 - fBetaKeyras: 0.1695 - val_loss: 0.4788 - val_fBetaKeyras: 0.1350\n",
            "Epoch 271/300\n",
            "5/5 [==============================] - 2s 432ms/step - loss: 0.4871 - fBetaKeyras: 0.1541 - val_loss: 0.4737 - val_fBetaKeyras: 0.2114\n",
            "Epoch 272/300\n",
            "5/5 [==============================] - 2s 425ms/step - loss: 0.4839 - fBetaKeyras: 0.1794 - val_loss: 0.4645 - val_fBetaKeyras: 0.1773\n",
            "Epoch 273/300\n",
            "5/5 [==============================] - 2s 433ms/step - loss: 0.4891 - fBetaKeyras: 0.1892 - val_loss: 0.4631 - val_fBetaKeyras: 0.1662\n",
            "Epoch 274/300\n",
            "5/5 [==============================] - 2s 411ms/step - loss: 0.4860 - fBetaKeyras: 0.1486 - val_loss: 0.4944 - val_fBetaKeyras: 0.1966\n",
            "Epoch 275/300\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.5183 - fBetaKeyras: 0.1421 - val_loss: 0.4727 - val_fBetaKeyras: 0.1766\n",
            "Epoch 276/300\n",
            "5/5 [==============================] - 2s 513ms/step - loss: 0.5018 - fBetaKeyras: 0.1765 - val_loss: 0.4652 - val_fBetaKeyras: 0.1849\n",
            "Epoch 277/300\n",
            "5/5 [==============================] - 2s 414ms/step - loss: 0.4854 - fBetaKeyras: 0.2024 - val_loss: 0.4662 - val_fBetaKeyras: 0.1540\n",
            "Epoch 278/300\n",
            "5/5 [==============================] - 2s 404ms/step - loss: 0.4780 - fBetaKeyras: 0.1586 - val_loss: 0.4862 - val_fBetaKeyras: 0.1444\n",
            "Epoch 279/300\n",
            "5/5 [==============================] - 2s 407ms/step - loss: 0.5049 - fBetaKeyras: 0.1425 - val_loss: 0.4665 - val_fBetaKeyras: 0.1674\n",
            "Epoch 280/300\n",
            "5/5 [==============================] - 2s 420ms/step - loss: 0.4879 - fBetaKeyras: 0.1854 - val_loss: 0.4846 - val_fBetaKeyras: 0.1930\n",
            "Epoch 281/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.5165 - fBetaKeyras: 0.1428 - val_loss: 0.4589 - val_fBetaKeyras: 0.1811\n",
            "Epoch 282/300\n",
            "5/5 [==============================] - 2s 401ms/step - loss: 0.4878 - fBetaKeyras: 0.1780 - val_loss: 0.5012 - val_fBetaKeyras: 0.1848\n",
            "Epoch 283/300\n",
            "5/5 [==============================] - 2s 409ms/step - loss: 0.5022 - fBetaKeyras: 0.1985 - val_loss: 0.4866 - val_fBetaKeyras: 0.1470\n",
            "Epoch 284/300\n",
            "5/5 [==============================] - 2s 516ms/step - loss: 0.5212 - fBetaKeyras: 0.1508 - val_loss: 0.4610 - val_fBetaKeyras: 0.1869\n",
            "Epoch 285/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.4949 - fBetaKeyras: 0.1900 - val_loss: 0.4634 - val_fBetaKeyras: 0.2111\n",
            "Epoch 286/300\n",
            "5/5 [==============================] - 2s 412ms/step - loss: 0.4812 - fBetaKeyras: 0.1884 - val_loss: 0.4636 - val_fBetaKeyras: 0.2236\n",
            "Epoch 287/300\n",
            "5/5 [==============================] - 2s 408ms/step - loss: 0.5007 - fBetaKeyras: 0.1961 - val_loss: 0.4733 - val_fBetaKeyras: 0.1998\n",
            "Epoch 288/300\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.4736 - fBetaKeyras: 0.1783 - val_loss: 0.5035 - val_fBetaKeyras: 0.1906\n",
            "Epoch 289/300\n",
            "5/5 [==============================] - 2s 406ms/step - loss: 0.4981 - fBetaKeyras: 0.1756 - val_loss: 0.5133 - val_fBetaKeyras: 0.1502\n",
            "Epoch 290/300\n",
            "5/5 [==============================] - 2s 410ms/step - loss: 0.5224 - fBetaKeyras: 0.1675 - val_loss: 0.5193 - val_fBetaKeyras: 0.2092\n",
            "Epoch 291/300\n",
            "5/5 [==============================] - 2s 413ms/step - loss: 0.5344 - fBetaKeyras: 0.1865 - val_loss: 0.4597 - val_fBetaKeyras: 0.2106\n",
            "Epoch 292/300\n",
            "5/5 [==============================] - 2s 426ms/step - loss: 0.4813 - fBetaKeyras: 0.2214 - val_loss: 0.4646 - val_fBetaKeyras: 0.1582\n",
            "Epoch 293/300\n",
            "5/5 [==============================] - 2s 428ms/step - loss: 0.4607 - fBetaKeyras: 0.1927 - val_loss: 0.4665 - val_fBetaKeyras: 0.2332\n",
            "Epoch 294/300\n",
            "5/5 [==============================] - 2s 428ms/step - loss: 0.4781 - fBetaKeyras: 0.1705 - val_loss: 0.4875 - val_fBetaKeyras: 0.2430\n",
            "Epoch 295/300\n",
            "5/5 [==============================] - 2s 552ms/step - loss: 0.5121 - fBetaKeyras: 0.1668 - val_loss: 0.4608 - val_fBetaKeyras: 0.2377\n",
            "Epoch 296/300\n",
            "5/5 [==============================] - 2s 441ms/step - loss: 0.4934 - fBetaKeyras: 0.1948 - val_loss: 0.4557 - val_fBetaKeyras: 0.2021\n",
            "Epoch 297/300\n",
            "5/5 [==============================] - 2s 439ms/step - loss: 0.4843 - fBetaKeyras: 0.1838 - val_loss: 0.4667 - val_fBetaKeyras: 0.1972\n",
            "Epoch 298/300\n",
            "5/5 [==============================] - 2s 430ms/step - loss: 0.4781 - fBetaKeyras: 0.2123 - val_loss: 0.4690 - val_fBetaKeyras: 0.1266\n",
            "Epoch 299/300\n",
            "5/5 [==============================] - 2s 548ms/step - loss: 0.4872 - fBetaKeyras: 0.2003 - val_loss: 0.4645 - val_fBetaKeyras: 0.1662\n",
            "Epoch 300/300\n",
            "5/5 [==============================] - 2s 555ms/step - loss: 0.4985 - fBetaKeyras: 0.1690 - val_loss: 0.4682 - val_fBetaKeyras: 0.1953\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/keras/engine/training.py:1948: UserWarning: `Model.evaluate_generator` is deprecated and will be removed in a future version. Please use `Model.evaluate`, which supports generators.\n",
            "  warnings.warn('`Model.evaluate_generator` is deprecated and '\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "2/2 [==============================] - 0s 70ms/step - loss: 0.4682 - fBetaKeyras: 0.2020\n",
            "> loss=0.468, fbeta=0.202\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeoAAAGrCAYAAAAPadTzAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOzdd5xkVZ3//9enQuccpidn0ggyQJMRicKYAHERFcMacNew7Lqi+DP81H0Y1rTILsqioCgqiwiIkkdyHHqGASYxOfT0TOdUXbnqfP84t7qqezrOVFdVd32ej0c9qrrCvaduV9X7fs49914xxqCUUkqp3OTKdgOUUkopNToNaqWUUiqHaVArpZRSOUyDWimllMphGtRKKaVUDtOgVkoppXKYBrVSSimVwzSolZokEfmQiDSJiE9EDojIwyJyThbbs1tEAk57Epf/meBrnxKRT011GydCRD4uIs9lux1K5RpPthug1HQiIl8EbgD+CXgUCAOXApcBh4SMiHiMMdEMNO09xpjV6Z5oBtuvlBqFVtRKTZCIVALfAT5njLnXGDNgjIkYY/5qjLneec63ROQeEblTRPqAj4vIXBF5QES6RGS7iHw6ZZqnOdV5n4i0ishPnfuLnGl0ikiPiLwiIg2H0eaPi8hzIvJjEekWkV0issp57LvA24D/Sa3CRcSIyOdEZBuwzbnv007bu5z3MjdlHkZE/kVEdopIh4j8SERcIlLgPP+ElOfOEhG/iNRP8n2c5SyDXuf6rGHvcaeI9Dvv78PO/ctF5GnnNR0i8n+TXX5K5QINaqUm7kygCLhvnOddBtwDVAG/B+4CmoG5wPuB74nIBc5zfwb8zBhTASwD7nbu/xhQCSwAarEVfOAw23068CZQB/wQuE1ExBjzNeBZ4PPGmDJjzOdTXnO587oVTlu/D1wFzAH2OO8p1RVAI3Cy8/4/YYwJO8+7JuV5HwT+boxpn2jjRaQGeBC4Cbssfgo8KCK1IlLq3L/KGFMOnAWsd176H8BjQDUwH/jvic5TqVyiQa3UxNUCHRPoCn7RGHO/MSaODcezga8YY4LGmPXAr4CPOs+NAMtFpM4Y4zPGvJRyfy2w3BgTM8asNcb0jTHP+53KO3H5dMpje4wxvzTGxIA7sGE7XnX+fWNMlzEmAHwYuN0Ys84YEwK+CpwpIotTnv+fzvP3AjdiAxlnfh8UEXH+/gjwu3HmPdy7gG3GmN8ZY6LGmD8CW4D3OI/HgeNFpNgYc8AYs9G5PwIsAuY6y163f6tpSYNaqYnrBOpEZLyxHftSbs8Fuowx/Sn37QHmObc/CRwNbHG6dN/t3P877Dbwu0SkRUR+KCLeMeZ5uTGmKuXyy5THDiZuGGP8zs2ySb6HPSnT8GGXxbxRnr/HeQ3GmJcBP3CeiBwLLAceGGfeww2Zf8o85hljBoAPYHscDojIg858AL4MCLBGRDaKyCcmOV+lcoIGtVIT9yIQwnYLjyX1lHQtQI2IlKfctxDYD2CM2WaM+SAwC/hP4B4RKXW2fX/bGLMC2537bpJVeDqNdvq84e9hUeIPp7u5NvEeHAtSbi90XpNwB7b7+yPAPcaY4CTbOGT+KfNILMNHjTEXY3sKtgC/dO4/aIz5tDFmLvAZ4OcisnyS81Yq6zSolZogY0wv8E3gZhG5XERKRMQrIqtE5IejvGYf8ALwfWeA2FuxVfSdACJyjYjUO93kPc7L4iJyvoicICJuoA/bjRufgrfVCiwd5zl/BP5RRFaKSCHwPeBlY8zulOdcLyLVIrIAuA5IHbh1J3Yb9jXAb8eZlzjLafACPAQcLXa3OI+IfABYAfxNRBpE5DJn5SEE+HCWk4j8g4jMd6bbjV35mIplqNSU0qBWahKMMT8Bvgh8HWjHdvl+Hrh/jJd9EFiMrQzvA/7/lF2pLgU2iogPO7Dsame78GzsgLQ+YDPwNGNv2/2rDN2PerwBbwk/A97vjAi/aaQnOG39BvBn4AB20NvVw572F2AtdiDXg8BtKa/fB6zDBuWz47TnLOygudRLL7ZH4d+xXe5fBt5tjOnA/oZ9Ebtsu4C3A//sTOtU4GVn2T4AXGeM2TnO/JXKOWLMaD1fSik1PhExwFHGmO1jPOd2oMUY8/XMtUypmUEPeKKUmlLO6PD3ASdltyVKTU/a9a2UmjIi8h/ABuBHxphd2W6PUtORdn0rpZRSOUwraqWUUiqH5dw26rq6OrN48eJsN0MppZTKmLVr13YYY0Y8Bn7OBfXixYtpamrKdjOUUkqpjBGR4UffG6Rd30oppVQO06BWSimlcpgGtVJKKZXDcm4btVJKqfwSiURobm4mGJzs+Vqmn6KiIubPn4/XO9bJ8IbSoFZKKZVVzc3NlJeXs3jxYpKnLp95jDF0dnbS3NzMkiVLJvy6Gd31HYvBpz4Ff/1rtluilFJqNMFgkNra2hkd0gAiQm1t7aR7DmZ0UIvAbbfBunXZbolSSqmxzPSQTjic9zmjg9rlspdoNNstUUoppQ7PjA5qAI9Hg1oppdTYenp6+PnPfz7p173zne+kp6dnClqUlJGgFpEqEblHRLaIyGYROTMT8wUNaqWUUuMbLaij4wTIQw89RFVV1VQ1C8jcqO+fAY8YY94vIgVASYbmq0GtlFJqXDfccAM7duxg5cqVeL1eioqKqK6uZsuWLWzdupXLL7+cffv2EQwGue6667j22muB5GGvfT4fq1at4pxzzuGFF15g3rx5/OUvf6G4uPiI2zblQS0ilcC5wMcBjDFhIDzV803QoFZKqenjX/8V1q9P7zRXroQbbxz7OT/4wQ/YsGED69ev56mnnuJd73oXGzZsGNyN6vbbb6empoZAIMCpp57KlVdeSW1t7ZBpbNu2jT/+8Y/88pe/5KqrruLPf/4z11xzzRG3PxNd30uAduDXIvKqiPxKREpTnyAi14pIk4g0tbe3p3XmHg9EImmdpFJKqRnutNNOG7Kv80033cSJJ57IGWecwb59+9i2bdshr1myZAkrV64E4JRTTmH37t1paUsmur49wMnAF4wxL4vIz4AbgG8knmCMuRW4FaCxsdGkdeZaUSul1LQxXuWbKaWlyXryqaeeYvXq1bz44ouUlJRw3nnnjbgvdGFh4eBtt9tNIBBIS1syUVE3A83GmJedv+/BBndGaFArpZQaT3l5Of39/SM+1tvbS3V1NSUlJWzZsoWXXnopo22b8oraGHNQRPaJyDHGmDeBC4FNUz3fBK9Xg1oppdTYamtrOfvsszn++OMpLi6moaFh8LFLL72UW265heOOO45jjjmGM844I6Nty9So7y8Av3dGfO8E/jFD89WKWiml1IT84Q9/GPH+wsJCHn744REfS2yHrqurY8OGDYP3f+lLX0pbuzIS1MaY9UBjJuY1nAa1Ukqp6UyPTKaUUkrlMA1qpZRSKodpUCullFI5TINaKaWUymEa1EoppVQO06BWSimV9w73NJcAN954I36/P80tStKgVkoplfdyOagzdcCTrNGgVkopNZ7U01xefPHFzJo1i7vvvptQKMQVV1zBt7/9bQYGBrjqqqtobm4mFovxjW98g9bWVlpaWjj//POpq6vjySefTHvb8iKo9exZSik1Taz9V+hO83kuq1fCKWOf7SP1NJePPfYY99xzD2vWrMEYw3vf+16eeeYZ2tvbmTt3Lg8++CBgjwFeWVnJT3/6U5588knq6urS226Hdn0rpZRSKR577DEee+wxTjrpJE4++WS2bNnCtm3bOOGEE3j88cf5yle+wrPPPktlZWVG2pMXFbUGtVJKTRPjVL6ZYIzhq1/9Kp/5zGcOeWzdunU89NBDfP3rX+fCCy/km9/85pS3Z8ZX1Hr2LKWUUuNJPc3lJZdcwu23347P5wNg//79tLW10dLSQklJCddccw3XX38969atO+S1U0EraqWUUnkv9TSXq1at4kMf+hBnnnkmAGVlZdx5551s376d66+/HpfLhdfr5Re/+AUA1157LZdeeilz586dksFkYoxJ+0SPRGNjo2lqakrb9D79aXjoIdi/P22TVEoplUabN2/muOOOy3YzMmak9ysia40xI55lcsZ3fWtFrZRSajrToFZKKaVymAa1UkqprMu1zbBT5XDepwa1UkqprCoqKqKzs3PGh7Uxhs7OToqKiib1uoyM+haR3UA/EAOio20wnwoa1Eopldvmz59Pc3Mz7e3t2W7KlCsqKmL+/PmTek0md8863xjTkcH5ARrUSimV67xeL0uWLMl2M3JWXnR9x+P2opRSSk03mQpqAzwmImtF5NrhD4rItSLSJCJN6e768Dh9BrFYWierlFJKZUSmgvocY8zJwCrgcyJybuqDxphbjTGNxpjG+vr6tM44EdR6Bi2llFLTUUaC2hiz37luA+4DTsvEfCEZ1LqdWiml1HQ05UEtIqUiUp64DbwD2DDV803QoFZKKTWdZWLUdwNwn4gk5vcHY8wjGZgvYM+eBRrUSimlpqcpD2pjzE7gxKmez2i0olZKKTWd5cXuWaBBrZRSanrSoFZKKaVymAa1UkoplcM0qJVSSqkcpkGtlFJK5TANaqWUUiqHaVArpZRSOUyDWimllMphGtRKKaVUDsuboNazZymllJqO8iaotaJWSik1HWlQK6WUUjlsxge1nj1LKaXUdDbjg1oraqWUUtOZBrVSSimVwzSolVJKqRymQa2UUkrlMA1qpZRSKodpUCullFI5LGNBLSJuEXlVRP6WqXmCBrVSSqnpLZMV9XXA5gzOD9CgVkopNb1lJKhFZD7wLuBXmZhfKg1qpZRS01mmKuobgS8D8ZEeFJFrRaRJRJra29vTOmMNaqWUUtPZlAe1iLwbaDPGrB3tOcaYW40xjcaYxvr6+rTOX8+epZRSajrLREV9NvBeEdkN3AVcICJ3ZmC+ALjd9loraqWUUtPRlAe1Mearxpj5xpjFwNXAE8aYa6Z6vgkul71oUCullJqOZvx+1GDPoKVBrZRSajryZHJmxpingKcyOU+w26k1qJVSSk1HeVFRa1ArpZSarjSolVJKqRymQa2UUkrlMA1qpZRSKodpUCullFI5TINaKaWUymEa1EoppVQO06BWSimlcpgGtVJKKZXD8iao9exZSimlpqO8CWqtqJVSSk1HGtRKKaVUDtOgVkoppXJYXgS1nuZSKaXUdJUXQa0VtVJKqelKg1oppZTKYRrUSimlVA7ToFZKKaVy2JQHtYgUicgaEXlNRDaKyLenep7Deb0QCmV6rkoppdSR82RgHiHgAmOMT0S8wHMi8rAx5qUMzBuAsjIYGMjU3JRSSqn0mfKgNsYYwOf86XUuZqrnm6q8HPr7MzlHpZRSKj0yso1aRNwish5oAx43xrw87PFrRaRJRJra29vTPv/ycltRx+Npn7RSSik1pTIS1MaYmDFmJTAfOE1Ejh/2+K3GmEZjTGN9fX3a519WZq99vrGfp5RSSuWajI76Nsb0AE8Cl2ZkhrEw/Lmec2p+BGhQK6WUmn4yMeq7XkSqnNvFwMXAlqmeLwAuL0R6KS/qAnQ7tVJKqeknE6O+5wB3iIgbu2JwtzHmbxmYL4iAp5wSYxNag1oppdR0k4lR368DJ031fEblraA43gdo17dSSqnpZ+YfmcxbTqFLK2qllFLTUx4EdQUFLltRa1ArpZSabmZ+UHvK8WITWru+lVJKTTczP6i9FbjjWlErpZSanvIiqF1x3UatlFJqepr5Qe0pRyJ9lJRo17dSSqnpZ+YHtbcCoj4qKuJaUSullJp28iCoywFoqPFpUCullJp28iCoKwBoqOnTrm+llFLTzswPao+tqGdV92tFrZRSatqZ+UHtVNR1lX0a1EoppaadPAhqW1HXVvZr17dSSqlpJw+C2lbUNeVaUSullJp+8iCobUVdVarbqJVSSk0/Mz+oPbairiixo76NyXJ7lFJKqUmY+UHtVNQVxf0YA35/ltujlFJKTcLMD2p3IbgKKCvUE3MopZSafmZ+UAN4yyktsEGtI7+VUkpNJ1Me1CKyQESeFJFNIrJRRK6b6nkewlNBideW0n19GZ+7UkopddgyUVFHgX83xqwAzgA+JyIrMjDfJG855cU2oXfsyOiclVJKqSMy5UFtjDlgjFnn3O4HNgPzpnq+Q3grKC/qRwQ2bcronJVSSqkjktFt1CKyGDgJeHnY/deKSJOINLW3t6d/xp5y3PE+li7VoFZKKTW9ZCyoRaQM+DPwr8aYIVuKjTG3GmMajTGN9fX16Z950Szo28p5p+5m48b0T14ppZSaKhkJahHxYkP698aYezMxzyGO/zqIi29f9D527QgTiWS8BUoppdRhycSobwFuAzYbY3461fMbUflyOOVnzCt+lRMXNLF9e1ZaoZRSSk1aJirqs4GPABeIyHrn8s4MzHeoyrcAUFfeoduplVJKTRueqZ6BMeY5QKZ6PuMqrAOgrryTjRvhyiuz3B6llFJqAvLjyGQAhbUALJ3Xyc6dWW6LUkopNUH5E9SeMnAVsGh2B/v2ZbsxSiml1MTkT1CLQGEtc2s7NaiVUkpNG/kT1AAFtcyq7KC5Wc9LrZRSanrIr6AurKO6tJNAALq6st0YpZRSanx5FtS1VBR2Amj3t1JKqWkh74K62NUBaFArpZSaHvIsqOvwxDoBo0GtlFJqWsivoC6oRYhRW9GrQa2UUmpayK+gdo5OtmKZ7qKllFJqesizoLZHJzt2iQa1Ukqp6SEvg3r5Aj06mVJKqekhz4Ladn0vndfJnj0QDGa5PUoppdQ48iyokxV1PI6e7lIppVTOy6+g9laCuJk/yx705I03stwepZRSahz5FdTigtIl1MirFBXB669nu0FKKaXU2PIrqAHmvQtX69855cQBDWqllFI5Lw+D+r0QD3HV21dr17dSSqmcN+VBLSK3i0ibiGyY6nlNyKy3gbeSC45+gNZWaGvLdoOUUkqp0WWiov4NcGkG5jMxLi/MXcVRpQ8Chtdey3aDlFJKqdFNeVAbY54Bcuvszw3nUxhvZfnsHbz0UrYbo5RSSo0u/7ZRA9SdBcBV57/ACy9kuS1KKaXUGHIiqEXkWhFpEpGm9vb2qZ9h5QrwVnLJyS/w4osQj0/9LJVSSqnDkRNBbYy51RjTaIxprK+vn/oZigvqzuSEOc/T2wubN0/9LJVSSqnDkRNBnRV1Z1ElG6ks6dHub6WUUjkrE7tn/RF4EThGRJpF5JNTPc8JmXUOguHTF9/FX/+a7cYopZRSI8vEqO8PGmPmGGO8xpj5xpjbpnqeEzLr7dBwAd99/5fYtGY7Tz+d7QYppZRSh8rfrm9xwRm/wVvo5flvncsff/Iwra3ZbpRSSik1VP4GNUDpAuSipyipruWWq9/J6u99mkd+9Rf2r3+OgQObMYE2iEez07a+rTCwN33T23sPPHMFRHzpm6ZSSqkpJ8aYbLdhiMbGRtPU1JTZmcZCtK3+JnUdP8Ilhy6PHn8VbX2z2Nu1lEJvlMpSP66CIjp9DXQMzKE/XEs46mWgd4Cq0n7mzeqntNCHxxOjPzqXg4EVeGOdEBvARIN4XCHmzwkRddeza381LS1RYgULqaopoKZygOXVr3BK+c0YXGzyf5hn27/I8oVdFHhjHPQtYeH8MK+/GiDQ72fOHAjFqzmr9KuUu3fzfM83kQWXUet+je59u/jr2lVc+e52Lom9FVfMxxO7PsKG4pu56JJSEBeJf39JCbjd8MIL8Ja3wAknJN9/NAqxGBQW2r/jcejthcpKcI2zqmcM0LcFtv2C1yPXU7dwPvPmjf8vCQbB47EX4hH27PPS0ABFRRP6jyql1LQiImuNMY0jPqZBnWT8rWxZ38y+bZ2E+jqJ+jsxwQ7KCzqZVXGQau9OQpFC+vwlmGiAhsqD1JceoMgbGJxGMFqCL1jOQLiMSNTDvOo9FHuDAMSNEI4WEY4VEgx7qSntwuOOjdiWW/7+GfyhEv7pwlsoKQyM+JxU/lAxzV3zOXrONgaCJZQW+W17IoWEowUYI/z++Q/z2Yt/AUCXr5qXd5yOP1TC8obtuF0x3jxwDP5wCZGol9JyL56CAvp9Lo6qXUtVSQ8bet5DxLuQXTvCRAM9zKro4PhFbxIzxWw6eBKdfWW4PEV4Cgop9vSxcvZqenwlXLBiNRXFfezvmst37v8PLnj7AKcufJL7Xr2G17uvYOWJcXp7oixZVkBFhfD8U710v3E/u9sW8vn3/h/vWfFrfvDAl/nLm1/kX/69guqSTiKueqqqhcJC6OmBY4+Fgd4B2ndsxuDmr08fSzhWzNlnw+zZcOKJUFdnVxz8frtiIgKBAPzmN+D1wqpVDK5ExGL2NKgPPQTLlsF559npjCQWsysziRWZVK2tUFYGpaUpd+6+C3b8Es75ExTWjPo/TXw1Rcb99yulpjkN6qlkDMRDtovcXQwu99DHY2EI7IeiWeAuGfzVDYdBTASvKwDiBt9uMDHwlBKIV9Plq0EEKovaKWq9m33di4mZYsrdeznYXsSCxcVU1Rbj64/jDu5G5lyEp3Ix8eaH6N3yMEHvUZQtOIkq/0Ps3d7NG/0fpnDBuVy0/E5adrYRbt9CNetwEcYvi4lEXZSZ7ZQUhYiEIkQjEVxE8LojdEWPwR8pZ1nZ07hdyaPDBGMVHBg4ikLpZ2751kMWTYvvGLyeGF2Bedz24lf4+iWfpcK9G4DO/hpqy7uIxtyDKyvhqJeegSpKiwYoLfQPTufZLefwtmOfIx4XQtFCiguCtPbOAqCqpAdfsIy9nQs5avY2yooGBqe1t3MxHf019AxUUeQN4vEY+vxl9AXKaffNoye6lN2tDdQXbafTV8uWlhWcdLKb/c1Rzln0Z05c+BpPb3k7+zoXsLt9Me7SBs499jnafXPY1b4Ut0c45lhhzRphoC/IWY1dLJvfxa72pby6+ySiMRfPPw+zZsGX/s1PZeAJqj1buWLxV3C7ojzd8hluffUW+vttL8UZZxg+dPJN1Jfs4s87vscNXyuhrAw++lH4wAdsj0dHB7S325WThQth5UrbswF2hSEUsr0Ow3s6AgH4r/+Cbdvghz+E+no7z3B4cr0UsZhth1IqvTSoVXpE/RDpBVcheCvA5Uk+FgtDPAixkF1xETcUzxn6+ngMfDuIROLs7lzOMvkt+HYQCBdSVOyhu60fE+6mvMJD0TEfhlAbQWlg3Z4zOPPoNUT3PUpPey8Rz1wKA28QCnsIxGsp8fYR6dlNyL0A9/xLiMXiLC5vwh3cjb+nm1iwh97+IkJhocTro9jTR5mrmQL36D0VMeOh1xxHtWsDwuS/I8FIMV3+BspKQviDbsq83YMrEev3ncKG5pP50Om/4qlt76S4MIwQw0T8nHmUPfj8hn1vYWffmRR4o+zaW8yaHafS46/i2LlbWFi7l93tizlmzpuUFAaIuuuJRN28svU4trYsxeWKU1wYp6gozsL6FlYuWMuy2tdYu+skfvH3z1NfG+GGK29h175y/vvhT9F43jJ6OvrZvcdLlBIWL4ZlywztB/zs2h7kI5+sorPLzX33wRuvx5gz182xx8LSpVBaatiwATweYeVKaGyEO+6wKwCnnWZoahI+ePHL1Fb28dtHL+TyK1wsXw7h/c+wuPsG/rTjJ/R4zuSEE2DFCrsC0doKb7wBW7fCggW2N+TYY+1yXbPGroyceiqUF3Twk5+Vs2ZtIZdcAu9+t10h6euzK0ef/KSd5o9/bNePw2F45BHYsAHe977kNIczBp5+2s572TL7980322leddUkPgR9b8K6L8LJN0LFUcmJT2UXSbgbcEFB5dTNQ00JDWqlhjMGggchcBDKlkKwDXw7AGMfqz4RSuZBpB9CnfZHN7Af6s+BUDsEWpy+aef74yqAwlrwVkLPG9C1DkJt4C4iHo8TCBdTcvT7kPIlULIQYgF44cPgb7YrPi430UA/m4MfZV/fMZxb8f9R6ulAXB7ioV5csb7BpkddlXjivYSllv5QFUV04HZFKPL4R3yrA5FK2kIrWFTWhIsIAMFIEV53BLcrNtirETdCb7ABj8tPidc32HsSjwtdAzV4PFBR1EV7YAkHuufioZ9jZ28YfG0s5iYS87LpwFspKxpgSe1WdncdxTENGwHY3bGEB19dxYGeOXz53T+korif/mAZj75+CQD3vXIF/cFySgr8uFxxegaqmFN1gOWzt1Nf3s7ezoXsaF2GL1TGRW9ZzWcv/jn7Ohfwu5f+mZ0ts1i76xSuOPU+Tl68jhe2ncMTGy+ktbeOK98Xxy+LuPdeoaPDUFo4QHlxPxed28fpJ/dRHn6F8+fdxPbWo/n1i//G+uaz2bC5AK8XPv2JEOXRV/nvO0/AHyrl/PPtisKePYaLTniKC09Zz+PbriEW97Dy6P3UzCrja99fxIIFcN8XLmK+5wm2dp3Ot194jg+97S9cXHUtzeVf5vaXvsymTcKqVXD11XaaL71kVywKvDH27BF27HTh9UJxcfJS4A7y2GoPBw56+MQn7IqRCAwMwPOP7+OCyBkEI0V85+U1vOt9tezbZzfJvO99tickdTNNPG5fK/EQ7L2HrpL3EIpXMHu2/WgHAra3JR09KH6/HW9SUHDk00qrqN/2hObA9iUNaqWmMxOH/h0Q9UHJfCissz0b3srkD4wxdkUj0GJ7M3DZ68IauyIiLrt5pe0piIdh3mW256PlIczAXqSgGmJ+8O8DdynGWwGecnAXsm97F5XF7VSWx+3KSP92u7LiKrQrNK4iMDGCwTitLX7mFTfh9hYSLlpBYXAje8IX0R9fwltKfkvs4DN4zAABz9H4T/o9NbuuwwTaiAb9FMRaRnz7MbwEYtWUuZMnjzdGeGLPJzhp0VpqZP2Q5/ebxZTL7iH39QYq8HiEEm8/wqEH99/c2sj86p2UF3QRjBbTLyvo7iuivmAj1aU9hOOlHAy9ldY2L7Mq26grPUiptwewKz0FntDgQNQDfYvY3nYcb1v+CH9d927ec/LfePPgCpbP2kKXr4b6ig72d83FF6mis7eSfT1LqSzuZlHNTjbtX8G5xz5DLO7mRw9eT3FBgLqyDqJxDyKGf7rgFvqCFdzbdBVvtiwDbxWe4goCvd184aIfMb+mmUJPiFd2ngRk0I0AACAASURBVMb3/vJVQtFCCjxhGuYUMHdeAc+9UkNNwW4+fP5DuKLtbDlwAu9Y+SynLnicV/ecxAduuoueQB0nLlhLa28D3gIvZ53m45x3H8+u5x9h354w+/yn8o0r/5PW/nn89qkPcLDNy5w5UDN/LjW1BXj9GymJbqam3EdYarn5zxexaWspxcWw6uI+PvWxfpo7ZrPuVTf9PX6WHlVCb6/tRWluhve+1w5mLSiAJUuguxtWP7CXaOs6OryXMGdBMcceC2eeCbMr9nHT/zbQctDDWad288gTtVx22qOctuQFHnr1Yja1n83s2cKJJ9pp3nef4fQ593BWw+0E2zZRJnvZ0nEG//7gat7xzlI+9jGoqoiwZ9NuvvNfy6mrE971LruZKRwGnw9aWmDdOvjIR2z70kWDWimVG0wcYsHBXoRB8Rj0rAfEjuUA241bPAdKFtjnRgMwsMu+vngeFDfYFZRIj+0RaX8eqk6A2lMhcABan4LoAOFwHO/A64i47SYb52I85RhPBa6S2VBzCkQH4OBqaHsaejeCiWFKFhGtuwhv97Pg225XcgpnQVED1DZC9Umw/ZdQ1MCA5xjamztZVPg4dK8j4FrM067VXDj/RrxdTxBgNq97b6Ky604Wlr5MibePvs4eIl3biMRL8FQfRVHwdTrijVQVtlAds5tBYq4KJB7CRYgW7z9QVRaguHc1Eg8OWbRB13we6b2D2RUtnC6fspXyKAbC5QzEGphVvJ1Y3MVtz13Hx8++ZdTNQbG4a+j4lHAhRQVDpx+MFOILllFX3jnk/lC0iL74UgroprLgAGAHswYjJcyt3k9Hfy3bW4+mP76AkqIIR1c9i8cdZX/XPPZ3z6Ojv47LG++ntNBPt7+Gl7efTntfLUfN3sYZy1+mva+OgXAZi+t28/LOszl96fOD8167+3RWv3EeBZ4Q5UX9NC5tYuWi19h2cDlrdpxG50ADn7/4RtbsOZ8XN7+VubWdXHT8ampLDvDsm+dyf9MVFHgCrFy0nsriXgZCpfjDJdSWdVJ06re44B9OG3UZT5YGtVJKTScmDr6dUDwXPCX276jPrmSAXUEJddqelWg/iNeeFTDRwxL1Q+cr9ra7EOIR24MS6gJPGcy+CNwFMLDHrhBVr7Q9JQf/bv+ubYRgB5goUVNI82uvULX8TKpqvND2DL2z/pniwiAFfc48iEPPBkyoE2k43/a0FFRh+nciLX8D3y7wlBIrP4Et28uYW7yWqvIAUrmCaF8zbv9WJNgC8RihijMJxSog2EKsfz8l0oKr/lS8R38c9t6D6XmDiL+PvlANb3RfwcpFr1JR6qcruoK63l/RXbyKNdEbufCYv+Dd+n1MYD8xU0goVgwVK9jQ9w/c8fxn+MhH3Zx+Ori2/Te8+iViFNLRV8OWA8czUHwGlyz9Oe6wXbHoiy8lLLUUuAYocPvxltbibvwxNJyXtn+5BrVSSqmZz8TtZp50vM4Yu9IiAgXV6WnfGMYKas9IdyqllFLTzuGE9GivExnzOAeZlN+HEFVKKaVynAa1UkoplcM0qJVSSqkcpkGtlFJK5TANaqWUUiqH5dzuWSLSDuxJ82TrgI40T3M60+WRpMtiKF0eQ+nyGEqXx1DpXB6LjDH1Iz2Qc0E9FUSkabT90/KRLo8kXRZD6fIYSpfHULo8hsrU8tCub6WUUiqHaVArpZRSOSxfgvrWbDcgx+jySNJlMZQuj6F0eQyly2OojCyPvNhGrZRSSk1X+VJRK6WUUtOSBrVSSimVw2Z0UIvIpSLypohsF5Ebst2ebBCR3SLyhoisF5Em574aEXlcRLY511N/DrcsEZHbRaRNRDak3Dfi+xfrJufz8rqInJy9lk+NUZbHt0Rkv/MZWS8i70x57KvO8nhTRC7JTqunjogsEJEnRWSTiGwUkeuc+/PuMzLGssjLz4eIFInIGhF5zVke33buXyIiLzvv+/9EpMC5v9D5e7vz+OK0NcYYMyMvgBvYASwFCoDXgBXZblcWlsNuoG7YfT8EbnBu3wD8Z7bbOYXv/1zgZGDDeO8feCfwMCDAGcDL2W5/hpbHt4AvjfDcFc73phBY4nyf3Nl+D2leHnOAk53b5cBW533n3WdkjGWRl58P539c5tz2Ai87//O7gaud+28B/tm5/VngFuf21cD/pastM7miPg3YbozZaYwJA3cBl2W5TbniMuAO5/YdwOVZbMuUMsY8A3QNu3u0938Z8FtjvQRUiciczLQ0M0ZZHqO5DLjLGBMyxuwCtmO/VzOGMeaAMWadc7sf2AzMIw8/I2Msi9HM6M+H8z/2OX96nYsBLgDuce4f/tlIfGbuAS4UEUlHW2ZyUM8D9qX83czYH7qZygCPichaEbnWua/BGHPAuX0QaMhO07JmtPefz5+ZzztdubenbArJq+XhdFWehK2c8vozMmxZQJ5+PkTELSLrgTbgcWyvQY8xJuo8JfU9Dy4P5/FeoDYd7ZjJQa2sc4wxJwOrgM+JyLmpDxrbT5O3++jl+/t3/AJYBqwEDgA/yW5zMk9EyoA/A/9qjOlLfSzfPiMjLIu8/XwYY2LGmJXAfGxvwbHZaMdMDur9wIKUv+c79+UVY8x+57oNuA/7YWtNdNc5123Za2FWjPb+8/IzY4xpdX6Q4sAvSXZf5sXyEBEvNph+b4y517k7Lz8jIy2LfP98ABhjeoAngTOxmzs8zkOp73lweTiPVwKd6Zj/TA7qV4CjnBF6BdiN+w9kuU0ZJSKlIlKeuA28A9iAXQ4fc572MeAv2Wlh1oz2/h8APuqM7D0D6E3p/pyxhm1jvQL7GQG7PK52RrMuAY4C1mS6fVPJ2YZ4G7DZGPPTlIfy7jMy2rLI18+HiNSLSJVzuxi4GLvd/kng/c7Thn82Ep+Z9wNPOL0xRy7bI+um8oIdobkVu13ha9luTxbe/1LsqMzXgI2JZYDdbvJ3YBuwGqjJdluncBn8EdtdF8FuT/rkaO8fO8rzZufz8gbQmO32Z2h5/M55v687PzZzUp7/NWd5vAmsynb7p2B5nIPt1n4dWO9c3pmPn5ExlkVefj6AtwKvOu97A/BN5/6l2BWS7cCfgELn/iLn7+3O40vT1RY9hKhSSimVw2Zy17dSSik17WlQK6WUUjlMg1oppZTKYRrUSimlVA7ToFYqD4k9WUtARHwpl7kicqtzgoW4iHw82+1USmlQK5XP3mOMKUu5tGB35fsssC7LbVNKOTzjP0UplS+MMTcDiEgw221RSllaUSullFI5TINaqfx1v4j0OJf7s90YpdTItOtbqfx1uTFmdbYboZQam1bUSimlVA7TilopNcg505wLe/IJr4gUAWFjT3GolMoCraiVUqkeAwLAWcCtzu1zs9oipfKcnj1LKaWUymFaUSullFI5TINaKaWUymEa1EoppVQO06BWSimlctiEds8SkUuBnwFu4FfGmB8Me/yfgM8BMcAHXGuM2eQ89lXgk85j/2KMeXSsedXV1ZnFixdP8m0opZRS09fatWs7jDH1Iz027qhvEXEDW4GLgWbgFeCDiSB2nlNhjOlzbr8X+Kwx5lIRWQH8ETgNmAusBo42xsRGm19jY6NpamqazPtTSimlpjURWWuMaRzpsYl0fZ8GbDfG7DTGhIG7gMtSn5AIaUcpkEj/y4C7jDEhY8wuYLszPaWUUkpNwES6vucB+1L+bgZOH/4kEfkc8EWgALgg5bUvDXvtvBFeey1wLcDChQsn0m6llFIqL6RtMJkx5mZjzDLgK8DXJ/naW40xjcaYxvr6EbvolVJKqbw0kaDeDyxI+Xu+c99o7gIuP8zXKqWUUirFRIL6FeAoEVniHLD/auCB1CeIyFEpf74L2ObcfgC4WkQKRWQJcBSw5sibrZRSSuWHcYPaGBMFPg88CmwG7jbGbBSR7zgjvAE+LyIbRWQ9djv1x5zXbgTuBjYBjwCfG2vEt1JKZcWDx8POO7LdCqVGNKH9qI0xDwEPDbvvmym3rxvjtd8Fvnu4DVRKqSkVj0LvRujbku2WKDUiPTKZUiq/xYL2Oh7JbjuUGoUGtVIqv8VDzrUGtcpNGtRKqfyWqKhNNLvtUGoUGtRKqfymFbXKcRrUSqn8NlhRa1Cr3KRBrZTKbzqYTOU4DWqlVH6Lade3ym0a1Eqp/BbXilrlNg1qpVR+S1TUOupb5SgNaqVUftNt1CrHaVArpQ6PicP2X0EsnO2WHBkNapXjNKiVSqeIzx47OhdF+iDck77pdTbBmk/DwcfSN81sSOxHrbtnqRylQa1UOj3aCK99NdutONQzV8CfKuGht4Ix6ZlmtM9epzP8s0ErapXjNKiVSqeBvbD797ZbOJccXA3uIvDvg2BreqYZ8dnraH96ppctemQyleM0qNX0ZQzEc+j05sZALACBA9Dxcvqnv+0WaHnkMNvlh+qT7N+9m9LTnuiAvY70pWd62TLWsb79LXBvA/S8kdk2KZVCg1pNX5t/BI+cnO1WJCUqM4Dmew9vGrt+B69eP/JjG78LO247jHaFbYVfc4r9O11BHUsE9SQr6tanYMev09OGdBir69u3HYJt0PVqZtukVAoNajV9+XaAb1e2W5EUCyRv77svedvfAvvun9g0mh+Arf8zck9BuNdWxpNul/OasqXgrYS+dFfUkwzqrTfDhm+npw1jWfuvsO0Xoz8e6oRA69hd34nu/VB7+tun1ARpUKvpKxa01WKuiDpBXbbUrkQkBlltvQmeu3Jio8GjA/Z9+bYPvT8es9uCo4cR1Il2eUqhckX6u76jk+z6jvSAycAmi71/ggOPjv74K5+D5z8wdkWd2P4eaof+7XYlQ6kMy8+gDrRC17pst0IdqVgot3apSVTUNY32OhGIvl2263ki1XDUqeCGbxNNBEYiHCfVLme+7hIb1H2bJz+NkRxuRR3uzszArXD32NvPA/sh0JJyZLKRgtr5fwTbYPsvoenzyWBXKkPyM6g3fheeWpXtVqgjFQ/aABw+wrpnY3b2ZT4kqDfa64E99noiIZt4Ts+GofcnqvPJdH0feMx2/SaqcE8JVKywoRPsmPh0Rm2rE2KHE9RTfbjOWMj+P8YK6ki/vYx1rO9E13ew3QY7HN7KklJHID+DOnjQ/ljp7hjT20hnPepeDw8dD/v/enjT7Gw6/P2ME0FdcaytXg8rqJ1g6B1WUUd6nccnEdTb/xc2fu/QihrSU1UPdn1PNqh7pn5FKtxtr8cK6mi/vYw16ju169uvQa2yY0JBLSKXisibIrJdRG4Y4fEvisgmEXldRP4uIotSHouJyHrn8kA6Gz8p8agd0GMMhLrsfaHOrDVHpcFIg4D23GWvJzL4p28rPLAM+nfYv7vXw6OnQttTh9eeRFB7nEDs3WhDIHjQ3j+RkB2sqEcJ6tgkQiLcbSvCxHzdxVA0y95Ox2f/cHbPMnFnG/VUB7XzHR+voo4OJP9vI26jTun6Hqyofelrp1ITMG5Qi4gbuBlYBawAPigiK4Y97VWg0RjzVuAe4IcpjwWMMSudy3vT1O7JO/g4PHsFdDVB2PmR0pGc09tgJeT8wBoDe+62tycSir0bwLcTdjq7Cg3ss9eJymmyEoO23MVQ+RYb1IlpwuQq6v7tQ99Dout7MhV1uNupGFO6vl2F9nbqrmSH63C2UUf6bVjnREWdGNHthPp4o74Tn4uIBrXKrIlU1KcB240xO40xYeAu4LLUJxhjnjTGJH5BXgLmp7eZaZD44gZaUirqNGynU9mT6PpOnBSiay0MOLtrTWRbbuIHd/cfnJ4W5/MwkUNidjbBgyckP1eQrMwSQR04AD3rUx6f4Dbq8qMBA31bUtqaqKj9E++aD3XZ0dWJNrpL7NHJILnsjoQT1PFIPwNjvbU3b4I3nN2xIs6ynfKK2nnPscDIARyPJv9fiRX2sUZ9R33Jz9RkejWUSoOJBPU8IKUsoNm5bzSfBB5O+btIRJpE5CURuXykF4jItc5zmtrbp6jKjaYMCkl0iwW1op7Whp9MoeUhQOxlQt3MzmdiYBd0vpz8wU4N31SxMDx+LrQ+Da1P2oq8OzWIhwU1QHPKtvKo3+5xMNpArljYBlj50fbv1EN9hp2gNvGJV8PO+1j9tzb7t6cE3OmvqOOhPr70pTFWHvbcBXttT8f+Xc6yNbH0HXN8JKn/w5Eq/tTu68T/3UQPbdNI3dxaUasMS+tgMhG5BmgEfpRy9yJjTCPwIeBGEVk2/HXGmFuNMY3GmMb6+vp0Nikp8eUK7E/p8tKKelobvv/rwB4onm0DKfXgI6NJfA7EA/vuTamoRwlq/15ofxZaHrT7SQP3/mYrLyeOFjq4jboY6s+y3cx7/y9lfgPwwgfhufeP3Z5SZ4hH6uczUVHDxFZC4pHBanDdi07gu1O6viezi1EsOHKoOpWlxxVj/94xphdogXAPsRh85h9Tlu1o+1L3bobNP554+0YyJKhH6P5ODe/U7fXDK/0RQ14rapVZEwnq/cCClL/nO/cNISIXAV8D3muMGVxdN8bsd653Ak8BJx1Bew9f4kew783kfbqNenobPpjM3wzF820gTSTMIv2AOAco2ZUMxsgoXd8BZ1BY/1a7bRvY9cZW7nY2iw+pqAuqYMGV9oAs4rH3RwdsaLU9PfJ28EQADAZ1SoCktmki3fop3fezKo6gog60wv0L4cl32NupUirL8MAo26mNGQzqzk7wkvI+Ruv+3nWHPYxqdAIrW6MZL6hTR6qnrjAM33Ye9dkDxQy/T6kMmkhQvwIcJSJLRKQAuBoYMnpbRE4C/hcb0m0p91eLSKFzuw44G0jTYZEmKfHFHBLUWlFPa8Mr6sB+KJnnVNQT7Pr2lEHJfPva8SrqxOjtvjcHg/ro2VtpS3ziU4MaYPmn7HWF05Ud8ydDY98IxwJPBEDJPBDX0KAOp1bUA/aY4GNtS095D4NB7S4G1wS3UXe8BLvuhNe/bqfV/hw8+76hz4kN2OUHRPyjBHWo0/5/Yn7aWiNUl6Ys29EGlCU2SR3JyT4S41BGm85oA+CGH/Qk6rMrckPu04p6UKgLnv/w0M/ndNf+Ity/IKcOTzxuUBtjosDngUeBzcDdxpiNIvIdEUmM4v4RUAb8adhuWMcBTSLyGvAk8ANjTFaCuqfd/gjGU4La6Dbq6W34EaX8zTZ0J1pRR33gLYPiubbCHS+oAwfstW/H4L7RR8/eSmui0IwOC+pZb4fK46H+HOfxgZSgvmeE9jgB4K2AgurRu76718OLH4WmL4z+3sLJoJpV0UYML7g84PLaO8erqF/7Grz4EdjxKzj6C7DsWmLdG1iwAJqbk+01RbPt5MKjhGqgJdns1t6hQT1aRR1KQ1BPpqJONXxAWaQ/GdTeCue1WlEP6lwDe/4A3RM80mM8Co+/DQ7+fWrbdSSa77e/JVv/J9stGTShbdTGmIeMMUcbY5YZY77r3PdNY8wDzu2LjDENw3fDMsa8YIw5wRhzonN9GKf+SY+eTvvlcjnb1YLhQiI+raizwt8CDyyHvm1HNp14yqjviM+GWcn8w6io50HwgN1XFsavqOMRMFGingaWztpJR5sTOLGA7eZ2OV3d4oJL1kDjzfZ2pM+GsacM2p49dF/mRFB7SqGwLrkbIQytngf22uvdd47+gzesoo6ZEqdNYrdTJ3oj/PvhgaOg/YWhr/c3Q8VxsPADcMI3oLgBd6yP9tYgW7Zgjz0eCxIrmAOACfcTH+kU3ClB3dveM6yiHuWAQ4MVda/dvc3fMvLzxhLuTo5wn0xFPbxNUR8UzQFXAZQutv/fXA/qA4/b/2kmKv/Ed3CiA+wivbZ3pnPN1LXpSHU8b6933JYzAwfz5shkMuzLta31KCI+raizom+LrUp7N4z/3MABWPtvh3aTmnjyhBwmkjwYRfG8SWyjdoK6eJ79gR7Ybe8frUs5sY3a0Vt6KV5PlMKo87pYIFlNJ3iKbXC7S5JBP+s8wCSPN2+Ms8+z8xl1l0JB7bBt1L3JbaWJ9+ougZc+MfLBS4YFdSQR1GC3Uyd6I7b93J4ApGNYUAdaYM4lcM5dtrovnDU4rdKeBwZ3O4u4bUVdWthP/0jZlxLUvu4eqkomsI06taJ+8aPQ9NmRnzeWSDeULLS3RzppyPCgdjvLZ6Sg9pbbA8UUz7Ofl1zv+u56xf5Pfbtg+62w8ftTN6/Ed3C8lZe2Z+zKYGIFMVePlx4LQucrUP82+53b84dstwiY6UEdC8HTl8Huu5DY0A/SmweOQXQbdXYkKpyJhGnLw/DmjUP3KYahZ82KR5KDs0rm27Cc6Khvj9P1DclBRWN1fSd+/IEOrz1efF3BVltNxgI2mEfiKU12nTe83V53rbXXBx6Fe2fbg5yA7Y4vrDu067vIVq/4nb7n039pewJe/Niho7JTttEWFYQIx1ODushWQtGAPcwoJKt0cI7Y5UsuF4CiBtv0ylYaQx+C175hZ+OybSov6qd7pMWWEtT+3t6JbaMOpVTU/uZkT8dkhLsHB+XtfNMJ5XgsefrQ4V3fXrutfcg26njU/nB7yuG4L8NRn7H/x/FCqfXJw2tzuiR2//Pvh52/gV2/nbp5JVb4xlsm6/4dXv9GSi/YEQwUnEpda+1vy7FftL8NvWk6gc0RmtlB7Sqw+9b2vI4rnvwgRWNudrYtpYD2qd2XM5tCnTnzITtE4kdyIgeOSFQ+w6vc1DXyeCQZXsWTHEzmLbdd3wlFs2z7RgqR4EGoOt5WmK4CDsTPA2BZw1Y6Oxm5ok7wlCYr8tLFULokuV2ve739ceh5LfncwhEq6hInOBMrJbPfAW/5BrQ8yIP37LdtSBi2shGOpQS1q9D+YO79k52Hq9DuepaQCNcRgnrFvE14ZWDwOOYBbEVdUdw3blCH+3vG30YdCyVX5CJ9tjKeTFdzLOQcK6EbShZgjPD7O/oIt22AB4+Dlz/hTNv5XCVG5HvK7XXq/z0xX28ZHPMFmH+ZvT1WRW0MPHmpPchLtiQ2mQSa7QrYaCue6TBYUY/zXQ4etN+PXK+o25+z1/Vn2+/5VC67SZjZQS0ChTUQ7sJjkl/2bn81bb2z8Ehk9EEl092mH8ATF2e7FSMbrKgncUjN4btMpY5ajkfsjxLY0J3wYLL+ZNd3QtlyZ34jjGINHoTiOfaAJKWL6fbPIhQpYE7VATvye6ygdpfY6hd4dUMlj689hXinU1H7neMJOftm40mpqBMrkuGeZHAm3mtBFdSeCsB3v7aX3/wmZX7hLvCUETcCQGh4UMeC0P8miBsazrfbgo2xyzURrs6KQVMT9IVt13fjkianzTbYB2JORV3cT1fKQOtBgRbwVgEQDQzr+h62MrRrF6y6MKUXIdyTPF55qr1/hidXjfz52fh9eHCFXQEprCEYK2dR7S48T54N/dvsBez/XlxQ5By3wRm9PqTrOxHmiccSt8dacYgFbHglek8mKtwL+x+c3GtGk+iJ8e12do3rnrqCJD6BitoY28MQC6YcTTBHK+rOJvsbUFRvg3q0XTUzbGYHNdhtfeEuPOKjtdf+2HT119Dhq7OPz9SR36GuISN/iUeG7rKSTYkfwImGKRxaUaeOWjZO13dBja2mJ1pRD26jno09ohlQfpQzv2Fr0vGYPVJY0Rw44Vtw4vcY8Au9/koqS3rtyO/oOBW181l7bVMFT7x2Mq6BnXY+iW7nxMlBEhV1PGTfRzxif9gSXd+BA7YCdHmgxB7iYGHtXnrbe5NVeLgbCmoYCNmQCUVH2EYdDdgViNJFNnj33g33NiTPo108l2gUzjkHbr7dVtSNS5uGvC1f1H6nRu369rdA5XEAmNDoFXVnJ5x5JhzYnfJ99O+1YxFSQ2DzT+wBYw48MvLuM/69NqjiYSioxh+p4PwVT+KK9UFhLfFgD6tX4/zvy5OVtNe5Tu36Tsw38Rxwur7HWMFMfKYnc4wGY+wI+6ffnZ7TjyY+A51rAGOXxVRVsBPp+o70JtuQoxW1MXD99eDr7rMryWBXhLWizpDCGgh1UeDysat9CQBdAzX0hZw16Zm6nTrxpUisSW+7Bf52TG509U+mop5Q13fY2TXLqYwns3uWp8zuspQ4q9RoQR3qsKFRPBvmXgoLr2RgAHoDlVQU99mgHrPruwSwy76tp4K1u06x93e9mux2Duy3Fa6r0K5ggv3RTeyjWuwEtYnZtX2AUieo6/Zy2eyPw4PH213Hwt1QUE1/wIZMMJLSrsQ26pjftqt0oX1/zX+xP6qJU4QWz6W9HUIhONheTDBWzspFKYdMBXyhcnzBUiqK+0avqCuOAXEhURvUnf01zvtIBvWrr0JD4Wu89eiUgEsM7kuEgInbI5Z5K+3fI1VlqSO8C6rxhSpYUOv0QNSdjb+vl4svhoCv34ZzIqBHqqhTu74Txq2onc/0ZAqAnb9OLvORenImK/Gb1vlS8r6JBM7+h2xFORmJru+xRkcnDoUbCw6uYB/cH+CuuyY3q6nU3Q0//jF0dQSTewsUVE/suP8ZMPODusB2fRe6fexss/tDdvlqmL3Q/hD2dczQU13Gg9i16ZSDgYQ60nOM5yM1uI16EsfjHt4FFR/e9b3fHpUMJnYIUWOS+1FDsvu73On6Hv4FTYzYToQl4PdjK+ri3vGD2p08ulVrVwXrdp1s/+hel+z6BluxiQyu1fu7O5I/3kWzbHctDAZ1W3cF3QNVLKzdy4LStbadT70T/M3EvTX0B+z7C0SGd32H7MqMu3iwKrfHSscOhvKUgbd8cB/x/n7oC82iuGBoJeQLltEXqKC8eISKOh5zNhfMB28lXtNDVWkP7f3OSnJK17f/wEZe+/5KPrfq1ykT322vYwE7rc41dnoLrkzeP9yQoK6hP2j3fQ5SD+XL8WKXZWSgf+SKeoyu7z17YHfzFFTUO1L2Wk3HiPLBI+ylLIuJBPXa62DTJEeIT6SiTgR1PFlR790V5FvfmtysplLipDJigsmj93mrNKgzP3v0EAAAIABJREFUpqAGgm0UuoPsaktW1MuOs2vlrc1HcFCFXDZ41K5EV1PiCzWJ0yROlcOqqIf90AzfRh3qTHZZuYvtmv5Yp1KMh2xlmqikEtX4aBV1Ypujc4APsF/uXn8lVaW942+jTjkMZUtbJZ2+OvpiC+0JPlLnlXheoV2RvOuOzuTjBVXJwHeC+uGHYW/HQlYu3cSs0n3QcKHtuu5eR0Sq6Q/aAAqEh3V9x4POKPWS5Ej2xApBPDy4PTxx1DWfD3qCtvs7GvcMTqo/UGqXQUnPoUEdtmfveuDxBlq7q1hS9yZF3hC72xfbx1Mq6mC3Xb4nz7KVZcRVS6x/d3JasQF7IArxJIN6pEOMRnqh6gS7e03tafT67fvvjL4FvJUUugZwu6LEQhOvqL/6zXJaWuC22+CJZ8owY1WPic/0ZHrqor7k5+Zw9tHu2wpbbrS345GRq/KJbGuN9E7+CGMT2T0rtaJ2fpfcEmCqzr90OBJB7YqHhlXU2vWdGQU1g4N4OvrraOmew77OBbzlRLum3dU6gw59l2r4tqDB3SJyIajTsI16+KjvWEqXlccJpbGq6sSPbeIHunSxDUdndPMhX9DBinpoUPcHK6kpT6moR909KxGUwoEOG7Z7fafY86QPeZ5tT9DYlY7IQEeyazxxMBcYDOqXXoKW3oWcvsQ5SMPRn7MjVoFgvBpf0E5vIFRCdzds3kyyoo75nW3UyV3OBlcUnKBOrai7/HbzwPbO5OH6+wOltPXNoqGy7dCub+d/tvaNalraKzl16SsAbNzvnFkstaLutStvXvERjbnpCCzCHU09DKjPBnXDeclejdEq6opj4eJnoGwJ3f32e37Af7xd0QEqS3oxYWcgoWdYUJtDR33f+9cynn3Wbkf3/T/2zjtOrqu8+987vc9W7Upa9WLJlovkbsANY1NMcWwTk1BMeYEEDIE3wBsIECBUU0ISICRAQgeDCdiEYox7w01yldW3anuZ3ue+fzzn3HtndmZ3ZUv2WtHz+exnd2fu3Dn33nOe3/k9tbBAoC4l7Par80k5a28yF7J5PfBDuMNRzrX3B/Dw+2QN6DgUx4YSWBjglFOHbnpfSDCZTlVzmL49Rp6pKSg1qXlz2MU0YeCXTYvsWEBN3i6z62tpngHyLMvRD9T+NvFtIYvs7H+4l8/86sOcdJow6sTEUc6oLaDWO9/FANTqni8oPWsBpm+zJP9roNbFK+a6Vr0B0Ixqy9/DBTdZynzW92lWoIEcWdyZkjDq+X3UCgC9MaamJHBt19ip9nVE1tUcNzItjNrPpFVXnMg6+zwKqB96CIqeFXjd6vnGNkvOL5Att5FWwWSZfIjPfQ7OPRdHHrUyfQeXYwXTrXqd/G4A1BNpufb9E5ssYEmkBaiXt4/OZtTqHvYPtzCTbaE1LP8/MaiA2hG4lXNUS5lMt7Onr7X2XNl+qbG+9BL7HjcDal3qE5hMyt+90ydYvu14MAEVzagVQDcwfWcSMqZ0PsLUFExNQaYQxlDzdmgIvnRtEfM3J0u+P9RuhBfKqis58Ct3wEKAevRm2bRoANEb30rO/s7Wk9V1KX/+fECtc8YPtWzrQtKzGjBqn0ue3eSz5XmcuAfuvKxpZH1WPTaPUeejBmvz8ulPw+9/f6QH2liOfqD2tVl/ZgoR+idWkS1G6FoWplo1yCb+lzDqymJi1IeSnvVMGHXdtZqm/Z3lOkYdWAJt21QrSG/jYDJ3sMaEnc1CrhwnFjgE07c3ZgHaw33b7PdVmpUeT/+ozFu/MSnR4L42Zfq2GXWpBI8+Ct4WYcTFspe8dx0svxQ2voe+6mVWMFk6H2J4GCYmoGxqRq1M326fsFRfG/RcJucPzQbqsZQAdf/kSquYSCITZizRRWd01GLUX/4yfO1rWM+s92CcmYxK0TIDVqyIk6mUszZAzOQ6mUjYYAtYtdUJdNtWi6ZALeCUz8N0Ws6za3SLDdShBO5qnY+6gen7gXtkjqTyUSYnBajT+QiGWYJKkf/8T/j8P85gzDxqF69xzumF+qkrh8io8+OAaUd36zVSztk51C0KqDVgz+dr1ec4VEZd56OuVuFHP6K2Sp3VV920jvO6ZP1aDW2OtExtl9/OeBCHaEZdA9QqrVDfuy98gecsAO7oB2rl6wPwh2UxtraC22OQLcUopI9SRl1tYvpeDIy6fAim72ZR3zXBZEX5X/dabsaoR/8I13dI4ZF607cWw2jsmypM2MpUSSYD+UqcoDfF5GRVpTsFGl+HHpM3bgHaPTtV5LfhglYF2grQDw57mEy1EfcelPxq3RjCYfp+4gmJyG5dLkC9e3gj45NeOd9pX6Uvc7bFqNO5EEk11XNFlUetTd8gft0l50H7abJRUfnkWpGmUjA6I6bv3rEVAtQuL6mMl6lcF7HADOmkPJNvfhM+8QmoFOSZjSdaiHWI0isFNlAs++SkDjNztWCvw2y1k0Q2Xnv/tIL1tTZn1NWKChAUcJ6ehpmsfO9j/ceDzwZqj1nvo56dnpWckrlneMIWUGcKasNVybBzJ/g9utZ1gzm9UKAuZ+187oVYmfR5C2O1392IUcdPlN/zMWp9jqfLqNV62rED/vIv4eUvl7gGwAHUWOvY55Fn96wBtS4mpF1YdaKB2uvK23pEM+riNKUSJJM0LpP7LMjRD9QORh1tFaXVofRtwYzXKIijSpoy6kVQaODpMOq5Cp6Uc+LemM9Hndoj9yO5azajdkojoM6P2+ZJJZmMzCGXYeKqpBbEqKuemGVme2LfEir+Hiq+ZXYwmxrP0BDs6DuFda0Pium7zjSOr5UHVSZNz3EC1DsPbq4J0JmexmLUqVwQbTzK5v21pm+AF/4czvm+WBZe/gSsfTNgM+p0Gg5OCaPee3AlpdhZlEKbJfK9IK+7S2OYJvT3w/g4HNglXziTbaFnjYCkp3Uj5YoKRnP6/kpJSlU/hFZScPeQzNUy6mpagPrAwTmA2nJn2ED9rdvexpVfvY6+4TaLIbWEZvC56qO+ZzNqo5wgVwrS2ua2TN/a508pzVNPQcCbt8YvY3LM6SYpWokE5PTQzao8i0Mxfevz5se59VZITTmyKCyg3iZzqU39blQXwCnW+HPNm6U0kjoftbYW3XUXfOQjerwONFaM3e/JcULP42wb2/rsRFZPK6BuUojGYtRuZzCZ7QabUUM8BtRHSvw2ULd2yiJrVyS76o4RcCUa538+36U+6ntR+aifRnrWrKhvh+lbK2idVmEp8rrz6+/NDTXOkdXSKC2jCaMumgJAIfekMMR5gLpkCogsWSJm6F9vfwV/2H6OHfyjGfVBuG/vWaxrf0TyiaMKqB2m74ceglgMlm9QQD20meuuk9eGh0VpamBJZkIWUGdyATKpAqlEzt7UeCP2JiC2Qczh1Jq+b9t5Hj+8+y/446Pn8A/X/S1r3/UImQwkiwLUvsook5NicgbY/bjcw5lMC/6IKD1363F21Lhi1Pk8+FxJimYMLvgd6fWfo2Op3NeKKcemRiSg7tc3tTkipOuAWoONA6iHpnr4454rmZyEkiHn7IyN43UV54363hC/i/1TJ9HWxixGXS1lBKh9dUBdbuKjLkxa5tfzz4err1av683GoZi+NaPOj/HGN8JAb9q+H9ocHl4FrzoAa940u8LW4I3wE49sWLU4m5Toaxm5GUZvaziEv/5ruPVWZpm+046Yst5e9UcDRu335Dlt7YO0scOucX+kpFqxGwDlGjNq2TybBDz52UBdnLY2IMnniNcd/UDtYNQdS2sZtdsfIxZMsvcIz5PnRLQCWGxR32bVYfqeRylVCqI4DY/sxE1HH0Wn6VsrGdc8wWRaAWWHahh1uSzu61wO/uZvoGQ0Mn2PW8o0lYKZGQHqslL+Ma9SRnOVEAUKVQGR44+X73zNp/+Nl336p+wbUkFqdUDtcVXArGCG6xl1G48+CqecAq7ICsaXf55v3/5WvvtdGd+998oYc2UBooQDqFNZP4apGbUjbauBaNNkPg8HDnby+q//kJlMnPvvNxgclM1GuixjD3tG2aMqdPp8MLBvhqrpJlMIE2oRpeeKH4fPXwvUo6NSK7xixCC+mYteuZy/vFruUw7JjS+nhFHv7m2VimyGZzajbgDUAOvXC9DOZORZrepQ/m5vi5SDdQfsXHJtjs8eZNOSB3l49NW0t4uFIJGwNz5jQ2myWQjNAmo9p41a0/c9b4CbX8TURIEdO+D662FkBHuz4Y2Ly2G+NVHOWXM3nxhjcBB8Rp3p2x0SP36gA1zu2RW2dDcyXQlPbrDjPqqJ8shH4ZEPzxpCqQTf+Ab8z/9QG0xmmhbjbG93WA3yo7bFQJ076M0RDTSxli1AUim44YaFHrxHzRXDygCql0wGfB51LfXBZMUZi8wdY9RHShxA3bk0gmHYjNobjh/FQN3E9P1cMWpdvMKpiOYbiwbg4LLZpSRrGLVuD6kYdbNgMguoB2uKWZx8Mnzuc/CnP8FXvwoHJ5v4qJUf8e1vhyuukF14xSXKvyOqdurzMOps2QZqp/z37zSjtk3ff9p3pvX+y167jocegpm0zahHRqCnBzAM3Cd+kP6JVaL8kUpf09NQdcn5EmnbRz067ifgyeN3ZxxpY7Xy7nfLNY6NQUgdksmAwlsee0x+79sH2ardWeveW0cxjCpXXAGl7AzZcgtgEGlTH4xtJBCsNX0PDwtQmx6HuVsFfhU9AqD+sgD1k3uV8mzUIU0DjPqsE6inp2F0Wl4/acWj8kZ4pXQyu2LGdj1oRn3w1wDsyryK9nbYv182VtrnP3BA5txZp8s8rBQcQO3yiyVPm6jH7oLh30I5w94/SYpapQLf/S72HPUEJUder4/kLrjlktkVvxzgPzUsu6iA2wnUkzVxOUCtK6c4YzewMQzHvWvAqMtp+1iH6HmUTOLYMJtQyVlAtmSJAupyRn5U8KHFqL1F4qFEzWs1Ui3N6S//wQ/g1a9eoI97Rj3vtm1NGXUm43BjzAomsxn1MaA+UuKNYeIGIBiNcO65cKbSf6F4jHgocXQAdWHSBkPTbJ6e9Vww6vF74IY1kHjKXny+tsaBM9WyA9SVklJlMmsWtFYQhsth+l4go3aYvhPZKE8+CY8/LuwQxFRbs8uvFOWzilHv2iX5yJkMVD2i/LvjSgE0yKNOpWD3AQHqTFGO10Dd3Q3nnAM/+FkbxLdw786T+Lu/E0Y9nlxC74QEkT3et46bboIdj8m1ZSutjI9DpyIqLS3gdtvfuX07PPIIhOMCLDMpm1H3DvhxuUx8nhLF6uzxFgoCItdfD+UyrFtnv9et9hPaJH7gAOQRoD5z3Z+4ZsUKbvv787n6yl5aQjNMJFsIBiG4/pVw4ieg7XSCYQHqD/9dmZERYZbRQAqX3wnU8nclKGb9iGeMTD7E3v0++z4fAqM2Tdi330M6H2brGuWv1ODh9oPhlb81UA/ewIHxNeR8x9PWZs+NTF5ZPAZk7l50oawvKyi1klW12jttUH3s4xajzBy4AxBLyLe/DZWiugZ3qLaF5tCNMHITpHbXPRwbqDOTCqg9dYy6zkVTUwqzzxG23Mh95LyP5YyUgK3zZ9cCtSNXvJy2TN9dXcqcrDcrOlffsa46IrqCWoNI851fhN+cPPt1JToWY0HAOfOYaj5zoQTgOa/HNOHAD3hJy18T9utkar3hD4vl5hijfhbEMCi7ZBcejIa57TZ45zvlLXcgTkskSXvmp3DTC567MR4O2f4ByRMEpWxUTe/DHfU9frdUQjoUyam2jPkRB0vulnHWB67s/w78epMoC608Qg2AWlsIPBH7nPMFk+nzZQeVQjTYe0CAamLCVsYTSaXYdF107WtUylaDSzKJxd66WwSoD47ZQVta/u7v4K/eLWNK5WoZ9aWXwuWXwyOPGAye/Bif+fHr+dznpFwlwP37z6JCgIPTy3joIVXCEhgcayWVsoHa5bJdOq2tcPfd8MADsGmLSs8qhKziEgf67Mj0iZnZjPq222p9jevX239roNZSKoHbH8L0RLj8jOvxukucse5+LoxdQ2tkholEC93dYATa4cSPgctNMCRAPThQ5skn5V7Ggkm8odmM2hPuplSW46cybQwOqiIZDRl1LVDrACC90di9WyrJrWhTBWQ0UIOYnUHmo1nFHL2N3+x4GW1thmWBk/soG5/xg2laW2HrSbK+ynkHuHlC4O+klB7n2mvBnNoOK6+A+BZaCrezaRN8+MOwZw/84mdqPerUP82odWOUWaVsbaAupwWowz5HxHlhssaKKPfDYfoe/p39uu5mVZisZdS6OlklK9X76iKl9fxOJqkL6kyTSmFZLXM57HQxXd7XAcpL4mONrxFkjWZ6mxYb0ZuwzAJc+mQHxCoXXi2WOadLYvvfwr1v4OyOb7B2idQrKJtqfRiG5TZwAvVz0S7h6AdqoGi0USj5CEd9tW94Y8QCSVYHbpWE+EOJdlxskum1F2PVsVOuLyHajFGP3g7XRWt7IDeSu/8CHv/UoY3Nyl3O2spUB0/VbxymHpZNRWHCVh4aqGtYbl52u+6Aw0ddZ/qei1GX0uAJs2evLIHxcRuoR6dbRUGVUzB4g23+83dQrYq5rVpVxytA6YoLxfzoPwS55hr7K4tF+PGPYSYtAJtQQH3SSfD+98vPiSqDZv9+YdIgTNbvh4///JPc7fo5puni7rvhyf2dZPIhHntKzHIaqJ1/v/nNAlKmCZtesI2DxbPZObTZOi5T8Ft/H+gPcc45wsC13HgjBIOwZYv834hROyUcBiPQRUd0kulMC7fueiXuzG6Wd86QyMZZurT2+GBIQNHjLpNMKqAOJfGFHV2qFNj6Y3bRlulMK9UqDA6yIKCenoZoVNgdKKDOyfOaycQxtWkTbKA2S5Dpxahk2N67lbY2aHPg3nhSbnIxMcSmTdDVIevKXXUEk3nCFIxO+veM88EPQqVcAlcAc8l5bGy7m7POLHPFZUUuf/kw3/o3dQ2eUB1Qq17y9WxTg0xoJa7iGC6jQtCn41FyNelpljhN3zOPQ5vK2a/kYee18NuttWbmen97Xe5xU0ZdEqCORGRO5HLY+kT3UneAcmd0vPE16rHVHe8UvQnLLoR35EdE3+iqgs7I77E7rT/bozLWfMmRYqkC8fTGoFwWi9OzLf8rgDpfbSedjxCN1r3hiRHw5mjx9sr/iyEi+ulKfszeaDhNWgutTJbao3xSQ82/o1pRIHeIRRH0gq9kbVZrAXXdllhHohZnbDOgxagdfuNqwTZZWj5qbfpuFvWtgXpYrsETsdweTkY9PKEU+MSf4I5Xw1NflP/9HUxOin9RiytQa/oeGQ/yi1/YCuR3v6uNFp5OxTAMMVV/6UuweTMsV+7RoSEbqAHWroWnhtbxVPIVcu4R+Pof/orTP/YAjz0hLLPDYeVcsgRWrBCWDgKqW85YyQ35e5hQjTBcLiiUbKD+ze+D3Hsv3Kn0lWlKkM7FF8Mb3yivHXec/R3NgFpXbLt3z9kkKqsh28+Slmlmsi2zPhOMyNi97hKplGyS4qEkLt9sRh2ItVkBXNMZsYz19kKFoBWIlUjAhz6EXbzIAdStrfY92r0bq/BK38SqGqsBhvablwTMgMcHt9DWRg2jnkh1MpVfxvLgdlassAt3+A0HuLlDPPxYDC/yBYZZApeXR4bPJezP8PKztmPs+3d++sbNeFUgWCYfVJ25JCiL5DyMOn4CAWOcSMAZt6GAuj7l0Ncqr5eSkurXfpq61rxsQrMDtay5lFDuMzWJ64C6hlFXCzV1yjVQB4NqDWig1k1vHLpjefscjFpbAJvkf2vgXBBQ54aloI+zTayWShZcQuDaIzLWXNEB1CoDxJkZ9FyYvxcE1IZhvNQwjF2GYew1DOP/NXj//YZhPGkYxqOGYfzRMIxVjvfeZBjGHvXzpsM5+IVKtiK78llArQogrG5Vi+K5joh+JlIYd/ihGwH1PHnU+rj5iuublUNvHNCIUevdbf09TymgLiVmM+p607c7oCJl6xi1yw8Y9qYk0ycmNP3dZgUm/wT+DitK2cmo+0ZUwNKMipgavkl+BzqtYC0t/lCAKl7L9J3OBclkVEQs8P3vg9cLu0c28oj5Cf409Cri8Vp/co+yCvb2iu93lVo9GiD1uECq6+0cOp7HVbaJk1F/7GMSjXvKKfL/y18uwBx0uKFXrYJC2Qbqvb1ifRhWumtkBAYG4MUvhmuugV/+Ek47zf68E3T96jShEBZQ37PnHEq+FVDJsyS0n5lsyyxGfe65AoqaUScSEAvUlv4kuh5WXYVr2UXkSrLJKZjyXK69Fu57MMgj23OMjMhm6AtfgD/+PgkYFlBNT8uGaJkiczt2QDIva75vYlVtWqZl+i5bqTxPDh1Pa2stUHd3w76pbWxc8jBLlmCtG4+rqKq9ZcATZnLai98rG2eDEo896eUN7xarxovP6oPsAO5Kgk99RObNZ691MOrcQXuu1kdEF8bB5cWMbqAlMEZb1IEaFqNuANQA4/cCJgmPPNBMMm/rg9QeO7ajlFRNa1SWRV1A2SxGrYPXlI86GpU5J6ZvdZN1sJ5DN3XGZdNRzjUAaotRzw3UCzJ950dE3+ga8c5NSTlrubQaArWyRjjL4z4XKVrzArVhGG7ga8DLgOOB1xmGURezynbgNNM0TwJ+DnxBfbYN+DhwJnAG8HHDMOqK+B556ctfyM2PX0SkPmVWKYblrWrHeDhazD0XYlZVC8s5GPV8pm9tIp/rHmhf81xNCRqJk1GX5mDUpaS92y3OOHzUPfZrzvG6/KJg633UhqFaXWbF0nDjRjjwPRUQppAt8QQsf6XFqPN5KdQBcGBITVHNajQL8HdYQVRawmGDshHn+OVy7FhSqnf98IfiI77+eokSN00Xvx34GANjHbTWrYBYTFjIww8LkfngB4XVXnihvO8sYrJC7VkaAfV558ErXiEs8rrrsNoIOoF640bIOxRRtlAL1JrRr1wJgYBE1jo3uBqovV444QR9D7CBevc5uCISOOQx8g0Z9RuvVkDtKpNKQSZVwO8t1AK12w8v+DFE11OoyML1hltxuaRjWIUgmWSOa6/F2mzt25mkbEQxcXH99eLnb20VoD7nHFGw+YoAde/E6lpWZqidkymMOmusJJWLzTJ9r1wJjx88lY1dT9HTnalda6WklfKWSHnx+0oYRhUXVQ70evEG5DraYmlrs7v1OLnxv7s5RNUVFqDX/mlokM8vaYLTuS7ioSRnb3Ps4srZ5owapEY4sL1XKuIN9TuAOrlbit24vFBKMD3u0BMZ0Y+3f/Fd3PmF18/2UWufeDlDKiXzJRSqM30H6nZrQGtQJnYxM5fpu3GRiwUz6mpZrBDNTN8VuyqcBuqswzUkPuqp5wWjPgPYa5rmftM0i8BPgFc7DzBN81bTNPUtuw9U8iNcAvzBNM0p0zSngT8ALz08Q1+43Dn+ft72H9+ezah1wXotz1fTd2FKVTiay/Q9TzCZzueciy1rs/hhYdRLZ4/HGaRWnLE3BKEeAeGB6x2g34BRO8t3ukNy7sn7Zdef3ieAHrd9taz+C/bsEUAC1VkKGBpXpm+nwsQAX9ssRh0KQdUdJxZMkaku5amDm1i+HH71K3jpSwXYPvMZAYyBAVEwTsWvZflyAXYQMH7lK+20qLExAcZTToFLLpHPa3ByArVTrrzSBvV6oHYy6lwxiNttA/WQesSahUJjoF6xwjbZh0JAdB0VI8T9+84g0G534zpxawtXXFE3OGVm9nkEqMu52opi9VI0BXiMQJtlfVi5OkBrLMcTT8DevWL272xJkszFuOceSS175BGsTZEuMFKo2qbvqSnZSLW2wuCQIXOpWoLE40xWxEHvNH3HYnLs7Y9tw+2qsqn7kdp4kFISyhlMT5jpGS9+bxGvW9ZkJufFr5lCyQZqDRoT00EmZhSjTqqJaLgbmL7HwN/J9idlQ/jyc+tyoSt5u9qaliXnSXbE7q+Dy8dgWnhWLpO3132mVxWAiZFNJDl9q2MDnRukODPIC7q+ydbOX5FMCtNOJsGsY9RO03e5DJX8lDxXb73ylY0aQCV/6KbvBfuoC6ouerBb9IO3pSmj7owLGmfzDj3SciKk9hA1d+JSaLlYgXo54HRSDKrXmslbgd8eymcNw3i7YRgPGobx4PgRaFKaSoHHY5vqLKlXDM9X07eu+Tun6Xue9CyLUc8BwrlnCNSVLJTrTd8ZJiZEGe560FkpKWEDsK8Fzvh3mLgb7nm9+pxi1IbXNtEp03d/P5iekLCFSYV+uWE5X0wBdXwLCWML4+O2aXdiQgBR+0JrgNonhTY0UGuwDYftFK29mZcABp//PHzgA6JMvvpVUfArVghQj401BuqeHjvSW4OkBtjxcVF+d9wB//IvEhxVrYr5vJ6dN5JZQO3wUQejIS68cDajXu5YpU6g7uwUc/qqVTZoh8PAxnfjuvQJrv1KhJe82gbqiy9tYdOmugEpoA6HxPRd0RHTTYC6jACcO9jK6tVyL5avChIL53jySdm0HH889HQlmcnEeFI9tne+UypoAbz2tbIhK7ts0/f0tDQQKRYF1DG8MmeSuxjJCVA7Td9tbfLdNz8sddnXxB+ezagrWYqVENmCD6+7hM9jA7Vm1JRT9hpSoJErhegbUkCdeFJYanD57HiQ/Dimv5MbbhJw2bZxf817ch/rGHV4BSx9qay/2GamZ7zkigGKWQejxhSA98ZJzyRwG7WMeui2b+BxV4j403hy8p2VCnWMutb0DVDJqih0xya6jN3YBsBo5KNeoOl7XqDWedPaghfqsbvRaT+8Aupl7cKo0zkHUK9/B7iDXH78F601sViBesFiGMbrgdOAaw/lc6Zp/rtpmqeZpnlaZzOK8AwknZYF5szvB2Yrhucro9a1dE1VYsu5y6/katl2s2tciI/aYtTzuAhKaTjwAzuPoYZRp0RRO8xlO3dKwFXq4C7Z+YNi1ClhFS7cYYRWAAAgAElEQVQ/rHkDrPs/MHqrvK/bWrockfzuAL29EoSVzirTtwbqtGIekXUQ3QAb32WZvc8+2z7Fpk0OoFYBZ4CVmzo6Kgpfg084jGWZ2TFyMSDK/QtfEMZx5ZVyXE+PML9HH4WTG6SHOoGxHqgnJmT+RqPy3TqKub0da5c/l2hmDnDqqbWM+r9vCLF2bS2jdrmEoWoJBGyfejgsG49Vq7B8z6EQ4A5gRFfzV38FsY52O8BIl2F0iksBdVAYteW6aALUumiLL9LKJz4hxS68/iDhQI6BAXEDbNgAS1oTTCTi7NolY/7a1+AlL5FzxOPw+c/DphOV6Xt8NTfeCPfcI+/v3o0w6sSTUC3SN7MFw5DPtbSI7mhrk2cwNLWcsUQn3b6HGpi+M6TzYUplLy6jRFuLrLtk2kcgEpD5XE7b1iLFqDefEGTPAQXUqd0QO07unfZRmyaM3AKZA0xnO7n/UXlALW5HEQgdEd6ofv36t8vvli0kEhLZXMw7gRqLUZcySTun2NcK6T10Jr7JnhHJ0wvmd1gfMZ1AraK+tekbwMyrAiwOoC5SOydclblM345CLWN3ydeU7PTBeX3U2sytLXgdZ0uKabWiUvEqlul7SYsAdSrrAOpAJ6x9C6/c8n22bhLQX6xAPQSscPzfo16rEcMwLgI+ArzKNM3CoXz2SIuePLOk3vS9mBh1pbjwhuXOvEDd8tH6P1+bQtHsGi2gXoCPej5GPfhLuPcN4gcGu7BJJWv3C9alMMtZi8WFy7sgvEZ29qWE8rdF7R1WZJ28XkzITl77qLW4/ezYITv9dCEsi3RKda7Q9YR9LfDK3bDhnVYt4tNPt09x0kmQzMUwdX/mtm2iaAJ2DnV3tx0AFg6DoYIS79l/kQwzYr+nZcUKMa0Xi/DCF86+ZRqonSCplZ1m1Fo0UC90T+tk1GecAT/6ia2IPP4gS5fKZqBUEkbd1SUWKC2GYa+fcBi+9S2xGGigDtcSJPmALnDhbQDUyh8cCpaJmjtp8emSno0WKRbwhOKtnH+++M3xBAmoDkzJpOR6t0SSTKXE9L1hw+xNzHveA6eeuxbTHYLIer77XQH0SEQDtccyOx+Y2Ehrq5zD7Raw1kANBruGjyPq6q0rZSs+6mQ2RKnixUWF9hZ5P53x0tKiAt2cpm/FqF94XpC9vWEBzvQByfH2OWrOj9wMt7wY8qPc/dRZDCfk/sbMJ+zvnwuol71CCn70vFqAuhigXKgH6hh4Y1QLCUI+pSeix0FhEqOa543/9gNKZQ+Rsg3UVIu2D7xsA7Wec2ZhCnztdqAntvvBerzVGW64Qfo92+etM33v+Qb88XwoZ2rqFMzLqLXFwlSMuut80SEzj9i6sC6YLJOrNb2aPX+Gz1PijE0yN6rpAbjzSpi4f54vP3yyEKB+ANhgGMYawzB8wFVATZVVwzC2At9EQNpZ1O33wMWGYbSqILKL1WvPqkxMNDERLmZGfcuFDevsNhRndxqzVLv4KnVA3ZRRq880ChQrTElep2bU1aJsJJqJ9kPrHsL1jNobtSNMh25gS/pNgEnU2Cds1xcXJlFO1SpvXaAiOyAbEHc9UAcsP/NDo5fB+F2ivAy3RNJCzTPX/lgdJQ0C1KbpolBVm7jAUth4DawQajwyIkDm9M+aHS/k5/dfzp4BQdBZQYvY/mKQwKZ60cDf3W2zV63sxsZqwfDpAnUkIufuWupQRO6QBbijowLUyxs4tpybj8svF1NzDaOul5AC6kaM2nCB4SIULPPRF1zCF1+rKhB5GjNqQ5lyI+0On4E7iNdlz/MNGyDqFx/1fffVppTVyKrXYrymn9vuaeHznxfWfcIJCqgNr8XABia6a1wUy5eLpUNvWFL5KD5XbTBZtZCASobpVJhSReZlZ5ust2TGSzyOSsGq81G7vLz4JR5SOfWQM30y153NYSb/JL8vO8i37novsa6l4PIRLEpmQt5st/VAow2PywMv/iOsvNJi1JViLVDv2h9lfCaOUbEZtdnxAqruCJd+8UaCPWey8+BmlgU1UJu4zKKwZU8YSskaHzWAUZyUcqouj7VByzuAulDy4SXJD39Q5StfcYy3PpgsNyzsNzNQE4FtAbVpNi7EpIB66zldYuBbcp68PnqbrQuVj70lKIF5yUxtq9p8WSZ4z1IZk5EbgIGfz9869DDKvEBtmmYZeDcCsDuB60zTfMIwjE8ahvEqddi1QAT4mWEYOwzDuEF9dgr4FAL2DwCfVK89q9Lfb6e81MhiZtTpA7YvZT5xttOrFu1Jbnjs6kNank561uP/CL8/o7ac4Vx9c638SxVGXe+jdjLqvp9wQvB7xIJJIu6DksahFVTJBurBQSh6lfLP9NUGk2lx+S2g/tHD77d7OHc6KKwDqA8eFJ/0unU2g1y7VoBnPKF2dsGlcOLHYdN7AQGz7m4bzMJhcJ3wf7nyqz+36g7PBdSbNjUGWH0+ZyqTVnbFYu05tW/4UIE6rqe72wHUHhuoh4dl8+IMJNOiAcoJyhs21I69RnRKXf0a02J4CAbKRHxTLGtV5skmpu9QTHW9W+rYbbuDuMwcl51+Ix9+9afZsAEC7mmxhphzALXhAn87kYhE17/lLeK3t0zfpiTJ944sqdnc//KXkham70O+HMFdTUMlT9UUNZpLTIBZZXImRKkiLpmOFgXUKQXU3kitj7qcBrcUnSlW9UM2ZaPjjdum76mHZRMbXMq+fbB2nQvCq3BXZFOcrS6Zm1E7ZGZGgLpargXq390c5ZEnY3jMJCG/jHs09AZ2rJ/iticv4IwzpPXq5u4duN1YgXK4fBDdgLn7X/nwKz5SY/p2lxWjBsv8nS3bN3ZwqgfDMMmnUkxOSgAaMNv0rasDZpsA9cH/kYqGiafkDppSnc/MjZApxdm1NygBaKHlch/Hbrf0lOmOkM6HiXgFmhLpWqDW/3cvkTGZeTWWQF2p1iMoC/JRm6b5G9M0N5qmuc40zU+r1z5mmqYG5ItM0+wyTfMU9fMqx2e/Y5rmevXzn0fmMuaWvj5Jq5gl7gAYHqta0aJi1JX8wtPFCg5G7TR9+1oUo3aW+XsaPupsvyqGMmAD7FwpWlb+ch1Qa0btidrnUdLTNkjUOyZBH74WZeKeAU+McllYz39et9IejzOYTIsDqPsGA3Dmt2D5K2HpxfYxdYx62bLa8psdHVKEZGxGlEnZV5tWohn1mWeKj7inR4IUDcNOo5oLqBuZvcEGOydIOk3Wh8P0HdOX7nIy6mANUB882Byo3W7piqXl+OOl1ncjC4Fl+m7EqAFcXkKBMj63w03TBKhPOEUuPtZeC9SGWea9l/47n37t37PB8z08pVEeGZBAr6ZA3UA2bpSNYBU1lzxRRsaDNYx63TpxSWigrhiKGVfyFNDVyoS9jU+FCYblXO1xmfuZnGbU0VrTt7oWvx96VjvWRJ3puzT2ML/90zb6+qQRyrp1iJtISabUYa/heYBaM2oqeYo5G6iTuSgDI3ECrgTxsKzh/f0hBofkWrZtE6DuaRvixI3jklIHsvE7/7eUl17JR17zGTa3304wCC6jgrs6bUeFa6Au2XNiaEYWhs6lntSFEetN3zrNqw6oLR91ah9gwuR9ANx8s6y1yaERJjOys9XBmk9Onk9y3+2U8/IMitUQmUJYcuGpBep0GnY8LguoNZojFAJXSZcUXmRA/XyWREJ+GjJqwwBvjIGZjfL/YmLUldzCx+M0fTsZtbelllF7wnP4qHV6VoPNgfP80Y3Nj7PO1QSonT5ql88OHANOXPEYbldFGKw3rrr89EN4BePj4ofcM9AtrCfT7wgmU8rV5cU03DwlG2oxa3ddAOfdYLM74M1vj1mBKE4zrwa9jg645RZo6xZlUjBs1EqnxY3S3S1KYGJC/JaGIWCoC5M0AuoNGwToLrqo8S3Tpu9DAeqOBeqJ2YzamcYWsIC6t1cUZSOGHI0qf3xdQObq1Q2CNAGWXwo9l9lBPPVieAgHcnjcjjJvTYDaHemRzYXK1ZYX5aLWdvUC4N/xNvDGuHfkDcChAzVAsazmUqCLqanG0fkaqE2PDdRlVyvliptKRiwDI5MhIjE5V2tM1kKp4pXOY/pzzo2uKnl73AlOoF6pNqxJyE/gLfZx6yPb+N73JOd//XogIkCdykXIlWxTxxe/ujCgNqp5KgUbqF3+GCNTMULeJCduljW790BISrYCW7dKtDzAieuH7baQLh8Euxlb+22GppZxXsuHCQZMWsIzGJhWsFmpKvMuVbCBeiwla7OigNrqhjUrmEwBdabfSs0yDAej1mRF9fx+RPVdqaSHGZ6ROdjXJ/P7RzceRyyQYGZEdtb5UtCqHAiQSNnr40Mfgnf8tfwfj+SJRsFTOQbUh10GVHJYQ0YNEF5Jf0p24Yum4InufrVgRt0kmMxi1GpB+VqfHqN2nj+2qflxWvR3ZBv4qLXf2TCkrZ+SbWselj80oy5OCyCH7daNyZRLivtn+qFSYO8BP/c9oCiey8/goIBpS4uAsFU836Hgb7krxn7lUXCyRyejjsXA9Ap7y5qyyPfsEVZvmnb3NaeEQpIyBQ2CqxAg3r9f0oQayZIlApBbt9aeU8vhYNQWUGtG7Q6C4aKrSx7Hw+oRNGPUDX3RzaTtVDj3F7WuCae4PDXlL02MWVYWS1ZdJQGAPocZXQH18pZe+b9agrVvYcUaQdKnA9SFogbqJYyP11Yk06KB2vDaQG14giRzMSsV6OBYmGhM5mVr1AZqy0ddStRumNW1bDmljlF7WwCT0rB03Hr4wDZ+/GN5e906LKBOF6Pkivau7tY7mwTlKdFA7THyeFw5EnkB0ksvizKdacXnKbFlg6z5nXvDDA6Ka2jdOiiZMsaVy7P4PYoAqPmUzgX55H9/jG73PXRwN21h5eVUjFqnPQ2O2c9xMq/r+EuEmJWdO8v0PZtRWx26QKomAkwLUOsNu7c8wsC4zag/8xkYmZLvT4zaqXEaqCtVF8m0HUm5bx90dcu4168RoPaZE7LZnaeX++GUox6otbmjKVBf8AduGPwi+ZJ/8Zi+dferhY6nnlFXHUBddZi+fa2iIBq1f5kLqPNjYkLuOBu6X9L8OC0amOdi1ACeEKYqzrBttUKJ4FJRUFnFmkM2UKfTiALL9kE1z+NP+unrV8rVEUh24YUSwWyZ0RxAncpFrRKAQ0OzGbVWzlWPAHW6IkD9s59JrMNtt0lpznrRIBYK1ZYHdcrKlU3YJ2J+7+2VKmZanIzaCf7HHSdpVg1Nzg3E4xFf/CwftWJyHo9c/4MqQL4Ro163Dtasmf360xbDQ8QvcyiVi1B0L5vj5nhsU7oW1U7UVUlLRHP7WXDce3nZy+T5x5u4xhuJ9rXvOyBzqejuIplsbIXTQO0JRGSdlpMY3gDJXAxPSRj14HCYaFzOFY/UAbU3MqsblVb4q9bJQ85V4hJ97RHmec8vbgFge99Wa46vX49l+s4Wo2QdQD0wPD+jLpQCRAJpvO4yiYrEcvSsjjKRkh1rT6sozieeEka9fLnMUZ+a6D1d2VpGjWTX3Py4mIyixj6ryYVm1IWyAN7YRED0LZAoiSnJZzgYtWna5KKBj9qfeZCTV+2gp8dh+s5poN4BmX7MCZnMfiYYnpJr6uuTkr6RVtE/uelhdf9soC6UAzU14EdHYfV6ubduBKgDhmol2my+HgE56oFal4VsaPoGCHTQ0hEhWwhhLhqgXkCqlFMK43ZpTCej9sZrTd86VcaZvlX/nfW+52pJIi/bToWL74EW1VJpLqDWbCE3JClmlQY+apBWgO2XSI/gVap9U7BbmJMuYuJg1KkUorBTezELCfqGQuQ1C3L4p1/8YvltNbgI2EnBqbwAdSolP5o9rlghO3SvbqKk7lWyJEA9NCSZA+ed1/iSnZHVT1c8ntq138z0HY0KqG7btvBzB4MNfNRu+wuWLbMrszVi1J/9LPzxjwv/vnnF8BD0yRz6+5/9I70b7jm0zzvGzpLz4JJ7IbKat7/90McZDsN//RdWn+yZnMyXtWtnH6uB2htSD6QwidvrJ5WP4q/KRJ1MhIi1KKAOy9wvln22j9oZ/AnWpsPtE7CYyImymk7LbmMpN9E7vopIm+wiPR5FPBSjzpejpHM2u+sfbmKZUDIzA4Y3QGtYQDDnU1XYli8jWxFQ6wz1Ua56eGi7j8FB2zUTjMj3tLdkiYVtH/VLXwqf+hSMq+YvQWN8FqPWXamGxwMUynLN6Yow6njIwag1sXCHVIR8xtY32QFe2fY6/ukN76e9vQGjLqcwbzqbj114JWAScCetGKQ775Tzbzszrg6V55UthKw+46XKbKBu7VCm8EpOLEvuBj2/j7Ac9UDd1yfKt1HXHy2dndLdqJRfJEBt1edewHjMqpiFtC9QA7XLJxO93vTd7LzaR10fza13shrsdKDKQoLJzCrf/2afo9iKCqLRjPrcX7K37esMzyylPSqL2vR31+behlfWAnVoJeRHMapZfn7/FVYaDO4A990nIKPTrXT6lWxiDLLFIOWKl2RydgWuj3xE2LKWZPhlfP+u15PMyViapS1p0Yz6mQB1vfh8jhTyZ3jez3wG3vpW9Y9m1A7T3Wc/K/7mcLjxptbrrd04PGNxeQh6ZA5NptsJdTYzeTURJ1AH51jcC5Q3vQnaOmQu7R0UC0wjC4IG6oB+IIUJPH5h1EGXAHCmYDPqaKiB6Zs6i5Z+Dsr0r3OkR6Zk7m1cuoc7njqX97xHDlu9WmUpKEZdqERJ5+R+5IoBEkkPeaVCPvABAdk3v1naM5ZKUoPbF7CB2rPkVHjFToyu84kpH1DM3UeFEAcPSjMTDdShqIw1Fs7S1iJ6xTR83Hqr1KdP5aJUDR8+c9xm1AqocwUBvGTab7HrnEuAuiUkjHp8HFv/aZ2W2mffp9QeOvx76W4ZIxSygbqYGmXXqGw4jNxB2sIThP0Z3K4qiWwcn88u0XvqWaJ/jLww6kw+ZLVSLVVtoNYtbTu7vIABlbzU5fceA+rDLv39wpbmquDU0SG7quKCeqY9C1If2DV+T/PiJ5Y/WoGwDiZzB+THGfWtI3AbWQ4qTRi1Nqv764B6IelZQN+jO2efSwN1dB39o51WsEciG5OcRWekcLjW9D1VECV274GLuGvXiyygNl1+brsNzj/fBlSLUbs8VL3tJLPyvYmE/Z5mj62t1JS6LLZeyBu/8X0yWUHKZmlLWo4EUBvG4Tvvu94FZ52lT+wS37HHBuqXvlRSlPr7Hcz7SIrhwe+WuVYo+Q/JVA3UAnXgmQM1QCAoc+nBJ2SuNwLqNWuk3vpxJ9hA7fYFmMnaEenZYohYi5iDIwFZJ6WyCiZzlve0oqHVtSig1gFbA6P2Onhq+nyrZrrVH9zfDp4wRdMG6lROdhI6sPHnP5cN7n/9F9x3n92iMhAOEA/KP13LghDfBIZBR48wYn+53xrP9LSjwE9cAXUoS2tc9Equ6KdolVUwqHg68VXHrQIi2vSdUTW086UAxYqMt+SVE2ugHhvDtgDqDVhKFbZvPdlKn2uPTNpAbZq4iqP8bvuFVIwwVTxEg2m2bVHpVtk4p0ofErxe2HC8THCfsoCkcrbpu2wGLB+4bmnb1WWILq2K6TvuHz8G1IdbmqZmOaSjQxbX4mPUOcml/sMLYOjGxsdqENbmZM2onUA9y/TdIJe6mY9aB5KpylyWopmPUauOV50+BdSeiD1WR0GGoSE4OC0IODyzVCI6de6tNwa+lhpGvb13K/min/f916dob8cC6kI5wMiIALW2njh7O+fpkoAfJIJcs+1mLFn7hLUPbD5GfThM33Odt1GA2jMSl78W7BDfeqNI5yMiLg9+lwLqcuDQ71sNUHc1P+4QRKdU3fNwFy0tEpQ465igtNVcsVoN2KxguAN86Q//yPbxy8gYa+gbX0Vcmb4toK5h1PpkakLpDZM3Trnq4Yl+cZr3HbQH8KEvnsfKlQLSGnQwDOi+mP70qSQzypSsmOH4uPz09krNc4CHHrKBOhQN4HIJs4/E7Xt53sUCQEY1hzdgb+Q0UMda5bVwIEtrTNZzMl3XRMHfiacywZLYGBXTw1e+3sLkJGRUMFmh5LciwL2hFqbSrXTFR61xW264oNoZp1VVwVa7MlFLaJJQyJT1WUriMQoMTK7g9uCD3J//JACvvkgiiZO5mLVJPflk8IVFv4RdwqhTWRuoDbefvXsFoHWnvO5uZL6VxfTdEjzGqA+7NC124hAN1JXCIgNqgHSv/G5UuN55rGapOpjMFbB2gbNM3/3Xwejtdedpkp5Vz6h1pPZ8wWRRCbvtDiug9tshytPpGCedJDWa9+/HYtQjM92ym9WMWlUi0wsmlYL9idOIvS3Jh790Fv/6rzZQz6iUivPPl7zmjo5aoJ4uLLVqeDtN381YshOoKxXJn362GTUcuQ0Abv+zGrU6SwwPHkPmmssTWFDN8ho5zKZvAK9f5tLQZNf8gXNOZuwOMJQ9hc/d8wu+N7OfmWwrLW1yLl2Ks1TxiqXCWTVMA7W+Fm+Ur++9j6/c+HZME/YNqA1rqIf48rUYBmzfbrcvBeDcX3DT8MeZTMg5TLeMa2LCNvW+4hUCtA8/bAN1OOpM0bPv5SWXxq0KYi5f2Aq0s4C6TeZMJJAlHhW9MpN0JNcDRqADozDOqs4BJrPLef/7XfzkJ3YN7XwpQKkaBHeQaNzDwOQKVrQPsGqVZtRKp+nWmEnVrEcBdbnqxusu0RZNC6NWOmo02UXv1Cb2DcnnztgiAUrpYtyK5zj9dCxd2RLQjDpo+ajd/gCFghA8TRC6urB06cqeEi2hGfpGjgH1YRNdu3g+Rt3eLqbvamkRArWOEHWWAW10rNfBqMu5OkZdZx5/9KPw2Mcbn6eShZ1fhj/9H/X9Cqi1j9rtU60l5wkmC3SCv51VcdXKKGAD9e4DUR57TMo3Xn89BFrrGbUC6pAAtdP0PTMDpYqPCy+U51osi5KYnPazbJmKhkXYr87/BLhu75d57w++RiRiM2rdB7qROIF6bEzAei6gPtKM+rADtStQY/p+1sXw4EHmkMcfmOfgBuLRNSrdduWrZzoklUo2llwyP1A7mbErQGurmIhHR4XoxlvlXAGv6BSvzyt+ZefnQhqo7edQiQs7npmB3QcUUC853wpWiEbtgEctsRhMzCimG7cZ9QMPiMtv2zb5efhhuz2kL9gYqKVyW4c1Lg1wGqjbOuXYoC9LPCqMejopjFpnO7hDnVAYZ2XHIANT4oPu77dLcxbKfspmALxR4nEYmFrByvZ+Nm3SPmo572hBfM7ZXklPo/OFEFnHLx56HQDt0UkF1LKTH010MT4O/cOiP5a3CFB7g3ErMPD00+UZVE2DWCABLh/TMx6LUev7snOnTRAsoK7kec87xZz+ze92Wu6FZ0OOaqA2TUmr0R2Mmolm1IsmPcsJ1Lr7y4KBWjFqDdRQ2y5SS9aBYmZVPqeVSN+PbFN7fkx1u5LP3nGHoypTMylnRfmEVrK2QxWy99lAfXBMdrTf+Q7s2gWbtypGnegWRaLzZVVKTo2PekoUQjgsSqukilSMTwU45xw7+GrNGqx8aYA7Hz2RpOc02toEqIeH5w4wdAL1fGZyeB4yak9o3gpWR1RcXinBCXgCTwOoNbj4O8HVJB/ukMckUd+jiQUwaue9c/tpaxMWOzoqG3+PKuEW8IhOCYS8sz9nmb5toNRzcmQEDvR5+c72L8Lmv51zKPE4Vh51W5fto77/fqkeF4kIUD/1lG1J8jYDarCB2hPmjDPkT22VfMWlbkpVP13tWWIR0UlTM3KtF1wg124EBKh72gbYPywI/8QTkFXBZPligLIZBE+UlhYsRr12bS2jvu/R5ewfW0OoqoLJwmsovnQvP7rzcrnW8CTlMpQzgqhjySVMTMDAqOiP9qCkmAViYvr+5jfhqqsAw0XRlPtkuoL09UFR5YcHwzZQa71jmb4reaJeQefBsQ7uumvOx3JY5agGap8P/uzP4MQT5z5OJnoIV3WRFDxx+pAXyqi1j9p0+KhdajEWlb3LZwe8kBuy86m1D1sv0MQTEklumlLxJ9BpVRH78z+H6XRk/spknjCEVxELStJyxWMD9cCIjLVYlGd02osEqIdnljI8DA88qhylkTXkcmKui8dlOAcPSuCXYQiT0KbvVNZfw3g3bJBiBboIyeCgMPBYTIB6bMwuHNJINPBmMvObyZ3HH25A1ec97D7q078BJyyw6cuREMMuKuF7JkB9mMzeABheylUfiWy8YWpWjXhqTd/r10tRHF1iVpe29btlnQQbAXUDRu0E6r4+eDj3fyWIag55y1vgjVfL/fAGI7hcNqPWneG2bZP1c4cip/4FAXWId75T0t109brOTvAGQriqWTrbRG+MTwmj/uY34Q9/QPRFKcnyln4OjAmj3rHDTs8qlP1kyp0Q7BZGPbmCjugky7uzTE9DuSg6bfsjfh7YLxdQdYXAE2RkRLIEQPzUAMVkLaM+MCSkImIIow7H47hcUqPA6pNtxNXvEL294Ffpdl5/gCVLbEbt96vgSndA9LLKgvmX/+jgNa+Z87EcVjmqgXqhYhgyEdwsZkZdmPtYzagrdVHfYHez0gsw0C3H6M40amMwPN1hn9Msq/KFY5Z/eWpKFEiuuABG7QlR9ts+h5LLBuoDgzFWrpQ81csvh0jXakCiXf/hH+DMczuZOuF6zLVvtcxP2lc2MGAH+USjNlCns4GaSlIbNkg6iq5Mp9tTaqAeH6/tuVwvbre0QFwoo37emb67X2znxD8X4rKB2h96BkB9mCK+AfBGyLuWAcah+ahdAY4/Xiw+Dz2kgFqZ0b0uxajDyo87l48aG6h37Zqj9HGdrFgBLzpfzmF4I7S1SZ79+HgtUIOUx4W6e+6pB2q1Vj1hQiEpIFMjbun13r1EyMPuPT7cbrFibd1qf97nKTE4JYx6aMjug54vBfjZgX+GF/yUeDaBxtAAACAASURBVBz6J0VPrF4iVr7EtOi6Bx4OMOOSC0jmZXEfPGgDdTwg+quSHqVaNRhPdjI+DvuVb9+dl8W/cv3slAJTdWorVUP09UEopnbCbj+bN9tArav2WW5EBdTxzmM+6udETFcYj7GIgbpZW0kdIamDySxGHbQVgCrPR/wEOPt7cMpn5X9t/lbft2Nn3eQrTEhxBuWf3qViOjLFSPOo72pF1eEOkXfZQF102ai4rz/KqlWy4//Wt4DoOgrn38v191/O4KDs/O8Z+DPe9T7pPwy273lgwG5Z6gTqfKkWqPXxe/bI+ZxAnUio/Mh5SnCGwzajdvaJbiTPO9P3cy2GE6j9cxzYRI4Eo97yUcxzfsZ73wvnnjvf9ztMHG4BapD52d2NVa1L65RQuI5Ru7w1zFWLBmodCDZffI09Bp3iFaGz064JoE3Xy5ZJ+uE+ZUUOhBfAqJsFG3rETdjZLoC64zE/Hc5CXY54lIFJu85+vmgHk1U8nRBabjFqgBVtwoCT06KPRsYDrDzlNADGkg6gTsnfMb8w6kp2lMl0O5Wqh127YDyhdvKZPkwM/u6jsxePKyDgnS8Lo462aqAOWECtdYb6QA1QH4v6fo7E8IbwuRYJUFcdQH2opu/69CywgdrthzVvsOt1W/2l5Ry6fKAlhUkxfauIb125KlOYg1HrHGpPiJRpa5m86Qgm2x9jxQpJBdIA5192Fl6frby3b5f4Al0CthGj9nqxTIyFsn8WowYB6ulpCSzUQD09LTmScwEvyNg0o+7qslthNjsWjgH1gsXBqCPxp8OoA6oZxBxmjkOV8Cqiq0/jn/5pAa4Gl9sGOAdQQy2j1u60cLQOqD0R6dPsfA2Z2z4f3Huv/L9goNZg74nQ0SGNO3w+2+1nGFLUB1Rfcu/CfNQNRTHqjlbRSY894attEOMAMc2owWH6Lvlr6s9roF4WFwY8NS76qFD2s+kFp1I1DYYn2y3X11RG7lvEJ0BdSo4ylpTFvG8fVhompQSGN4rXNxvmAhE5ZjoVYmoKWjpqgXpmRhp7WO4x5aO2gfrwBDAuVI4BtRKXLyRF5quV+Q8+0uL0US84mKxJehbYpm+1y7eUW3ov3HweDP8BaATUE9JoQDFqXeg+nQ83B2odkOcOkSjZWiZbFaA2XV729/mtto9O0QDs8cB110lAzNVXw2WX2cygUKCmT7BbhcDmi7WMetkyATntNwQB6nhcwN80D41Rz2X2hiMHqEfMR/1ci4NRv+uapwHUhgEX3ATH/c1hHNQhigZYd4CODnvj5wRqQ8Vy6KpnNUAdWQdnfhtWXGad0jBknu7cKRvZLQv1TjhSvPS83rq1ti3pVVfJBralhVpwrgdqzYibZQUoRt3WIow6k/fXAXUto9YFdDRQ50uBGqAempbFtaxFgHp0WM4bjQdYvT7KWPkMHu8/jpERFS9ieDG9MUJuAWozN8LwzFLruitVD2VD3ecm/dBdfhnUwVG5xrYlaoG5ArzsZbKh16ZvuUfaRz0pz879NKxAz0COAbUSK7m/UTGQZ1ucpm9dlL6pj7quiEgzRu3y2m0lg93y98D1MHYHjNwENADq9D5hyKp4iQbqVG6OYDKLUYeZyjuAuqKA2h2jVKIpUEejcOmlkmMN8MEPwi9+UQuqzkIUbq9oonpG7XJRE+ADEhATiwm7hvkZtQbq4WE7mKaZHElGHQg0b/TxvBUHUK9Y9TSAGqDrPAg8uybIGnEANWCxaidQ6/XwgQ+p//U69UQElde9ZVZ7T21u/cQn7JKl84rD9K1BU/unreF64Cc/gX/9V3vMNZ/VYpm+52bUQb+Qh2LZV9tpTAF1qeplLLnE3mQ7GLVeL/E4FMt+ksVuQvTT2Qnjw6L/1m0MYBjwVM8tvO/7X+GJJwSoly4Fw9dOUAG1r3KQg9PLaqwaeBxFkxqJAvCZtAykc6nto96wAW66SfSMdU7toy7NNAX/IynHgFqJNygPbFE05mjYNEMx6moZ7v5L6RIDs33U9SVEQaK+XY6ttcsrQThjd8r/GdnJWkCtzTr6O1Q/Z236TmTrTN+TD8JdV8nYyrbpezzVRaHko1DykSmp4A2VFtEIqE85RdpAagXT3m6X9XQqLCej9vga+6hB2EM9o3aWx1woo54vQhyOHFCff74E3B11Ypm+jeatMBe76IAy1eREK3Wnj1qvh45O3TzGJ5uUOVLjNm+WClrveMchjKXO9A22Fcop27bBq1/NrJ7kNdLAdz7ru8pZDEUeCuV6Rt0Ghovp/HJM02WN49Z9l8FJ/8jHP7eU10kqNF4vXHMNEF4BqT288oU7GB8Vnbb+OLmvm7eEKFV8FlAvWwb42wkYk4BJxC09p51ArX3QTUFV6ctsQa6xu6d203XmmbJB/xttsNHFo0rJ2narz5IcA2olfqVpU9OLHKjzoyrP+X9qj63xUedUiUi10IpTdsckLaEerOYA2Tqgbt0qjNsC6h4KBTsvOZGpA+qDv4X+n0Km12ba7hDJlIuByRVkCmFrQeQqskAaAfWPfwz/8R92Uw1nXrQTqJ2M2quAulDyNwTq/fvtwif1QL0QRp1Ozx8hDkfO9H3VVfCDHxzecy4K0YzaHXhW2wUeVlkIo9brQVX7wjDkc97mVPlb35K63PWFTeaUyFo48ZPQ8yprU9kIqC3R4Nzo/juivht/NiTXpax55YqnFqgNF/jamSmKJW7TJlm/RXcPbPkI73iHYRVQAfjnf4ZY9woYu4NvX7GVZT7ppHbc8TLGJUtk0/7EEwKeGqh95iTtkUk8rlINo47FwOXXgSzNgFpezxZDBALQ7jB9awk4b432UZcSzwmjniM85n+XBFVXmOnJLLE58mWfFankRZGZjkYcOupbL3zd1q1RwZNKThaZMlmTHahp9QjUBuGoc2mgNiPrMKYfkXxqgFAPe/dKTvKKFTCdigpQVwriq9FjyfTb5nVPiERCUi8CvrwF1JlCc6AGWRinniqmXh3xDbUA6GTUuuxjuRqY5cc9/ngxc992myy6WOzQGfXAgC7MP/exmzaJT1FHmx+TeUQDWT2bez6J3hyra7jqKomrOOkkoOowfbu8tWDojczJqD2euQMXG4rhghM/CsDrXy9z+7jj5jheA1KjyO7IGulcFT9+9nsgjLqShWqRUtUPGLVADdByIkO9Esm2bJms90a10y057r1yTw58j01Lxcd2/BYhF4YBJ5yAxajPPRfwteOp7mFpq8TwDM8s5VWb5VRLl1LbL6CRqNfLZpBVq8Dw2sFkDUX7qIuJZz2QDI4BtSWhWBjSkJxcBEVPKjmZtGoxALaP2gJqZc+1GHVYFmslK6zaE5LF5vLK/w7T9y23wKZMD7IfMdDMejrTyh8fv5BtJ76UVv/tqiGHAcGl7FV18U8+Ge7bc7pUMxu/E7ovsseS7XfUBA+RTMItT17IZLqdqqoRPDIZJRhkFvt1SleXRH07FU0zRu0LiEJ0+wOziMHZZ8vvm2+WYDBdJAXk77nGAALU46onyXyMevNmiSQ/JgsUzajrLT3PJ/HWMur2dvi4VZlXNzavzFb+7WdCyzxVmJ6BtLVhmZabisWoG/Qu9bXAZQdnv259VlVxrBaoInplFlBfcBO/+70syKVL4X3vk+IhTWXJuRDdCAe+x8qOfqpVg02bbZPCli3SASyb1Yy6DXd5kmUtMs5UeZlVkGjpUuwqjM3M1Or1rmUhzjwTKQa15FxoP73x8U4fdWS+JPvDL8dM30oiqn1bamaRmL7dgVrTU7WOUefqgNrll1QlXYXMHRLgDq2030eina++Gr7zE/V65znWV2SLIS767B95Kv0a20+lwP7AAfl3yxYBX9Plt83vGqgzfTXBZIkEfPqXf89r//lnVou7Pb0xPvjB+a2dJ55YG7Hq8QgrhsZA7W2gBdavFwWiU7MAq51iR8f8AVpOhj4fUB+TQxSXw/T9fBUrJ7rBNTj97kadDftFP4cT62rtP9syF1DPJw5GbSq9MguoXW6CIYGXpUvhbW+DN7xhnvP6OzAx6IhOUqgE8AdsJXHllfa6P+44wNeOq5zgzBPFbVfyLLXGUMuo5/ZRX/qaEN/9LjIfL7pdCgE1En2fChOLN5jMMIyXGoaxyzCMvYZh/L8G759rGMbDhmGUDcO4ou69imEYO9TPDYdr4IdbQjEB6nx6sQB1sNYsVQ/UVn51XoG0IaxZ50zrQJDwavmt0gn6+sSc++VfvYU7zOuhXTcphmBEFu+BA9jmHWU+P3BAzM8rV0K2EKbYcgEcVECdc5i+HcFkyaTdBzyXM8gUQixZHnWwjkMTbf52mr79QUHzmiYDSgzDZtUaqDWjns/sDbVAPZ/p+5gcohhHEVA3ugbDZfulF2OwnB5zfVWyBX02pJr95PD4/Jx2mqpIVidXXCGdvuY0eTvF5bH0TsWs3Xiff77orb17pSy0TiH76LsljuYv37aUtjbZ0Pf0YDPqeaK+jYU2prECc6cXZzCZYRhu4GvAy4DjgdcZhlHvvOgHrgZ+1OAUOdM0T1E/r3qG4z1i4lPBZJXiIgDq6hyMutKAUeucPpfXUdxEhyGvVu8JoOlav4a/jb/50p9hOnIe16wT8/Hjj2MzagdQr1ljg1cyeqk0dE/urjV9VxzBZEkbEFMp+Om9f86k9+KnHTukzd/Ohe9XjNofbGxXO0cZDOqBeiEM+RijPoJyNDHqZjm1GqAXM1A/XUYNkBvBE4jwwAONG9xs2SKugENZ74bqLd6orKzLJf24XS6slpfe0RvAG+fNbwvhdsOvf60itRfIqBfc6tU5Txcpoz4D2Gua5n7TNIvAT4BXOw8wTbPXNM1HgeoRGOOzIroou9Vp6rkUy/Q9B6Mup1TkZd6eRC6f3be6nlErE9Uddwgj/fCHxQ88k7OBOhoPcPHF8N3vQsWjGbVEfe3fL0Ct05Cm/BfLHwd/a0eAZ/pqGHUiYTPRsTF46398h4OeeVqZzSEaqJ2MWnclCoQbK8vDwahdrvn92cfkEMXyUR8NQN3kGoyjFKg1uKX2QLBn7mMPVVTQq3e+1qdtp4lOyw5A0I7+veQS5cP2zRf1rRTBQi0KznnajKUfQVkIUC8HBhz/D6rXFioBwzAeNAzjPsMwGvYbMQzj7eqYB8d19M6zLP6oaH93efo5+f4aqeRmM+pKXTAZSLR1tWBPokaMus70ffvt8KIXSRQlwPCU7VzyBgNcc41EVj6222bUpimMeu1aG7ymS+tkkY/qKv+dyvRdy6i1OUo314g/g82oNn07GXUuuI0v/eb9TLjOa/iZM86As86yazc/HUbd2Wmb8I/JYZKjwfTtncNHDeBWQRb1PurFIK7DwKgzvXZmyeESKxh1niBDtx86zpS/gw2qEc0X9R1ZD5s/CMtesbBxOe/TImXUz1RWmaZ5GvAXwD8ZhrGu/gDTNP/dNM3TTNM8rXMhVOcISCAao1o1cFcWA1DrgiVqQbi8sxk1iPl7gYzaNHx87Wvi4zn3XKzuQH2jqopQxUMg6OFlLxPz0s9+pShksIfxcYm2dDLqbM4Fsc0wdru80H46VAvkJvtkHC6P1Z4yELCLjsSewWY0GhXwdOaXhqIB/vaHXyLS2vjEwaDUTb7gAnU7whJsojcqc4m+1mNm7yMgR4Ppe+klsO6tEGgSwLCYGbXLCxhPE6jVDtasHH6g1vdyIZaWzhfJ72CDfFrd0tfXxEHucsPWz9utRueT54HpewhwZr32qNcWJKZpDqnf+4HbgAZhB8+9uNwuZrIteM3FAtRBe0H4OxsDdX60DqgbMWrpk9c74Ofd75aWdW9+s90+b9+gMOd8KUAoJMzxa1+D3QOySx3LrbYivteudQB1Fohvtr5v2i3VFSb377S+O5kUoA4GDx+jrg9M0cC/UNO0yyXWgYVUfdKM+lgg2REQi1E/j9Oz4sfDmd8Spd9IFrOP2jAUGXgGpm84AkCtGfVCgPqF8rsRo+66ELZ9GTpfcHjG5X5uTd8LyaN+ANhgGMYaBKCvQtjxvGIYRiuQNU2zYBhGB/AC4AtPd7BHWpL5FnwsFqAO2LtKf4ftB64B6npG7bWP04w6uAwMD9MJPy0tklOsgzuWLYOdBzphlTS10MB0ySUQCl7MK977a975iTNJq69cs8b+bCYDrLFjCvdNn8FpQKt7p/XdiYQAqROonwmjvvpqeOELa1/TwH0ohpg58zkdou/HMUZ9BMR1FPio5xNdu8BZvncxiTvw9KK+nbEzh7N7GTiAegGLtPMciRJvOXn2e24fbHrf4RuXc0PzHER9zwvUpmmWDcN4N/B7wA18xzTNJwzD+CTwoGmaNxiGcTrw30Ar8ErDMD5hmuYJwGbgm4ZhVBH2/jnTNJ88YlfzDCWRa8UfWiRA7QrUMuqCqqZRzojppZRsbPrWoheTyw0tJzGydxlLltRGYK5eDU/uiWNe4CFXDFps+f+3d+bRcVVXvv5OlapUkyZLsjwj2djEBLAxxhCmNDGD7dAMgRACpOm8vOXQIXmkO7CA14Q0dDrLeUlnIBOdwW8lnaQJIUnjDubF0EzLTLYxhtixjQdsDcay5rmkGs7749xbg1RlleQqVUna31peunWH0rnHt+qn3z77nA2weImTzbs+ykcbTck3+3w7haC/Hyi1hVqx/b0LOKfChd/VSUhXcf1HzXV26LvBynI4FUd9zTUj961aBRs3wpo143/fdIijziF2WHgyh75Ho5AdNZiwffUlo583nJw66jGEvl2lcMP7SQVeckaeQ98Z3aHWejOwedi+hxK2t2NC4sOvexXI3RI8WaZnsIKaQCEItZ1MZhdrrkqenuUqNcdtR22HYhKSVv6y38db++C224ArXuDRb7tHLEpQVwdbtyq0u4pgyDNiOpLLBfX1ZlnEmhojXP1WUncs9G217519M/jf9V/jm7fdS3u3j82b4dZbze//4x/NQitwao46FQ6HCeXnAnHUOWQqjFGPRqEL9bnfGN91RQUS+oaJ69vJINTThb6hCrzOkyydN1HE5lFbWaWJQh3uM07bMcM46mgQnPbDHXfU3/6+j18+bsRSuUp5vzmeQGZTV2cKYYSd1QRD4Et4/hwOsz5vfb0parFkidlvu+6+Pkw9XYcLPDXs3w8vvvgPXHD6G/hKA5xxBvzqV+Zcb0LU6FQc9URjtzXVHFHhFJkKWd+jYf/hXIhZ36dCLMnVHV9vIVvYjrrQchcmwRj1tKEvVIHPVQiO2komW/Q/zPq3XbtHCrW7cuQYdcIXwp59XoJB6OgwU6RaWkbWp62rM4U2uodq6A32jShqsWCBCVkfOBAPO9ui298PWhWhSs8E7xz274fqagc3P/pbAO64I/4+9tKfLld8ezKwaJGpXHXDDfluyRRkWjhqe4x6igm17ah987Jf+cx21IWWu2CPUTuK8/JHhMwOTaA/UkFgAoW6uZlYsYskbPENLISFf2M+8IlFOYr87DlUTfvx1pRj1FoVsXef+XJoajJh59bWkevx2g77j8e+xRd+/r2kMWowjnrPHtNO21E7HEasjxwxiVxb9X/Qu/R7HDuWPIZ8YXxl0pi4l5ZOroqGSpnQ/fB+EbLAVCjKMRqFHvoeL4lCnfX39hvHXqiOOg+JZCBCncRgtBx30SCEBybk9z3wANx447Cd0dDIijsOt6lWFY1AuA/t9LN1RxXuaMvIrG9AO3yxBLCmJjNNKhQamRltC/VLb5/NziPnjRCkBQuMI4e4UIMRrm3bzPt+7xdL2d9kpsZffXV8jrO9IhjEhXoyhb2FHDMtHPUUFWo79J3tjG+bcx6B2tty897jxX5O8zA+DRL6TiKorUnyQx3jm7YwRtra4kIYw66GlfgFZv91GR2CcB+doVrqm6sJFPdAKJKwMplx1GEdV9ymJuOmYaSjnjvXOOS9e83rVKFvm8WL49s+nwmHAzz9tJmbDWYRkUWLTLg8cUERO9yd7UQyYRIzHcaoHVN0jNrhNmKdq3KPS7+Um/c9Fezv2DyMT4MIdRJDiULtS7HaTZbp74dgcNjOWNnKYY4aYkLdeMJPa4+lupH+5KIcQDCcWqiHO2qXy5pLbQl1qtA3mBDwooT15Px+CIfNdl8f3H23cedLlphpUu3tyYXvxVELI5gWQl3g86jHi1JwxYtQcnq+WzJxOFymIlqeHLWEvhMIqQShziVaw3+v5ryap9IL9fDQN7Dha4MQ6eNQvZ+W7gTVtc6NKnNe/6APl8skkTU1xec+j6gZi3HN3d1mO52jPu205CQwW9BrauIrgj35pBH+b3/bFPVIJHGMWhCAabLgyRQNfYNZMthdMfp5UwWlzLMqQp1/ws4JEupIPzQ/z7mznz2JUCeE3i2h3rVzCB3q49ARPx0DCarr9PD66/Dk760EsmYfp59uhPZkjhqSw9vpHHXi+DTEBX3hQnj8cdiyBVasSH+7tsiLoxZiTAdHXchrfQtjx+nJWzKZhL4TiDgsoQ515vYXhcwyn1W+BkIhiETAaS8XHLES2ZIctQlt6/AAKhqke8BPcUmCUDs8fPObsK7afCF09/tYssSEpzNx1DbDHXVpqSnCPrwovC3otbVwxRWj366EvoUR2OI1lYV6qk7Pmq6c9WCsDvZEI0KdgHZNkKO2al7XBMy6moODCW425qgTpidYH3gX5g+IvqAf5UkOfbe2Qsnp5jyn28fq1bB7t8nObm0161vbZSITOZmjBtixY2TI2j7PLuwxGhL6FkYwnaZnTbVksulKNtcOHyMS+k7ECmtEB3Ms1CEj1LPL6gEj1DEsEaeoJL5LGwEuVqZdfYN+PGUziEatSclOD+3t4Co2XwiXXe7jC18wWd0tLcZVV1WlnsNsC7XTmVw+0qamJnllMYg770yFWkLfwghkepYgZIwIdQLFniK6B0qI9OfaUZvQd2WgDa+7P3mc2i5TmVBHtT9ohNrnbAeMUFdWOWnvm2FOcHpoa4MitxVqsxYkmGtNc3znnfTVpWyh9vszX4xEHLVwyth/iKarFzwVEKEWsoQIdQJeL3T0VRAJToyjBphf2ZAs1EPW+HhCdmHfgAkP+oriQj1zJvEpWpajLvba437JQr13b+rxaYgL9VhW3xqvUIujFmLMvBQ+8hxUFGR5+uwgY9RClhChTsAWah1sz+0vsmtGA/NnNIzqqHv6zQfe74qHvquriU3RCoY8BIPg9iQ76osuMolg4XBctIdTXm7Grocnkp2MEssMjTX0LY5aiKEcMGv15FpTdqzEHPUUm0ctTDiSTJaAxwPHO2fxgcHm7L+51vEvpXAGjjphjLqnz3zQA+5koW6tr7KOGyX0+JIddWkpvPkmvPKKmUqVCqWMq45lnWfApz9tVirLVNzFUQvTEpmeJWQJcdQJeL1wrGMOzsGm7L5x72H4w2xo/C/zOhR31Auq6kc6alcpb//ZSWOj2dVtCXWZd5hQ9xqh7uy1hNqb7KjBCPEll5gVyNKxbFnm7hjMKmSf+lTm5192Gdx1F6xcmfk1gjDpkaxvIUuIUCfg9cKxzjkUhY+bAhjZQEfh9c9AsNmUq4SYo27tqWT+jIbkrO+hTnCV8fGPw333mV3dPUaAZ/iTx6jt0HdnjxFqbyDZUWfKT39qFi7JFeXl8P3vj8weF4QpjYxRC1lChDoBjwea2ueiiMLgiey8acPv4cSLZtsefw73ElXFHD6xcGToO9QF7nJaW+MlMLt6TDJZhX+Yo7aSydq7jFD7/NYXQtHYhNrnG9sYtSAIGSBZ30KWEKFOwHbUAAwcy86b9h4yP52++PhzqIeIo4SGtvkpx6i1q4yeHjh61OzqtBx1ZUmbectggIoKOHxiMRFdxIlOs+C2v8Qd/12CIOQXEWohS4hQJ2CPUQPQnyWhtmtbe2cnOeoIAbr6yyjx9Ixw1FFnOeEwNDeb6lodXUaAF1TWMxQppqu/DK8XXjx4DY/sOkJjaw0A/pLxOWpBEHKAHfqWMWrhFBGhTiBJqAeylFAWDZoPrLsiyVGHKKF/yIdv+IInQ52EiKdH19fHhbrM1017/2zcboXDAYGAoqljLu3tpu2x6VniqAUh/4ijFrJERkKtlFqjlNqvlDqolLo/xfHLlFI7lVJhpdRNw47doZQ6YP27I1sNzwUeDzR31RDVjrGFvrWGo7+BaHjksfCAqYTlLk9y1EM6QN+gH39xnxHqZ1bA3n+FUBeDOj6H+uhRaOuMr4fc3DMnlpQVCEBvL7S1WeUmHeKoBaFgUDKPWsgOowq1UsoJ/ABYC5wJfFIpdeaw0+qBvwV+PezaGcBXgAuAVcBXlFIFW8TU64VItIgBXTM2oW59FV65BZqfH3ksYgm1qyzJUQ9FjaP2uAcZGoyYjPCWVyDURTASd9RHj0J7R/yD/n7H7NjKYCUl0NMD7e2m9jRlH4SSJVCyeBx3LwhCVhFHLWSJTBz1KuCg1vqw1noIeBy4LvEErfURrfU7QHTYtVcDz2qt27XWHcCzwJostDsn2E61JzxnbGPUA++bn6mqbkVSOeoeguEAfUGTaq2HuiAaMmKtI/SHhznqjvgHvb51dnpHXXI6/PV+8M7KvO2CIOQGmZ4lZIlMhHou0JDwutHalwkZXauUWq+U2qGU2tFiF0/OA/ZSl92hOWNz1EFrKleoe+SxyAAUDXPU4V6C4RL6Bo1QO0PW9T1mPlbfULKj7uxyEIqYReSOHB8Z+o45akEQCgdx1EKWKIhkMq31j7XWK7XWK6vTlXmaAFwucDigc3CMQj1o/XGRUGwjRiz0XQ6RfuOcQz0MhAP0D5kYtitiz9nWAHQHjaOuqDBC3dUF4agZpz7WeRJHLQhC4RBz1DJGLZwamQh1EzA/4fU8a18mnMq1E45SJvzdNjDXiG9kcPSLIO6owycRaqvWNUNdEO6lbyjuqIt18uIq3QPm3LPPthx1J0SsmtTHOpIddXe3OGpBKEhmfhjOfhhmnJ/vlgiTnEyEejuwq6z3NAAAFA1JREFUWClVp5RyA7cAmzJ8/z8BVymlKqwksqusfQWLxwNt/dYUreDxzC6KOeoUoe/wADg9xlHb50aH6BsMEIoaR11MslB39Jpzly+HhgYzlzqqjFC/3xlPJgsE4PhxCIXgrLMyv0dBECaAIi+c/RA4xVELp8aoQq21DgOfxwjsXuAJrfUepdQjSqlrAZRS5yulGoGPA/+mlNpjXdsO/DNG7LcDj1j7ChavF1p6x7joSWyMOoWjjgaTHXW/qbTRGywhooyj9jmSq3W195pz77nHiDEAtlB3JIe+wUQCrr46s6YKgiAIk4uMylxqrTcDm4fteyhhezsmrJ3q2o3AxlNo44Ti9cLx7jEuI2o76pOFvm1HbQl1TzBAVBlr7HckO+q27nI8Hpg/HzZsgM99DnAWMxR20dZbOUKoL7gAqqoyvUNBEARhMiH1qIfh8cB7x63E9EyF+mSO2lrw5J195ZwDMaHu7i8h6jCO2l9kXe9wQ3SIlq4ySqxy1J/9LMycCQG3m8b3ZgNqhFCvWzemWxQEQRAmEQWR9V1IXHQR/HZTJeGoK7NlRKMRGDTFMtJNzxoIebn+ZhPObm0wQn28LRBbQazEbQl16VJwuGnv8lBaanY5HHDjjeAocsecvi3UdoL8Rz869vsUBEEQJgfiqIfx/e9Df7+isW0OszqO4RntgqE27GlV6ULf3X1e2q0EsfbGRqoCsP2tEpwVxlGX2UI9+ypwFNHTo2KOOsbstTy714i9LdTXXw9bt8KKFWO+TUEQBGGSII56GEVFsHatmQYV6ckg9B1MCFunmUfd3eelZ8Aob1HIOOrWrgAOl3HUZR7rPc55BNbsoKeHkUK9/GtsfP0+gFjWt9sNF188ptsTBEEQJhki1CmoqjJ1qVUwA6G2E8kCdSND39EQ6Agd3V6i2klXfyk1PlOfur13Bg6Xscalnk5QTnCYRU1SCjVxJ23/FARBEKY+ItQpqKyEpva5uMJjcNSBRSND3xFTi7q92yhrV38Z/uI+dh1dRkPbAjxeB8GwZY+L/GaeFSLUgiAIQhwR6hRUVZnQt4su6DsK7/07HPm1SRwDmpvhy1+GwUEgaDvqRRAJJpe6DBuhbu3w4HRCZ78Zp37qz58GTAh7KGoLdSB2mQi1IAiCYCPJZCmorDShbwD+dAEErQVJeg8T/sCDfOIT8NJLZlrUh/wnAAX+08w54R5wW5U8o0EAWtq8nHMO9A6WMRR24Vh4G2AEdyjiB1pHCLWd9Z2IXTREhFoQhKlEKBSisbGRYDCY76bkHI/Hw7x583C5Mi/WIkKdAp8PWvvsZUSbYdW/wYmX4c9fYfPztbz00m2AorcXcByH4qq4OIe649uWoz7e6mX+fHjj+Md56/3VnHllVez3hHRC6BuIRk2hDXHUgiBMFxobGykpKaG2thZlDQFORbTWtLW10djYSF1dXcbXiVCnQCkYwBLqkiWw8DNw2q3Qc5Br9af4v3+3lU//6DEj1M6j4K8Fl6WsiZnf1hj1sWYvcz4AH7nzfzE0BH6jyXi9ENbWC8tR9/Zav/YkQm1nfQuCIEwFgsHglBdpAKUUlZWVjLWcs4xRp2HAUcvRrg/C8q+DwwmuAL0XvcKmnddy3cqnAOjrA/qOQKAWitIL9Yk2L3PnwrJlcP75cPrpptrV/PkQJtlR91iXi6MWBGE6MdVF2mY89ylCnYZAmZdbf7kb5l8f27dtu5M9jWdSVtwKaHp7oybZLMlRW1O0oqGYUA+EvMyZE39vtxsOHYL164kV5og6jaMWoRYEQRASEaFOQ1UVtLUl73v1VWjprsahwpT5utD9zRAdBH8tushkf+15uwdaXoPflsMxU8dkYChZqAHKy83iKnZhjogyQt1t6bwItSAIwsTR2dnJD3/4wzFft27dOjo7O3PQojgi1GmorITW1uR9r7wCxaVmge3qkhbcofcA0P46HnzYKOsbLx6D126HSD+0bQOMUM+dm/r32I76jTf9bN0K775r9i9cOPJcEWpBEITckE6ow+FwirPjbN68mfLy8lw1C5BksrRUVUFHB0Qi4HRCOAyvvQZr7zRCPa+6BU/kCADvHK7lsZ+V8C+r4IYlX4XeVlAOot2HcQBDEZP1nQrtNI566+sBtr1sBNrjgSVLRp4rQi0IwlTni1+EXbuy+57Ll8N3vnPyc+6//34OHTrE8uXLcblceDweKioq2LdvH++++y7XX389DQ0NBINB7r77btavXw9AbW0tO3bsoLe3l7Vr13LJJZfw6quvMnfuXJ566im8WfjCFkedhspKM1XKjmg8/zx0dcFZKy2hrmohwBEA9jWcFlvLu8LbArOvBu9cHINmZbMN3/CS7g8u7TSOum/Qz6uvwltvwdlnm7D4cOxweCAw8pggCIIwfjZs2MCiRYvYtWsX3/jGN9i5cyff/e53edcKc27cuJE333yTHTt28Oijj9I2fGwUOHDgAHfddRd79uyhvLyc3/3ud1lpmzjqNFSZqc60tRnR/tWvoKwMLvpIFfw/mFvVQqnzCHhmcuSAj1AEhiLFuJ2DUHsb7H8U+hsA+NhN6WtwaasmdW8wQHOzcfF33JH63Ntvh3nzoKIim3cqCIJQOIzmfCeKVatWJc11fvTRR/nDH/4AQENDAwcOHKCysjLpmrq6OpYvXw7Aeeedx5EjR7LSFnHUabD7v7UV+vvh9783daE91hj1rPJWKtxHwF9Lfb0Rz5AuoX/QS3TOdeCdFX8zZ/rQh72E6AeXG5s8NGTCNKmYMQM+9rFTvjVBEARhFPz2ghfAiy++yHPPPcdrr73G22+/zbnnnptyFbXi4uLYttPpHHV8O1NEqNOQ6KifecYsRHLbbUCRD5w+Zpa1UOU5Av46GhrMnOhefRpPvHEz7T0lRItnx9/Mmd5Rn7PCPAx/+z/9sdD2smW5uSdBEAQhNSUlJfT0pChVDHR1dVFRUYHP52Pfvn28/vrrE9o2CX2nIdFR79hhVhO77DLroKea2eVNzAq8B4GbYkL9kut57tzo5q27watn4QfC2kPRSSa4FxX7rJ8BLrgAnnsOzjknt/cmCIIgJFNZWcnFF1/MWWedhdfrpaamJnZszZo1PPbYYyxdupQzzjiDCy+8cELblpFQK6XWAN8FnMBPtdYbhh0vBn4BnAe0AZ/QWh9RStUCe4H91qmva63vzE7Tc8ucOSZp6403YOtWuPjihASv4mqWzX6ZImcYKpZRXw8XXggV1aUMhqClBcrVbPxARHlP3slF/tjPO++EM85IPYdaEARByC2//vWvU+4vLi7mmWeeSXnMHoeuqqpi9+7dsf333HNP1to1qlArpZzAD4ArgUZgu1Jqk9b6LwmnfQbo0FqfrpS6Bfg68Anr2CGtdZpR18KluNhUx3riCZPgdeutiQermeHdAcCAZxnt7bBgAVSb4WtaWqAqMIvZgHaMkppvF/Bwz+DGG804uCAIgiDYZDJGvQo4qLU+rLUeAh4Hrht2znXAz63tJ4HVagos3HrjjUakAT784YQDHqPI/UNe6jsWAyb0bQt1ayu09JpkMnWSRDIAalbDXz0DFZPubxlBEARhAshEqOcCDQmvG619Kc/RWoeBLsDOW69TSr2llHpJKXXpKbZ3Qlm3zjhrjwdWrkw4UGwUeU/T2dQ3OAEj1HYCWksLHO8yyWTKNYpQO5wwZ40p2SUIgiAIw8h1Mtn7wAKtdZtS6jzgP5VSH9RadyeepJRaD6wHWLBgQY6blDmBAHzqUzAwYAQ7RrFR5F3vLcNhzcKaP9+cU1pqhNrrroF54HTLMmKCIAjC+MlEqJuAxAUw51n7Up3TqJQqAsqANq21BgYBtNZvKqUOAUuAHYkXa61/DPwYYOXKlXoc95EzfvKTFDut0Peu+mX4ZxgzbK/lXV1thLq42ENHRTnl1emnZgmCIAjCaGQS+t4OLFZK1Sml3MAtwKZh52wC7PW0bgKe11prpVS1lYyGUmohsBg4nJ2m5xH/aQBsP3Q+f/kL1NTEHbct1G1t0NI7e/QxakEQBEE4CaMKtTXm/HngT5ipVk9orfcopR5RSl1rnfYzoFIpdRD4B+B+a/9lwDtKqV2YJLM7tdbt2b6JCadmNU+Ht7H98Cp274aEVeaoqooL9WOv/jMs/VL+2ikIgiBkxHjLXAJ85zvfob+/P8stipPRymRa681a6yVa60Va63+x9j2ktd5kbQe11h/XWp+utV6ltT5s7f+d1vqDWuvlWusVWuv/ytmdTCRKEfSfD8DRo8lCbTvq1lbY1XYjzL4qT40UBEEQMqWQhVpWJhsniRWsamvj2zNnWslkXlixYsKbJQiCMLl584vQkeU6lxXL4byTV/tILHN55ZVXMnPmTJ544gkGBwe54YYbePjhh+nr6+Pmm2+msbGRSCTCl7/8ZZqbmzl27BiXX345VVVVvPDCC9ltOyLU4yZRqBMd9SWXwNe/DocOwZVXTny7BEEQhLGzYcMGdu/eza5du9iyZQtPPvkk27ZtQ2vNtddey8svv0xLSwtz5szh6aefBswa4GVlZXzrW9/ihRdeoMqeo5tlRKjHSUJhlSShvuoqU0mroyO+XrggCIKQIaM434lgy5YtbNmyhXPPPReA3t5eDhw4wKWXXsqXvvQl7rvvPq655houvXRilgYRoR4n6ULfbrdZ0eynPxWhFgRBmIxorXnggQf47Gc/O+LYzp072bx5Mw8++CCrV6/moYceynl7pMzlOLGF2uEw63wn8slPmp+zZiEIgiBMAhLLXF599dVs3LiR3t5eAJqamjhx4gTHjh3D5/Nx++23c++997Jz584R1+YCcdTjxA59z5sHLlfyscsvh02b4IorJr5dgiAIwthJLHO5du1abr31Vj70oQ8BEAgE+OUvf8nBgwe59957cTgcuFwufvSjHwGwfv161qxZw5w5c3KSTKbM4mGFw8qVK/WOHTtGPzHPRCKm7OVll8FLL+W7NYIgCJOXvXv3snTp0nw3Y8JIdb9KqTe11itTnS+h73HidILPl5xIJgiCIAjZRkLfp8BXvwoXXpjvVgiCIAhTGRHqU+Dv/z7fLRAEQZgaaK1R06Dc73iGmyX0LQiCIOQVj8dDW1vbuERsMqG1pq2tDY9nbFUVxVELgiAIeWXevHk0NjbS0tKS76bkHI/Hw7x588Z0jQi1IAiCkFdcLhd1kpmbFgl9C4IgCEIBI0ItCIIgCAWMCLUgCIIgFDAFtzKZUqoFOJrlt60CWrP8npMZ6Y840hfJSH8kI/2RjPRHMtnsj9O01tWpDhScUOcCpdSOdEuzTUekP+JIXyQj/ZGM9Ecy0h/JTFR/SOhbEARBEAoYEWpBEARBKGCmi1D/ON8NKDCkP+JIXyQj/ZGM9Ecy0h/JTEh/TIsxakEQBEGYrEwXRy0IgiAIkxIRakEQBEEoYKa0UCul1iil9iulDiql7s93e/KBUuqIUurPSqldSqkd1r4ZSqlnlVIHrJ8V+W5nrlBKbVRKnVBK7U7Yl/L+leFR63l5Rym1In8tzw1p+uOflFJN1jOySym1LuHYA1Z/7FdKXZ2fVucOpdR8pdQLSqm/KKX2KKXutvZPu2fkJH0xLZ8PpZRHKbVNKfW21R8PW/vrlFJvWPf9G6WU29pfbL0+aB2vzVpjtNZT8h/gBA4BCwE38DZwZr7blYd+OAJUDdv3f4D7re37ga/nu505vP/LgBXA7tHuH1gHPAMo4ELgjXy3f4L645+Ae1Kce6b1uSkG6qzPkzPf95Dl/pgNrLC2S4B3rfueds/ISfpiWj4f1v9xwNp2AW9Y/+dPALdY+x8D/s7a/hzwmLV9C/CbbLVlKjvqVcBBrfVhrfUQ8DhwXZ7bVChcB/zc2v45cH0e25JTtNYvA+3Ddqe7/+uAX2jD60C5Umr2xLR0YkjTH+m4Dnhcaz2otX4POIj5XE0ZtNbva613Wts9wF5gLtPwGTlJX6RjSj8f1v9xr/XSZf3TwEeAJ639w58N+5l5ElitlFLZaMtUFuq5QEPC60ZO/tBNVTSwRSn1plJqvbWvRmv9vrV9HKjJT9PyRrr7n87PzOetUO7GhKGQadUfVqjyXIxzmtbPyLC+gGn6fCilnEqpXcAJ4FlM1KBTax22Tkm851h/WMe7gMpstGMqC7VguERrvQJYC9yllLos8aA2cZppO0dvut+/xY+ARcBy4H3gX/PbnIlHKRUAfgd8UWvdnXhsuj0jKfpi2j4fWuuI1no5MA8TLfhAPtoxlYW6CZif8HqetW9aobVusn6eAP6Aedia7XCd9fNE/lqYF9Ld/7R8ZrTWzdYXUhT4CfHw5bToD6WUCyNMv9Ja/97aPS2fkVR9Md2fDwCtdSfwAvAhzHBHkXUo8Z5j/WEdLwPasvH7p7JQbwcWWxl6bszg/qY8t2lCUUr5lVIl9jZwFbAb0w93WKfdATyVnxbmjXT3vwn4Gyuz90KgKyH8OWUZNsZ6A+YZAdMft1jZrHXAYmDbRLcvl1hjiD8D9mqtv5VwaNo9I+n6Yro+H0qpaqVUubXtBa7EjNu/ANxknTb82bCfmZuA561ozKmT78y6XP7DZGi+ixlX+Md8tycP978Qk5X5NrDH7gPMuMl/AweA54AZ+W5rDvvgPzDhuhBmPOkz6e4fk+X5A+t5+TOwMt/tn6D++Hfrft+xvmxmJ5z/j1Z/7AfW5rv9OeiPSzBh7XeAXda/ddPxGTlJX0zL5wM4B3jLuu/dwEPW/oWYP0gOAr8Fiq39Huv1Qev4wmy1RZYQFQRBEIQCZiqHvgVBEARh0iNCLQiCIAgFjAi1IAiCIBQwItSCIAiCUMCIUAuCIAhCASNCLQiCIAgFjAi1IAiCIBQw/x8H35mGBJh7GwAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 576x504 with 2 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}